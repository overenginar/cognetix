{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3fd977-3107-4150-b241-c18247ac2d48",
   "metadata": {},
   "source": [
    "## Income Prediction with Spark Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b019947-3e52-4742-9a33-8dc33d9f32a3",
   "metadata": {},
   "source": [
    "### Install findspark and init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0156047-cfe9-47e1-9622-74666342340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.9/site-packages (2.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c38bc1-77fa-400a-b944-44e1d20757aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1712a2-81a4-459c-8e36-c7317a52a07c",
   "metadata": {},
   "source": [
    "### Get spark and h2o sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd3e1e6-51bf-41ad-ab4a-d08c1ef14cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/10/20 14:40:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:40:07.224 172.17.0.2:54321      6000     Thread-4  INFO water.default: ----- H2O started  -----\n",
      "10-20 14:40:07.225 172.17.0.2:54321      6000     Thread-4  INFO water.default: Build git branch: rel-zz_kurka\n",
      "10-20 14:40:07.225 172.17.0.2:54321      6000     Thread-4  INFO water.default: Build git hash: 5ff8870f912c6110d7b6988f577c020de10496ec\n",
      "10-20 14:40:07.226 172.17.0.2:54321      6000     Thread-4  INFO water.default: Build git describe: jenkins-3.40.0.3-122-g5ff8870\n",
      "10-20 14:40:07.226 172.17.0.2:54321      6000     Thread-4  INFO water.default: Build project version: 3.40.0.4\n",
      "10-20 14:40:07.226 172.17.0.2:54321      6000     Thread-4  INFO water.default: Build age: 5 months and 22 days\n",
      "10-20 14:40:07.226 172.17.0.2:54321      6000     Thread-4  INFO water.default: Built by: 'jenkins'\n",
      "10-20 14:40:07.226 172.17.0.2:54321      6000     Thread-4  INFO water.default: Built on: '2023-04-28 12:08:23'\n",
      "10-20 14:40:07.227 172.17.0.2:54321      6000     Thread-4  WARN water.default: \n",
      "10-20 14:40:07.227 172.17.0.2:54321      6000     Thread-4  WARN water.default: *** Your H2O version is over 100 days old. Please download the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html ***\n",
      "10-20 14:40:07.227 172.17.0.2:54321      6000     Thread-4  WARN water.default: \n",
      "10-20 14:40:07.228 172.17.0.2:54321      6000     Thread-4  INFO water.default: Found H2O Core extensions: [HiveTableImporter, StackTraceCollector, MojoPipeline, HiveFrameSaver, XGBoost]\n",
      "10-20 14:40:07.228 172.17.0.2:54321      6000     Thread-4  INFO water.default: Processed H2O arguments: [-internal_security_conf_rel_paths, -name, sparkling-water-root_local-1697812804151, -port_offset, 1, -hdfs_config, /tmp/spark-82785ddf-9893-4d4b-bfe8-91df3479dfc6/userFiles-588f7dc6-fa5c-4cc5-b589-673b7e035299/hdfs_conf3764335879118785268.xml, -log_level, INFO, -embedded, -baseport, 54321, -log_dir, /home/jovyan/notebooks/h2ologs/local-1697812804151, -quiet, -flatfile, /tmp/spark-82785ddf-9893-4d4b-bfe8-91df3479dfc6/sparkling-water-98f3314d-1e65-4e09-acc5-4411685c26df/flatfile.txt]\n",
      "10-20 14:40:07.228 172.17.0.2:54321      6000     Thread-4  INFO water.default: Java availableProcessors: 4\n",
      "10-20 14:40:07.229 172.17.0.2:54321      6000     Thread-4  INFO water.default: Java heap totalMemory: 133.0 MB\n",
      "10-20 14:40:07.229 172.17.0.2:54321      6000     Thread-4  INFO water.default: Java heap maxMemory: 1.00 GB\n",
      "10-20 14:40:07.229 172.17.0.2:54321      6000     Thread-4  INFO water.default: Java version: Java 11.0.11 (from Ubuntu)\n",
      "10-20 14:40:07.229 172.17.0.2:54321      6000     Thread-4  INFO water.default: JVM launch parameters: [-Xmx1g, -Dio.netty.tryReflectionSetAccessible=true]\n",
      "10-20 14:40:07.230 172.17.0.2:54321      6000     Thread-4  INFO water.default: JVM process id: 6000@95675304fa2d\n",
      "10-20 14:40:07.230 172.17.0.2:54321      6000     Thread-4  INFO water.default: OS version: Linux 5.15.49-linuxkit-pr (amd64)\n",
      "10-20 14:40:07.230 172.17.0.2:54321      6000     Thread-4  INFO water.default: Machine physical memory: 5.80 GB\n",
      "10-20 14:40:07.230 172.17.0.2:54321      6000     Thread-4  INFO water.default: Machine locale: en_US\n",
      "10-20 14:40:07.230 172.17.0.2:54321      6000     Thread-4  INFO water.default: X-h2o-cluster-id: 1697812805943\n",
      "10-20 14:40:07.231 172.17.0.2:54321      6000     Thread-4  INFO water.default: User name: 'root'\n",
      "10-20 14:40:07.231 172.17.0.2:54321      6000     Thread-4  INFO water.default: IPv6 stack selected: false\n",
      "10-20 14:40:07.231 172.17.0.2:54321      6000     Thread-4  INFO water.default: Possible IP Address: eth0 (eth0), 172.17.0.2\n",
      "10-20 14:40:07.231 172.17.0.2:54321      6000     Thread-4  INFO water.default: Possible IP Address: lo (lo), 127.0.0.1\n",
      "10-20 14:40:07.231 172.17.0.2:54321      6000     Thread-4  INFO water.default: H2O node running in unencrypted mode.\n",
      "10-20 14:40:07.233 172.17.0.2:54321      6000     Thread-4  INFO water.default: Internal communication uses port: 54322\n",
      "10-20 14:40:07.234 172.17.0.2:54321      6000     Thread-4  INFO water.default: Listening for HTTP and REST traffic on http://172.17.0.2:54321/\n",
      "10-20 14:40:07.235 172.17.0.2:54321      6000     Thread-4  WARN water.default: Flatfile configuration does not include self: /172.17.0.2:54321, but contains []\n",
      "10-20 14:40:07.235 172.17.0.2:54321      6000     Thread-4  INFO water.default: H2O cloud name: 'sparkling-water-root_local-1697812804151' on /172.17.0.2:54321, static configuration based on -flatfile /tmp/spark-82785ddf-9893-4d4b-bfe8-91df3479dfc6/sparkling-water-98f3314d-1e65-4e09-acc5-4411685c26df/flatfile.txt\n",
      "10-20 14:40:07.235 172.17.0.2:54321      6000     Thread-4  INFO water.default: If you have trouble connecting, try SSH tunneling from your local machine (e.g., via port 55555):\n",
      "10-20 14:40:07.235 172.17.0.2:54321      6000     Thread-4  INFO water.default:   1. Open a terminal and run 'ssh -L 55555:localhost:54321 root@172.17.0.2'\n",
      "10-20 14:40:07.236 172.17.0.2:54321      6000     Thread-4  INFO water.default:   2. Point your browser to http://localhost:55555\n",
      "10-20 14:40:07.669 172.17.0.2:54321      6000     Thread-4  INFO water.default: Log dir: '/home/jovyan/notebooks/h2ologs/local-1697812804151'\n",
      "10-20 14:40:07.670 172.17.0.2:54321      6000     Thread-4  INFO water.default: Cur dir: '/home/jovyan/notebooks'\n",
      "10-20 14:40:07.679 172.17.0.2:54321      6000     Thread-4  INFO water.default: Distributed HTTP import not available (import from HTTP/HTTPS will be eager)\n",
      "10-20 14:40:07.700 172.17.0.2:54321      6000     Thread-4  INFO water.default: HDFS subsystem successfully initialized\n",
      "10-20 14:40:07.707 172.17.0.2:54321      6000     Thread-4  INFO water.default: S3 subsystem successfully initialized\n",
      "10-20 14:40:07.735 172.17.0.2:54321      6000     Thread-4  INFO water.default: GCS subsystem successfully initialized\n",
      "10-20 14:40:07.736 172.17.0.2:54321      6000     Thread-4  INFO water.default: Drive subsystem not available\n",
      "10-20 14:40:07.736 172.17.0.2:54321      6000     Thread-4  INFO water.default: Flow dir: '/root/h2oflows'\n",
      "10-20 14:40:07.746 172.17.0.2:54321      6000     Thread-4  INFO water.default: Cloud of size 1 formed [95675304fa2d/172.17.0.2:54321]\n",
      "10-20 14:40:07.760 172.17.0.2:54321      6000     Thread-4  INFO water.default: Registered parsers: [GUESS, ARFF, XLS, SVMLight, AVRO, PARQUET, ORC, CSV]\n",
      "10-20 14:40:07.761 172.17.0.2:54321      6000     Thread-4  INFO water.default: HiveTableImporter extension initialized\n",
      "10-20 14:40:07.762 172.17.0.2:54321      6000     Thread-4  INFO water.default: StackTraceCollector extension initialized\n",
      "10-20 14:40:07.762 172.17.0.2:54321      6000     Thread-4  INFO water.default: MojoPipeline extension initialized\n",
      "10-20 14:40:07.763 172.17.0.2:54321      6000     Thread-4  INFO water.default: HiveFrameSaver extension initialized\n",
      "10-20 14:40:07.763 172.17.0.2:54321      6000     Thread-4  INFO water.default: XGBoost extension initialized\n",
      "10-20 14:40:07.764 172.17.0.2:54321      6000     Thread-4  INFO water.default: Registered 5 core extensions in: 1025ms\n",
      "10-20 14:40:07.764 172.17.0.2:54321      6000     Thread-4  INFO water.default: Registered H2O core extensions: [HiveTableImporter, StackTraceCollector, MojoPipeline, HiveFrameSaver, XGBoost]\n",
      "10-20 14:40:08.070 172.17.0.2:54321      6000     Thread-4  INFO hex.tree.xgboost.XGBoostExtension: Found XGBoost backend with library: xgboost4j_gpu\n",
      "10-20 14:40:08.072 172.17.0.2:54321      6000     Thread-4  INFO hex.tree.xgboost.XGBoostExtension: XGBoost supported backends: [WITH_GPU, WITH_OMP]\n",
      "10-20 14:40:08.254 172.17.0.2:54321      6000     Thread-4  INFO water.default: Registered: 280 REST APIs in: 490ms\n",
      "10-20 14:40:08.255 172.17.0.2:54321      6000     Thread-4  INFO water.default: Registered REST API extensions: [XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4]\n",
      "10-20 14:40:08.420 172.17.0.2:54321      6000     Thread-4  INFO water.default: Registered: 329 schemas in 163ms\n",
      "10-20 14:40:08.421 172.17.0.2:54321      6000     Thread-4  INFO water.default: H2O started in 2497ms\n",
      "10-20 14:40:08.421 172.17.0.2:54321      6000     Thread-4  INFO water.default: \n",
      "10-20 14:40:08.421 172.17.0.2:54321      6000     Thread-4  INFO water.default: Open H2O Flow in your web browser: http://172.17.0.2:54321\n",
      "10-20 14:40:08.421 172.17.0.2:54321      6000     Thread-4  INFO water.default: \n",
      "10-20 14:40:08.425 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.sparkling.H2OContext: Connecting to H2O cluster.\n",
      "10-20 14:40:08.425 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.sparkling.H2OContext: Trying to lock H2O cluster 172.17.0.2:54321 - sparkling-water-root_local-1697812804151.\n",
      "10-20 14:40:08.501 172.17.0.2:54321      6000   7762763-69  INFO water.default: POST /3/CloudLock, parms: {reason=Locked from Sparkling Water.}\n",
      "10-20 14:40:08.508 172.17.0.2:54321      6000   7762763-69  INFO water.default: Locking cloud to new members, because requested via REST api. Reason: Locked from Sparkling Water.\n",
      "10-20 14:40:08.564 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/CloudLock successfully responded for the POST.\n",
      "10-20 14:40:08.578 172.17.0.2:54321      6000   7762763-65  INFO water.default: GET /3/verifyWebOpen, parms: {}\n",
      "10-20 14:40:08.652 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/verifyWebOpen successfully responded for the GET.\n",
      "10-20 14:40:08.656 172.17.0.2:54321      6000   7762763-68  INFO water.default: GET /3/verifyVersion, parms: {referenced_version=3.40.0.4}\n",
      "10-20 14:40:08.673 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/verifyVersion?referenced_version=3.40.0.4 successfully responded for the GET.\n",
      "10-20 14:40:08.704 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/Cloud successfully responded for the GET.\n",
      "10-20 14:40:08.708 172.17.0.2:54321      6000   7762763-68  INFO water.default: GET /3/LogLevel, parms: {}\n",
      "10-20 14:40:08.714 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/LogLevel successfully responded for the GET.\n",
      "10-20 14:40:08.719 172.17.0.2:54321      6000   7762763-68  INFO water.default: POST /99/Rapids, parms: {ast=(setTimeZone \"UTC\")}\n",
      "10-20 14:40:08.834 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/99/Rapids successfully responded for the POST.\n",
      "10-20 14:40:08.845 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.sparkling.backend.utils.ProxyStarter: Trying to bind on port 54323 using wildcard ip address\n",
      "10-20 14:40:08.988 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.util.SignalUtils: Registering signal handler for INT\n",
      "10-20 14:40:17.812 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.org.eclipse.jetty.server.Server: jetty-9.4.z-SNAPSHOT; built: 2018-06-05T18:24:03.829Z; git: d5fc0523cfa96bfebfbda19606cad384d772f04c; jvm 11.0.11+9-Ubuntu-0ubuntu2.20.04\n",
      "10-20 14:40:17.873 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.org.eclipse.jetty.server.handler.ContextHandler: Started a.h.o.e.j.s.ServletContextHandler@60049080{/,null,AVAILABLE}\n",
      "10-20 14:40:17.876 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@288c899b{HTTP/1.1,[http/1.1]}{0.0.0.0:54323}\n",
      "10-20 14:40:17.876 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.org.eclipse.jetty.server.Server: Started @16153ms\n",
      "10-20 14:40:17.889 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.sparkling.backend.utils.RestApiUtils: H2O node http://172.17.0.2:54321/3/Cloud successfully responded for the GET.\n",
      "10-20 14:40:17.971 172.17.0.2:54321      6000     Thread-4  INFO ai.h2o.sparkling.H2OContext: Sparkling Water 3.40.0.4-1-3.1 started, status of context: \n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.40.0.4-1-3.1\n",
      " * H2O name: sparkling-water-root_local-1697812804151\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,172.17.0.2,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://95675304fa2d:54323 (CMD + click in Mac OSX)\n",
      "\n",
      "     \n",
      "Connecting to H2O server at http://95675304fa2d:54323 ...10-20 14:40:18.043 172.17.0.2:54321      6000   7762763-71  INFO water.default: GET /3/Metadata/schemas/CloudV3, parms: {}\n",
      "10-20 14:40:18.092 172.17.0.2:54321      6000   7762763-70  INFO water.default: GET /3/Metadata/schemas/H2OErrorV3, parms: {}\n",
      "10-20 14:40:18.101 172.17.0.2:54321      6000   7762763-70  INFO water.default: GET /3/Metadata/schemas/H2OModelBuilderErrorV3, parms: {}\n",
      " successful.\n",
      "Warning: Your H2O cluster version is (5 months and 22 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>11 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>5 months and 22 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>sparkling-water-root_local-1697812804151</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://95675304fa2d:54323</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>null</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.7 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O_cluster_uptime:         11 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    5 months and 22 days\n",
       "H2O_cluster_name:           sparkling-water-root_local-1697812804151\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://95675304fa2d:54323\n",
       "H2O_connection_proxy:       null\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.7 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.40.0.4-1-3.1\n",
      " * H2O name: sparkling-water-root_local-1697812804151\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,172.17.0.2,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://95675304fa2d:54323 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pysparkling import H2OContext\n",
    "import h2o\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "    SparkSession.builder.appName('cognetix-spark-nb')\n",
    "    .config('spark.dynamicAllocation.enabled', 'false')\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "sc = spark.sparkContext\n",
    "hc = H2OContext.getOrCreate()\n",
    "h2o_cluster = h2o.cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b11a08-e309-4d12-a74d-56eeb12f1757",
   "metadata": {},
   "source": [
    "### Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26e8b22-875e-49cc-ae40-499d37ab4b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 5\n",
    "learning_rate = 0.01\n",
    "train_rate = 0.8\n",
    "seed = 42\n",
    "\n",
    "train_path = '../data/census-train.csv'\n",
    "test_path = '../data/census-test.csv'\n",
    "model_path = 'outputs/income_rf_spark'\n",
    "pred_path = 'outputs/income_rf_spark_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c63fd9-3e8a-43ba-b0ae-c4048ce8e233",
   "metadata": {},
   "source": [
    "### Load data and basic transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf8c40cb-18a9-4faa-897b-bdd2a3b33274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:40:18.586 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 30 ms to list leaf files for 1 paths.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"workclass\", StringType(), True),\n",
    "    StructField(\"fnlwgt\", DoubleType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"education_num\", IntegerType(), True),\n",
    "    StructField(\"marital_status\", StringType(), True),\n",
    "    StructField(\"occupation\", StringType(), True),\n",
    "    StructField(\"relationship\", StringType(), True),\n",
    "    StructField(\"race\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"capital_gain\", DoubleType(), True),\n",
    "    StructField(\"capital_loss\", DoubleType(), True),\n",
    "    StructField(\"hours_per_week\", DoubleType(), True),\n",
    "    StructField(\"native_country\", StringType(), True),\n",
    "    StructField(\"income_level\", StringType(), True),\n",
    "])\n",
    "\n",
    "train_df = (\n",
    "    spark.read\n",
    "    .format('csv')\n",
    "    .option('header', 'false')\n",
    "    .option('delimiter', ',')\n",
    "    .schema(schema)\n",
    "    .load(train_path)\n",
    "    .drop('education_num')\n",
    "    .withColumn('label', when(col('income_level').contains('>50K'), lit(1)).otherwise(lit(0)))\n",
    "    .drop('income_level')\n",
    "    .withColumn('workclass', when(col('workclass') == ' ?', lit('NA')).otherwise(col('workclass')))\n",
    "    .withColumn('occupation', when(col('occupation') == ' ?', lit('NA')).otherwise(col('occupation')))\n",
    "    .withColumn('native_country', when(col('native_country') == ' ?', lit('NA')).otherwise(col('native_country')))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5dfb6c-b722-4fd7-ab7d-f9269e7b6a39",
   "metadata": {},
   "source": [
    "### Explore train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0aa121b-ad53-48ee-83aa-e6930ef42cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:40:24.555 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:24.556 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:24.558 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<>\n",
      "10-20 14:40:25.139 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 173.773322 ms\n",
      "10-20 14:40:25.162 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.195505 ms\n",
      "10-20 14:40:25.203 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 176.1 KiB, free 434.2 MiB)\n",
      "10-20 14:40:25.263 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.2 MiB)\n",
      "10-20 14:40:25.267 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 95675304fa2d:39707 (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:25.270 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 0 from count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:40:25.301 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:25.569 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:40:25.583 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 3 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0\n",
      "10-20 14:40:25.587 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 14:40:25.587 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 1 (count at NativeMethodAccessorImpl.java:0)\n",
      "10-20 14:40:25.587 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)\n",
      "10-20 14:40:25.589 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0)\n",
      "10-20 14:40:25.593 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:40:25.649 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.9 KiB, free 434.2 MiB)\n",
      "10-20 14:40:25.667 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.2 MiB)\n",
      "10-20 14:40:25.668 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 95675304fa2d:39707 (size: 8.1 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:25.668 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:25.686 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:25.687 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:25.760 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:25.806 172.17.0.2:54321      6000   .0 (TID 0)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "10-20 14:40:25.810 172.17.0.2:54321      6000   .0 (TID 0)  INFO org.apache.spark.executor.Executor: Fetching file:/tmp/sparkling-water-12007379862768238077-hash-login.conf with timestamp 1697812805906\n",
      "10-20 14:40:25.834 172.17.0.2:54321      6000   .0 (TID 0)  INFO org.apache.spark.util.Utils: /tmp/sparkling-water-12007379862768238077-hash-login.conf has been previously copied to /tmp/spark-82785ddf-9893-4d4b-bfe8-91df3479dfc6/userFiles-588f7dc6-fa5c-4cc5-b589-673b7e035299/sparkling-water-12007379862768238077-hash-login.conf\n",
      "10-20 14:40:25.842 172.17.0.2:54321      6000   .0 (TID 0)  INFO org.apache.spark.executor.Executor: Fetching file:/tmp/spark-82785ddf-9893-4d4b-bfe8-91df3479dfc6/hdfs_conf3764335879118785268.xml with timestamp 1697812805871\n",
      "10-20 14:40:25.844 172.17.0.2:54321      6000   .0 (TID 0)  INFO org.apache.spark.util.Utils: /tmp/spark-82785ddf-9893-4d4b-bfe8-91df3479dfc6/hdfs_conf3764335879118785268.xml has been previously copied to /tmp/spark-82785ddf-9893-4d4b-bfe8-91df3479dfc6/userFiles-588f7dc6-fa5c-4cc5-b589-673b7e035299/hdfs_conf3764335879118785268.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:40:26.194 172.17.0.2:54321      6000   .0 (TID 0)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:40:26.248 172.17.0.2:54321      6000   .0 (TID 0)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 46.793064 ms\n",
      "10-20 14:40:26.601 172.17.0.2:54321      6000   .0 (TID 0)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 1965 bytes result sent to driver\n",
      "10-20 14:40:26.627 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 892 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:26.636 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:26.650 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.044 s\n",
      "10-20 14:40:26.651 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:40:26.651 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:40:26.652 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 1)\n",
      "10-20 14:40:26.652 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:40:26.663 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:40:26.683 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 434.2 MiB)\n",
      "10-20 14:40:26.719 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 434.2 MiB)\n",
      "10-20 14:40:26.726 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 95675304fa2d:39707 (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:26.726 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:26.728 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:26.728 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:26.735 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:26.736 172.17.0.2:54321      6000   .0 (TID 1)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "10-20 14:40:26.840 172.17.0.2:54321      6000   .0 (TID 1)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:26.841 172.17.0.2:54321      6000   .0 (TID 1)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms\n",
      "10-20 14:40:26.877 172.17.0.2:54321      6000   .0 (TID 1)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 2648 bytes result sent to driver\n",
      "10-20 14:40:26.881 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 150 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:26.881 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:26.882 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.213 s\n",
      "10-20 14:40:26.887 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:26.887 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "10-20 14:40:26.890 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 0 finished: count at NativeMethodAccessorImpl.java:0, took 1.321554 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c419a47-23f1-424c-9638-b2ce82e32c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'marital_status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital_gain',\n",
       " 'capital_loss',\n",
       " 'hours_per_week',\n",
       " 'native_country',\n",
       " 'label']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5afae865-b5c3-4e52-9f76-c28235e7c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93430319-4f83-4946-a7ea-77e7362e8abd",
   "metadata": {},
   "source": [
    "### Split train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f97377-33f2-494a-8018-e77e9273765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:40:30.727 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:30.727 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:30.728 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:40:30.826 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 51.186079 ms\n",
      "10-20 14:40:30.834 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 14:40:30.870 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on 95675304fa2d:39707 in memory (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:30.871 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.0 MiB)\n",
      "10-20 14:40:30.871 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 95675304fa2d:39707 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:30.872 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:40:30.873 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:30.972 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:40:30.973 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 10 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1\n",
      "10-20 14:40:30.974 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 14:40:30.974 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)\n",
      "10-20 14:40:30.974 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)\n",
      "10-20 14:40:30.974 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 2)\n",
      "10-20 14:40:30.976 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:40:30.980 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 34.2 KiB, free 433.9 MiB)\n",
      "10-20 14:40:30.982 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 433.9 MiB)\n",
      "10-20 14:40:30.983 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 95675304fa2d:39707 (size: 15.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:30.983 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:30.984 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:30.984 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:30.985 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:30.986 172.17.0.2:54321      6000   .0 (TID 2)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "10-20 14:40:31.050 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_1_piece0 on 95675304fa2d:39707 in memory (size: 8.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:31.086 172.17.0.2:54321      6000   .0 (TID 2)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 27.37736 ms\n",
      "10-20 14:40:31.094 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on 95675304fa2d:39707 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:31.112 172.17.0.2:54321      6000   .0 (TID 2)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.556207 ms\n",
      "10-20 14:40:31.141 172.17.0.2:54321      6000   .0 (TID 2)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:40:31.174 172.17.0.2:54321      6000   .0 (TID 2)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 25.726272 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:40:31.701 172.17.0.2:54321      6000   .0 (TID 2)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 2.0 (TID 2). 2732 bytes result sent to driver\n",
      "10-20 14:40:31.705 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 720 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:31.706 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:31.706 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.729 s\n",
      "10-20 14:40:31.706 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:40:31.707 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:40:31.707 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 3)\n",
      "10-20 14:40:31.707 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:40:31.707 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:40:31.711 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 434.1 MiB)\n",
      "10-20 14:40:31.714 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 434.1 MiB)\n",
      "10-20 14:40:31.716 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 95675304fa2d:39707 (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:31.717 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:31.718 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:31.721 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:31.723 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:31.724 172.17.0.2:54321      6000   .0 (TID 3)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 3.0 (TID 3)\n",
      "10-20 14:40:31.730 172.17.0.2:54321      6000   .0 (TID 3)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:31.730 172.17.0.2:54321      6000   .0 (TID 3)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:31.732 172.17.0.2:54321      6000   .0 (TID 3)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 3.0 (TID 3). 2648 bytes result sent to driver\n",
      "10-20 14:40:31.737 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 14 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:31.738 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:31.738 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.030 s\n",
      "10-20 14:40:31.738 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:31.738 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "10-20 14:40:31.739 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.766000 s\n",
      "Train split size: 26076\n",
      "10-20 14:40:31.773 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:31.773 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:31.774 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:40:31.842 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 31.405824 ms\n",
      "10-20 14:40:31.847 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 14:40:31.865 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.9 MiB)\n",
      "10-20 14:40:31.866 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 95675304fa2d:39707 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:31.867 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:40:31.879 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:31.918 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_4_piece0 on 95675304fa2d:39707 in memory (size: 15.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:31.929 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:40:31.931 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2\n",
      "10-20 14:40:31.931 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 14:40:31.931 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)\n",
      "10-20 14:40:31.931 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)\n",
      "10-20 14:40:31.931 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 4)\n",
      "10-20 14:40:31.949 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:40:31.952 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 34.2 KiB, free 434.0 MiB)\n",
      "10-20 14:40:31.953 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 433.9 MiB)\n",
      "10-20 14:40:31.954 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 95675304fa2d:39707 (size: 15.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:31.955 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:31.957 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:31.957 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:31.958 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:31.959 172.17.0.2:54321      6000   .0 (TID 4)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 4.0 (TID 4)\n",
      "10-20 14:40:31.967 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on 95675304fa2d:39707 in memory (size: 5.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:31.979 172.17.0.2:54321      6000   .0 (TID 4)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:40:32.013 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_3_piece0 on 95675304fa2d:39707 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:32.305 172.17.0.2:54321      6000   .0 (TID 4)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 4.0 (TID 4). 2689 bytes result sent to driver\n",
      "10-20 14:40:32.306 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 348 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:32.306 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:32.307 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.358 s\n",
      "10-20 14:40:32.307 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:40:32.307 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:40:32.307 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 5)\n",
      "10-20 14:40:32.307 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:40:32.308 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:40:32.311 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.1 KiB, free 434.1 MiB)\n",
      "10-20 14:40:32.322 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 434.1 MiB)\n",
      "10-20 14:40:32.323 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 95675304fa2d:39707 (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:32.333 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:32.334 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:32.334 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:32.335 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:32.336 172.17.0.2:54321      6000   .0 (TID 5)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 5.0 (TID 5)\n",
      "10-20 14:40:32.340 172.17.0.2:54321      6000   .0 (TID 5)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:32.340 172.17.0.2:54321      6000   .0 (TID 5)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:32.341 172.17.0.2:54321      6000   .0 (TID 5)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 5.0 (TID 5). 2648 bytes result sent to driver\n",
      "10-20 14:40:32.342 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:32.342 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:32.343 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.034 s\n",
      "10-20 14:40:32.343 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:32.343 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished\n",
      "10-20 14:40:32.344 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.413894 s\n",
      "Validation split size: 6485\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_df.randomSplit([train_rate, 1-train_rate], seed=seed)\n",
    "print(f'Train split size: {train_df.count()}')\n",
    "print(f'Validation split size: {val_df.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df909d-7075-4529-8600-455e41994ca4",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f42e7b5-1c58-42ce-b120-7180cd5ba25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:40:34.059 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:34.060 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:34.061 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:40:34.132 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 31.058113 ms\n",
      "10-20 14:40:34.217 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 56.432359 ms\n",
      "10-20 14:40:34.222 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 176.1 KiB, free 434.0 MiB)\n",
      "10-20 14:40:34.239 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_8_piece0 on 95675304fa2d:39707 in memory (size: 5.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:34.243 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 434.0 MiB)\n",
      "10-20 14:40:34.243 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 95675304fa2d:39707 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:34.244 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 9 from toPandas at /tmp/ipykernel_5962/3328129577.py:1\n",
      "10-20 14:40:34.245 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:34.263 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on 95675304fa2d:39707 in memory (size: 28.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:34.279 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on 95675304fa2d:39707 in memory (size: 15.1 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:34.297 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: toPandas at /tmp/ipykernel_5962/3328129577.py:1\n",
      "10-20 14:40:34.298 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 24 (toPandas at /tmp/ipykernel_5962/3328129577.py:1) as input to shuffle 3\n",
      "10-20 14:40:34.299 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 3 (toPandas at /tmp/ipykernel_5962/3328129577.py:1) with 200 output partitions\n",
      "10-20 14:40:34.299 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 7 (toPandas at /tmp/ipykernel_5962/3328129577.py:1)\n",
      "10-20 14:40:34.299 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)\n",
      "10-20 14:40:34.299 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 6)\n",
      "10-20 14:40:34.300 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[24] at toPandas at /tmp/ipykernel_5962/3328129577.py:1), which has no missing parents\n",
      "10-20 14:40:34.303 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 40.8 KiB, free 434.2 MiB)\n",
      "10-20 14:40:34.304 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 18.0 KiB, free 434.1 MiB)\n",
      "10-20 14:40:34.305 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 95675304fa2d:39707 (size: 18.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:34.306 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:34.306 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[24] at toPandas at /tmp/ipykernel_5962/3328129577.py:1) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:34.307 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:34.308 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.309 172.17.0.2:54321      6000   .0 (TID 6)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 6.0 (TID 6)\n",
      "10-20 14:40:34.333 172.17.0.2:54321      6000   .0 (TID 6)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.085186 ms\n",
      "10-20 14:40:34.341 172.17.0.2:54321      6000   .0 (TID 6)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 4.565444 ms\n",
      "10-20 14:40:34.350 172.17.0.2:54321      6000   .0 (TID 6)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.06983 ms\n",
      "10-20 14:40:34.362 172.17.0.2:54321      6000   .0 (TID 6)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 7.871249 ms\n",
      "10-20 14:40:34.370 172.17.0.2:54321      6000   .0 (TID 6)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n",
      "10-20 14:40:34.781 172.17.0.2:54321      6000   .0 (TID 6)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 6.0 (TID 6). 2934 bytes result sent to driver\n",
      "10-20 14:40:34.782 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 474 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:34.782 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:34.783 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 6 (toPandas at /tmp/ipykernel_5962/3328129577.py:1) finished in 0.483 s\n",
      "10-20 14:40:34.783 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:40:34.783 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:40:34.783 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 7)\n",
      "10-20 14:40:34.783 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:40:34.783 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[27] at toPandas at /tmp/ipykernel_5962/3328129577.py:1), which has no missing parents\n",
      "10-20 14:40:34.795 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 34.3 KiB, free 434.1 MiB)\n",
      "10-20 14:40:34.808 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 434.1 MiB)\n",
      "10-20 14:40:34.809 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 95675304fa2d:39707 (size: 17.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:34.810 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:34.811 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 200 missing tasks from ResultStage 7 (MapPartitionsRDD[27] at toPandas at /tmp/ipykernel_5962/3328129577.py:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "10-20 14:40:34.811 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 7.0 with 200 tasks resource profile 0\n",
      "10-20 14:40:34.813 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 43.0 in stage 7.0 (TID 7) (95675304fa2d, executor driver, partition 43, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.813 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 191.0 in stage 7.0 (TID 8) (95675304fa2d, executor driver, partition 191, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.814 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 9) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.814 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 7.0 (TID 10) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.815 172.17.0.2:54321      6000   .0 (TID 7)  INFO org.apache.spark.executor.Executor: Running task 43.0 in stage 7.0 (TID 7)\n",
      "10-20 14:40:34.819 172.17.0.2:54321      6000   .0 (TID 8)  INFO org.apache.spark.executor.Executor: Running task 191.0 in stage 7.0 (TID 8)\n",
      "10-20 14:40:34.820 172.17.0.2:54321      6000   0 (TID 10)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 7.0 (TID 10)\n",
      "10-20 14:40:34.821 172.17.0.2:54321      6000   .0 (TID 9)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 7.0 (TID 9)\n",
      "10-20 14:40:34.821 172.17.0.2:54321      6000   .0 (TID 7)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.821 172.17.0.2:54321      6000   .0 (TID 7)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.837 172.17.0.2:54321      6000   .0 (TID 8)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.839 172.17.0.2:54321      6000   .0 (TID 9)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.839 172.17.0.2:54321      6000   .0 (TID 9)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.839 172.17.0.2:54321      6000   .0 (TID 8)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:40:34.845 172.17.0.2:54321      6000   .0 (TID 7)  INFO org.apache.spark.executor.Executor: Finished task 43.0 in stage 7.0 (TID 7). 3853 bytes result sent to driver\n",
      "10-20 14:40:34.845 172.17.0.2:54321      6000   0 (TID 10)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.845 172.17.0.2:54321      6000   0 (TID 10)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms\n",
      "10-20 14:40:34.846 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 7.0 (TID 11) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.846 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 43.0 in stage 7.0 (TID 7) in 33 ms on 95675304fa2d (executor driver) (1/200)\n",
      "10-20 14:40:34.848 172.17.0.2:54321      6000   .0 (TID 9)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 7.0 (TID 9). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.850 172.17.0.2:54321      6000   .0 (TID 8)  INFO org.apache.spark.executor.Executor: Finished task 191.0 in stage 7.0 (TID 8). 3849 bytes result sent to driver\n",
      "10-20 14:40:34.851 172.17.0.2:54321      6000   0 (TID 11)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 7.0 (TID 11)\n",
      "10-20 14:40:34.851 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 7.0 (TID 12) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.852 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 9) in 38 ms on 95675304fa2d (executor driver) (2/200)\n",
      "10-20 14:40:34.852 172.17.0.2:54321      6000   0 (TID 10)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 7.0 (TID 10). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.853 172.17.0.2:54321      6000   0 (TID 12)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 7.0 (TID 12)\n",
      "10-20 14:40:34.857 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 4.0 in stage 7.0 (TID 13) (95675304fa2d, executor driver, partition 4, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.858 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 7.0 (TID 10) in 44 ms on 95675304fa2d (executor driver) (3/200)\n",
      "10-20 14:40:34.858 172.17.0.2:54321      6000   0 (TID 13)  INFO org.apache.spark.executor.Executor: Running task 4.0 in stage 7.0 (TID 13)\n",
      "10-20 14:40:34.858 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 5.0 in stage 7.0 (TID 14) (95675304fa2d, executor driver, partition 5, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.859 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 191.0 in stage 7.0 (TID 8) in 46 ms on 95675304fa2d (executor driver) (4/200)\n",
      "10-20 14:40:34.860 172.17.0.2:54321      6000   0 (TID 14)  INFO org.apache.spark.executor.Executor: Running task 5.0 in stage 7.0 (TID 14)\n",
      "10-20 14:40:34.865 172.17.0.2:54321      6000   0 (TID 11)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.867 172.17.0.2:54321      6000   0 (TID 14)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.868 172.17.0.2:54321      6000   0 (TID 14)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.867 172.17.0.2:54321      6000   0 (TID 12)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.868 172.17.0.2:54321      6000   0 (TID 12)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:40:34.867 172.17.0.2:54321      6000   0 (TID 13)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.869 172.17.0.2:54321      6000   0 (TID 13)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:40:34.868 172.17.0.2:54321      6000   0 (TID 11)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 14:40:34.879 172.17.0.2:54321      6000   0 (TID 11)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 7.0 (TID 11). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.879 172.17.0.2:54321      6000   0 (TID 12)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 7.0 (TID 12). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.879 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 6.0 in stage 7.0 (TID 15) (95675304fa2d, executor driver, partition 6, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.880 172.17.0.2:54321      6000   0 (TID 15)  INFO org.apache.spark.executor.Executor: Running task 6.0 in stage 7.0 (TID 15)\n",
      "10-20 14:40:34.880 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 7.0 in stage 7.0 (TID 16) (95675304fa2d, executor driver, partition 7, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.881 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 7.0 (TID 12) in 30 ms on 95675304fa2d (executor driver) (5/200)\n",
      "10-20 14:40:34.881 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 7.0 (TID 11) in 36 ms on 95675304fa2d (executor driver) (6/200)\n",
      "10-20 14:40:34.882 172.17.0.2:54321      6000   0 (TID 16)  INFO org.apache.spark.executor.Executor: Running task 7.0 in stage 7.0 (TID 16)\n",
      "10-20 14:40:34.885 172.17.0.2:54321      6000   0 (TID 13)  INFO org.apache.spark.executor.Executor: Finished task 4.0 in stage 7.0 (TID 13). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.886 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 8.0 in stage 7.0 (TID 17) (95675304fa2d, executor driver, partition 8, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.886 172.17.0.2:54321      6000   0 (TID 17)  INFO org.apache.spark.executor.Executor: Running task 8.0 in stage 7.0 (TID 17)\n",
      "10-20 14:40:34.886 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 4.0 in stage 7.0 (TID 13) in 29 ms on 95675304fa2d (executor driver) (7/200)\n",
      "10-20 14:40:34.887 172.17.0.2:54321      6000   0 (TID 14)  INFO org.apache.spark.executor.Executor: Finished task 5.0 in stage 7.0 (TID 14). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.888 172.17.0.2:54321      6000   0 (TID 16)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.888 172.17.0.2:54321      6000   0 (TID 15)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.889 172.17.0.2:54321      6000   0 (TID 15)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.894 172.17.0.2:54321      6000   0 (TID 17)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.894 172.17.0.2:54321      6000   0 (TID 17)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.895 172.17.0.2:54321      6000   0 (TID 15)  INFO org.apache.spark.executor.Executor: Finished task 6.0 in stage 7.0 (TID 15). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.898 172.17.0.2:54321      6000   0 (TID 17)  INFO org.apache.spark.executor.Executor: Finished task 8.0 in stage 7.0 (TID 17). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.898 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 9.0 in stage 7.0 (TID 18) (95675304fa2d, executor driver, partition 9, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.899 172.17.0.2:54321      6000   0 (TID 18)  INFO org.apache.spark.executor.Executor: Running task 9.0 in stage 7.0 (TID 18)\n",
      "10-20 14:40:34.899 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 5.0 in stage 7.0 (TID 14) in 41 ms on 95675304fa2d (executor driver) (8/200)\n",
      "10-20 14:40:34.899 172.17.0.2:54321      6000   0 (TID 16)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms\n",
      "10-20 14:40:34.902 172.17.0.2:54321      6000   0 (TID 16)  INFO org.apache.spark.executor.Executor: Finished task 7.0 in stage 7.0 (TID 16). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.903 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 10.0 in stage 7.0 (TID 19) (95675304fa2d, executor driver, partition 10, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.903 172.17.0.2:54321      6000   0 (TID 19)  INFO org.apache.spark.executor.Executor: Running task 10.0 in stage 7.0 (TID 19)\n",
      "10-20 14:40:34.903 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 11.0 in stage 7.0 (TID 20) (95675304fa2d, executor driver, partition 11, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.904 172.17.0.2:54321      6000   0 (TID 20)  INFO org.apache.spark.executor.Executor: Running task 11.0 in stage 7.0 (TID 20)\n",
      "10-20 14:40:34.904 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 12.0 in stage 7.0 (TID 21) (95675304fa2d, executor driver, partition 12, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.904 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 7.0 in stage 7.0 (TID 16) in 24 ms on 95675304fa2d (executor driver) (9/200)\n",
      "10-20 14:40:34.905 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 8.0 in stage 7.0 (TID 17) in 19 ms on 95675304fa2d (executor driver) (10/200)\n",
      "10-20 14:40:34.905 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 6.0 in stage 7.0 (TID 15) in 26 ms on 95675304fa2d (executor driver) (11/200)\n",
      "10-20 14:40:34.910 172.17.0.2:54321      6000   0 (TID 18)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.910 172.17.0.2:54321      6000   0 (TID 18)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.910 172.17.0.2:54321      6000   0 (TID 21)  INFO org.apache.spark.executor.Executor: Running task 12.0 in stage 7.0 (TID 21)\n",
      "10-20 14:40:34.912 172.17.0.2:54321      6000   0 (TID 20)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.913 172.17.0.2:54321      6000   0 (TID 20)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:40:34.913 172.17.0.2:54321      6000   0 (TID 19)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.914 172.17.0.2:54321      6000   0 (TID 19)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.916 172.17.0.2:54321      6000   0 (TID 18)  INFO org.apache.spark.executor.Executor: Finished task 9.0 in stage 7.0 (TID 18). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.917 172.17.0.2:54321      6000   0 (TID 21)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.917 172.17.0.2:54321      6000   0 (TID 21)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.917 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 13.0 in stage 7.0 (TID 22) (95675304fa2d, executor driver, partition 13, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.917 172.17.0.2:54321      6000   0 (TID 22)  INFO org.apache.spark.executor.Executor: Running task 13.0 in stage 7.0 (TID 22)\n",
      "10-20 14:40:34.918 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 9.0 in stage 7.0 (TID 18) in 20 ms on 95675304fa2d (executor driver) (12/200)\n",
      "10-20 14:40:34.922 172.17.0.2:54321      6000   0 (TID 20)  INFO org.apache.spark.executor.Executor: Finished task 11.0 in stage 7.0 (TID 20). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.922 172.17.0.2:54321      6000   0 (TID 21)  INFO org.apache.spark.executor.Executor: Finished task 12.0 in stage 7.0 (TID 21). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.930 172.17.0.2:54321      6000   0 (TID 22)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.930 172.17.0.2:54321      6000   0 (TID 22)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.931 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 14.0 in stage 7.0 (TID 23) (95675304fa2d, executor driver, partition 14, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.931 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 11.0 in stage 7.0 (TID 20) in 28 ms on 95675304fa2d (executor driver) (13/200)\n",
      "10-20 14:40:34.932 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 15.0 in stage 7.0 (TID 24) (95675304fa2d, executor driver, partition 15, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.933 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 12.0 in stage 7.0 (TID 21) in 29 ms on 95675304fa2d (executor driver) (14/200)\n",
      "10-20 14:40:34.933 172.17.0.2:54321      6000   0 (TID 24)  INFO org.apache.spark.executor.Executor: Running task 15.0 in stage 7.0 (TID 24)\n",
      "10-20 14:40:34.929 172.17.0.2:54321      6000   0 (TID 19)  INFO org.apache.spark.executor.Executor: Finished task 10.0 in stage 7.0 (TID 19). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.936 172.17.0.2:54321      6000   0 (TID 22)  INFO org.apache.spark.executor.Executor: Finished task 13.0 in stage 7.0 (TID 22). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.936 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 16.0 in stage 7.0 (TID 25) (95675304fa2d, executor driver, partition 16, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.936 172.17.0.2:54321      6000   0 (TID 23)  INFO org.apache.spark.executor.Executor: Running task 14.0 in stage 7.0 (TID 23)\n",
      "10-20 14:40:34.936 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 10.0 in stage 7.0 (TID 19) in 34 ms on 95675304fa2d (executor driver) (15/200)\n",
      "10-20 14:40:34.937 172.17.0.2:54321      6000   0 (TID 25)  INFO org.apache.spark.executor.Executor: Running task 16.0 in stage 7.0 (TID 25)\n",
      "10-20 14:40:34.942 172.17.0.2:54321      6000   0 (TID 24)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.948 172.17.0.2:54321      6000   0 (TID 23)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.951 172.17.0.2:54321      6000   0 (TID 23)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 14:40:34.945 172.17.0.2:54321      6000   0 (TID 25)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.942 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 17.0 in stage 7.0 (TID 26) (95675304fa2d, executor driver, partition 17, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.952 172.17.0.2:54321      6000   0 (TID 25)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "10-20 14:40:34.951 172.17.0.2:54321      6000   0 (TID 24)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms\n",
      "10-20 14:40:34.953 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 13.0 in stage 7.0 (TID 22) in 36 ms on 95675304fa2d (executor driver) (16/200)\n",
      "10-20 14:40:34.954 172.17.0.2:54321      6000   0 (TID 26)  INFO org.apache.spark.executor.Executor: Running task 17.0 in stage 7.0 (TID 26)\n",
      "10-20 14:40:34.956 172.17.0.2:54321      6000   0 (TID 25)  INFO org.apache.spark.executor.Executor: Finished task 16.0 in stage 7.0 (TID 25). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.956 172.17.0.2:54321      6000   0 (TID 24)  INFO org.apache.spark.executor.Executor: Finished task 15.0 in stage 7.0 (TID 24). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.957 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 18.0 in stage 7.0 (TID 27) (95675304fa2d, executor driver, partition 18, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.957 172.17.0.2:54321      6000   0 (TID 27)  INFO org.apache.spark.executor.Executor: Running task 18.0 in stage 7.0 (TID 27)\n",
      "10-20 14:40:34.958 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 15.0 in stage 7.0 (TID 24) in 26 ms on 95675304fa2d (executor driver) (17/200)\n",
      "10-20 14:40:34.960 172.17.0.2:54321      6000   0 (TID 26)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.960 172.17.0.2:54321      6000   0 (TID 26)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.962 172.17.0.2:54321      6000   0 (TID 27)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.968 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 19.0 in stage 7.0 (TID 28) (95675304fa2d, executor driver, partition 19, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.968 172.17.0.2:54321      6000   0 (TID 27)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms\n",
      "10-20 14:40:34.969 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 16.0 in stage 7.0 (TID 25) in 33 ms on 95675304fa2d (executor driver) (18/200)\n",
      "10-20 14:40:34.970 172.17.0.2:54321      6000   0 (TID 28)  INFO org.apache.spark.executor.Executor: Running task 19.0 in stage 7.0 (TID 28)\n",
      "10-20 14:40:34.976 172.17.0.2:54321      6000   0 (TID 27)  INFO org.apache.spark.executor.Executor: Finished task 18.0 in stage 7.0 (TID 27). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.979 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 20.0 in stage 7.0 (TID 29) (95675304fa2d, executor driver, partition 20, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.979 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 18.0 in stage 7.0 (TID 27) in 22 ms on 95675304fa2d (executor driver) (19/200)\n",
      "10-20 14:40:34.980 172.17.0.2:54321      6000   0 (TID 29)  INFO org.apache.spark.executor.Executor: Running task 20.0 in stage 7.0 (TID 29)\n",
      "10-20 14:40:34.981 172.17.0.2:54321      6000   0 (TID 28)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.981 172.17.0.2:54321      6000   0 (TID 28)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.985 172.17.0.2:54321      6000   0 (TID 29)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:34.985 172.17.0.2:54321      6000   0 (TID 29)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:34.986 172.17.0.2:54321      6000   0 (TID 26)  INFO org.apache.spark.executor.Executor: Finished task 17.0 in stage 7.0 (TID 26). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.987 172.17.0.2:54321      6000   0 (TID 28)  INFO org.apache.spark.executor.Executor: Finished task 19.0 in stage 7.0 (TID 28). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.987 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 21.0 in stage 7.0 (TID 30) (95675304fa2d, executor driver, partition 21, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.988 172.17.0.2:54321      6000   0 (TID 30)  INFO org.apache.spark.executor.Executor: Running task 21.0 in stage 7.0 (TID 30)\n",
      "10-20 14:40:34.988 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 22.0 in stage 7.0 (TID 31) (95675304fa2d, executor driver, partition 22, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.989 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 17.0 in stage 7.0 (TID 26) in 47 ms on 95675304fa2d (executor driver) (20/200)\n",
      "10-20 14:40:34.989 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 19.0 in stage 7.0 (TID 28) in 22 ms on 95675304fa2d (executor driver) (21/200)\n",
      "10-20 14:40:34.990 172.17.0.2:54321      6000   0 (TID 31)  INFO org.apache.spark.executor.Executor: Running task 22.0 in stage 7.0 (TID 31)\n",
      "10-20 14:40:34.996 172.17.0.2:54321      6000   0 (TID 29)  INFO org.apache.spark.executor.Executor: Finished task 20.0 in stage 7.0 (TID 29). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.997 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 23.0 in stage 7.0 (TID 32) (95675304fa2d, executor driver, partition 23, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:34.997 172.17.0.2:54321      6000   0 (TID 23)  INFO org.apache.spark.executor.Executor: Finished task 14.0 in stage 7.0 (TID 23). 3832 bytes result sent to driver\n",
      "10-20 14:40:34.998 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 20.0 in stage 7.0 (TID 29) in 19 ms on 95675304fa2d (executor driver) (22/200)\n",
      "10-20 14:40:34.998 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 14.0 in stage 7.0 (TID 23) in 67 ms on 95675304fa2d (executor driver) (23/200)\n",
      "10-20 14:40:35.000 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 24.0 in stage 7.0 (TID 33) (95675304fa2d, executor driver, partition 24, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.001 172.17.0.2:54321      6000   0 (TID 33)  INFO org.apache.spark.executor.Executor: Running task 24.0 in stage 7.0 (TID 33)\n",
      "10-20 14:40:35.002 172.17.0.2:54321      6000   0 (TID 32)  INFO org.apache.spark.executor.Executor: Running task 23.0 in stage 7.0 (TID 32)\n",
      "10-20 14:40:35.006 172.17.0.2:54321      6000   0 (TID 32)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.006 172.17.0.2:54321      6000   0 (TID 32)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.010 172.17.0.2:54321      6000   0 (TID 32)  INFO org.apache.spark.executor.Executor: Finished task 23.0 in stage 7.0 (TID 32). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.011 172.17.0.2:54321      6000   0 (TID 31)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.011 172.17.0.2:54321      6000   0 (TID 31)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.012 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 25.0 in stage 7.0 (TID 34) (95675304fa2d, executor driver, partition 25, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.013 172.17.0.2:54321      6000   0 (TID 34)  INFO org.apache.spark.executor.Executor: Running task 25.0 in stage 7.0 (TID 34)\n",
      "10-20 14:40:35.013 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 23.0 in stage 7.0 (TID 32) in 16 ms on 95675304fa2d (executor driver) (24/200)\n",
      "10-20 14:40:35.015 172.17.0.2:54321      6000   0 (TID 30)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.015 172.17.0.2:54321      6000   0 (TID 30)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.015 172.17.0.2:54321      6000   0 (TID 31)  INFO org.apache.spark.executor.Executor: Finished task 22.0 in stage 7.0 (TID 31). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.016 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 26.0 in stage 7.0 (TID 35) (95675304fa2d, executor driver, partition 26, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.016 172.17.0.2:54321      6000   0 (TID 35)  INFO org.apache.spark.executor.Executor: Running task 26.0 in stage 7.0 (TID 35)\n",
      "10-20 14:40:35.016 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 22.0 in stage 7.0 (TID 31) in 28 ms on 95675304fa2d (executor driver) (25/200)\n",
      "10-20 14:40:35.020 172.17.0.2:54321      6000   0 (TID 30)  INFO org.apache.spark.executor.Executor: Finished task 21.0 in stage 7.0 (TID 30). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.021 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 27.0 in stage 7.0 (TID 36) (95675304fa2d, executor driver, partition 27, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.021 172.17.0.2:54321      6000   0 (TID 35)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.022 172.17.0.2:54321      6000   0 (TID 35)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.022 172.17.0.2:54321      6000   0 (TID 33)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.022 172.17.0.2:54321      6000   0 (TID 33)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.022 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 21.0 in stage 7.0 (TID 30) in 35 ms on 95675304fa2d (executor driver) (26/200)\n",
      "10-20 14:40:35.022 172.17.0.2:54321      6000   0 (TID 36)  INFO org.apache.spark.executor.Executor: Running task 27.0 in stage 7.0 (TID 36)\n",
      "10-20 14:40:35.042 172.17.0.2:54321      6000   0 (TID 35)  INFO org.apache.spark.executor.Executor: Finished task 26.0 in stage 7.0 (TID 35). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.043 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 28.0 in stage 7.0 (TID 37) (95675304fa2d, executor driver, partition 28, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.043 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 26.0 in stage 7.0 (TID 35) in 27 ms on 95675304fa2d (executor driver) (27/200)\n",
      "10-20 14:40:35.049 172.17.0.2:54321      6000   0 (TID 37)  INFO org.apache.spark.executor.Executor: Running task 28.0 in stage 7.0 (TID 37)\n",
      "10-20 14:40:35.053 172.17.0.2:54321      6000   0 (TID 33)  INFO org.apache.spark.executor.Executor: Finished task 24.0 in stage 7.0 (TID 33). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.054 172.17.0.2:54321      6000   0 (TID 37)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.054 172.17.0.2:54321      6000   0 (TID 37)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.054 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 29.0 in stage 7.0 (TID 38) (95675304fa2d, executor driver, partition 29, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.055 172.17.0.2:54321      6000   0 (TID 38)  INFO org.apache.spark.executor.Executor: Running task 29.0 in stage 7.0 (TID 38)\n",
      "10-20 14:40:35.055 172.17.0.2:54321      6000   0 (TID 36)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.055 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 24.0 in stage 7.0 (TID 33) in 55 ms on 95675304fa2d (executor driver) (28/200)\n",
      "10-20 14:40:35.055 172.17.0.2:54321      6000   0 (TID 36)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.057 172.17.0.2:54321      6000   0 (TID 34)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.059 172.17.0.2:54321      6000   0 (TID 34)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:40:35.061 172.17.0.2:54321      6000   0 (TID 38)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.061 172.17.0.2:54321      6000   0 (TID 38)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.067 172.17.0.2:54321      6000   0 (TID 37)  INFO org.apache.spark.executor.Executor: Finished task 28.0 in stage 7.0 (TID 37). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.070 172.17.0.2:54321      6000   0 (TID 34)  INFO org.apache.spark.executor.Executor: Finished task 25.0 in stage 7.0 (TID 34). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.070 172.17.0.2:54321      6000   0 (TID 38)  INFO org.apache.spark.executor.Executor: Finished task 29.0 in stage 7.0 (TID 38). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.073 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 30.0 in stage 7.0 (TID 39) (95675304fa2d, executor driver, partition 30, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.073 172.17.0.2:54321      6000   0 (TID 39)  INFO org.apache.spark.executor.Executor: Running task 30.0 in stage 7.0 (TID 39)\n",
      "10-20 14:40:35.074 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 31.0 in stage 7.0 (TID 40) (95675304fa2d, executor driver, partition 31, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.074 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 32.0 in stage 7.0 (TID 41) (95675304fa2d, executor driver, partition 32, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.075 172.17.0.2:54321      6000   0 (TID 41)  INFO org.apache.spark.executor.Executor: Running task 32.0 in stage 7.0 (TID 41)\n",
      "10-20 14:40:35.075 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 29.0 in stage 7.0 (TID 38) in 21 ms on 95675304fa2d (executor driver) (29/200)\n",
      "10-20 14:40:35.075 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 25.0 in stage 7.0 (TID 34) in 64 ms on 95675304fa2d (executor driver) (30/200)\n",
      "10-20 14:40:35.076 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 28.0 in stage 7.0 (TID 37) in 34 ms on 95675304fa2d (executor driver) (31/200)\n",
      "10-20 14:40:35.076 172.17.0.2:54321      6000   0 (TID 40)  INFO org.apache.spark.executor.Executor: Running task 31.0 in stage 7.0 (TID 40)\n",
      "10-20 14:40:35.082 172.17.0.2:54321      6000   0 (TID 41)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.082 172.17.0.2:54321      6000   0 (TID 41)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.085 172.17.0.2:54321      6000   0 (TID 41)  INFO org.apache.spark.executor.Executor: Finished task 32.0 in stage 7.0 (TID 41). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.089 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 33.0 in stage 7.0 (TID 42) (95675304fa2d, executor driver, partition 33, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.089 172.17.0.2:54321      6000   0 (TID 42)  INFO org.apache.spark.executor.Executor: Running task 33.0 in stage 7.0 (TID 42)\n",
      "10-20 14:40:35.089 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 32.0 in stage 7.0 (TID 41) in 15 ms on 95675304fa2d (executor driver) (32/200)\n",
      "10-20 14:40:35.082 172.17.0.2:54321      6000   0 (TID 40)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.089 172.17.0.2:54321      6000   0 (TID 40)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "10-20 14:40:35.093 172.17.0.2:54321      6000   0 (TID 40)  INFO org.apache.spark.executor.Executor: Finished task 31.0 in stage 7.0 (TID 40). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.089 172.17.0.2:54321      6000   0 (TID 39)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.087 172.17.0.2:54321      6000   0 (TID 36)  INFO org.apache.spark.executor.Executor: Finished task 27.0 in stage 7.0 (TID 36). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.096 172.17.0.2:54321      6000   0 (TID 39)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "10-20 14:40:35.096 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 34.0 in stage 7.0 (TID 43) (95675304fa2d, executor driver, partition 34, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.097 172.17.0.2:54321      6000   0 (TID 43)  INFO org.apache.spark.executor.Executor: Running task 34.0 in stage 7.0 (TID 43)\n",
      "10-20 14:40:35.098 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 31.0 in stage 7.0 (TID 40) in 24 ms on 95675304fa2d (executor driver) (33/200)\n",
      "10-20 14:40:35.094 172.17.0.2:54321      6000   0 (TID 42)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.098 172.17.0.2:54321      6000   0 (TID 42)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:40:35.100 172.17.0.2:54321      6000   0 (TID 39)  INFO org.apache.spark.executor.Executor: Finished task 30.0 in stage 7.0 (TID 39). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.101 172.17.0.2:54321      6000   0 (TID 42)  INFO org.apache.spark.executor.Executor: Finished task 33.0 in stage 7.0 (TID 42). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.102 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 35.0 in stage 7.0 (TID 44) (95675304fa2d, executor driver, partition 35, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.103 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 36.0 in stage 7.0 (TID 45) (95675304fa2d, executor driver, partition 36, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.103 172.17.0.2:54321      6000   0 (TID 44)  INFO org.apache.spark.executor.Executor: Running task 35.0 in stage 7.0 (TID 44)\n",
      "10-20 14:40:35.103 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 37.0 in stage 7.0 (TID 46) (95675304fa2d, executor driver, partition 37, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.104 172.17.0.2:54321      6000   0 (TID 46)  INFO org.apache.spark.executor.Executor: Running task 37.0 in stage 7.0 (TID 46)\n",
      "10-20 14:40:35.104 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 30.0 in stage 7.0 (TID 39) in 31 ms on 95675304fa2d (executor driver) (34/200)\n",
      "10-20 14:40:35.104 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 27.0 in stage 7.0 (TID 36) in 83 ms on 95675304fa2d (executor driver) (35/200)\n",
      "10-20 14:40:35.105 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 33.0 in stage 7.0 (TID 42) in 17 ms on 95675304fa2d (executor driver) (36/200)\n",
      "10-20 14:40:35.106 172.17.0.2:54321      6000   0 (TID 43)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.106 172.17.0.2:54321      6000   0 (TID 43)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.107 172.17.0.2:54321      6000   0 (TID 44)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.108 172.17.0.2:54321      6000   0 (TID 44)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.109 172.17.0.2:54321      6000   0 (TID 43)  INFO org.apache.spark.executor.Executor: Finished task 34.0 in stage 7.0 (TID 43). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.110 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 38.0 in stage 7.0 (TID 47) (95675304fa2d, executor driver, partition 38, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.112 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 34.0 in stage 7.0 (TID 43) in 16 ms on 95675304fa2d (executor driver) (37/200)\n",
      "10-20 14:40:35.113 172.17.0.2:54321      6000   0 (TID 45)  INFO org.apache.spark.executor.Executor: Running task 36.0 in stage 7.0 (TID 45)\n",
      "10-20 14:40:35.113 172.17.0.2:54321      6000   0 (TID 44)  INFO org.apache.spark.executor.Executor: Finished task 35.0 in stage 7.0 (TID 44). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.113 172.17.0.2:54321      6000   0 (TID 47)  INFO org.apache.spark.executor.Executor: Running task 38.0 in stage 7.0 (TID 47)\n",
      "10-20 14:40:35.114 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 39.0 in stage 7.0 (TID 48) (95675304fa2d, executor driver, partition 39, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.114 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 35.0 in stage 7.0 (TID 44) in 12 ms on 95675304fa2d (executor driver) (38/200)\n",
      "10-20 14:40:35.116 172.17.0.2:54321      6000   0 (TID 46)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.116 172.17.0.2:54321      6000   0 (TID 46)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.116 172.17.0.2:54321      6000   0 (TID 48)  INFO org.apache.spark.executor.Executor: Running task 39.0 in stage 7.0 (TID 48)\n",
      "10-20 14:40:35.117 172.17.0.2:54321      6000   0 (TID 47)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.117 172.17.0.2:54321      6000   0 (TID 47)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.119 172.17.0.2:54321      6000   0 (TID 46)  INFO org.apache.spark.executor.Executor: Finished task 37.0 in stage 7.0 (TID 46). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.120 172.17.0.2:54321      6000   0 (TID 47)  INFO org.apache.spark.executor.Executor: Finished task 38.0 in stage 7.0 (TID 47). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.120 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 40.0 in stage 7.0 (TID 49) (95675304fa2d, executor driver, partition 40, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.120 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 37.0 in stage 7.0 (TID 46) in 17 ms on 95675304fa2d (executor driver) (39/200)\n",
      "10-20 14:40:35.121 172.17.0.2:54321      6000   0 (TID 49)  INFO org.apache.spark.executor.Executor: Running task 40.0 in stage 7.0 (TID 49)\n",
      "10-20 14:40:35.125 172.17.0.2:54321      6000   0 (TID 49)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.125 172.17.0.2:54321      6000   0 (TID 49)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.126 172.17.0.2:54321      6000   0 (TID 48)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.126 172.17.0.2:54321      6000   0 (TID 48)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.129 172.17.0.2:54321      6000   0 (TID 49)  INFO org.apache.spark.executor.Executor: Finished task 40.0 in stage 7.0 (TID 49). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.129 172.17.0.2:54321      6000   0 (TID 45)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.129 172.17.0.2:54321      6000   0 (TID 45)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.130 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 41.0 in stage 7.0 (TID 50) (95675304fa2d, executor driver, partition 41, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.130 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 40.0 in stage 7.0 (TID 49) in 10 ms on 95675304fa2d (executor driver) (40/200)\n",
      "10-20 14:40:35.133 172.17.0.2:54321      6000   0 (TID 45)  INFO org.apache.spark.executor.Executor: Finished task 36.0 in stage 7.0 (TID 45). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.133 172.17.0.2:54321      6000   0 (TID 48)  INFO org.apache.spark.executor.Executor: Finished task 39.0 in stage 7.0 (TID 48). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.135 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 42.0 in stage 7.0 (TID 51) (95675304fa2d, executor driver, partition 42, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.137 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 38.0 in stage 7.0 (TID 47) in 27 ms on 95675304fa2d (executor driver) (41/200)\n",
      "10-20 14:40:35.138 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 44.0 in stage 7.0 (TID 52) (95675304fa2d, executor driver, partition 44, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.138 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 36.0 in stage 7.0 (TID 45) in 35 ms on 95675304fa2d (executor driver) (42/200)\n",
      "10-20 14:40:35.139 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 45.0 in stage 7.0 (TID 53) (95675304fa2d, executor driver, partition 45, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.139 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 39.0 in stage 7.0 (TID 48) in 25 ms on 95675304fa2d (executor driver) (43/200)\n",
      "10-20 14:40:35.140 172.17.0.2:54321      6000   0 (TID 53)  INFO org.apache.spark.executor.Executor: Running task 45.0 in stage 7.0 (TID 53)\n",
      "10-20 14:40:35.143 172.17.0.2:54321      6000   0 (TID 53)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.144 172.17.0.2:54321      6000   0 (TID 53)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.144 172.17.0.2:54321      6000   0 (TID 52)  INFO org.apache.spark.executor.Executor: Running task 44.0 in stage 7.0 (TID 52)\n",
      "10-20 14:40:35.144 172.17.0.2:54321      6000   0 (TID 51)  INFO org.apache.spark.executor.Executor: Running task 42.0 in stage 7.0 (TID 51)\n",
      "10-20 14:40:35.148 172.17.0.2:54321      6000   0 (TID 51)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.148 172.17.0.2:54321      6000   0 (TID 51)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.151 172.17.0.2:54321      6000   0 (TID 50)  INFO org.apache.spark.executor.Executor: Running task 41.0 in stage 7.0 (TID 50)\n",
      "10-20 14:40:35.154 172.17.0.2:54321      6000   0 (TID 50)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.154 172.17.0.2:54321      6000   0 (TID 50)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.157 172.17.0.2:54321      6000   0 (TID 53)  INFO org.apache.spark.executor.Executor: Finished task 45.0 in stage 7.0 (TID 53). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.158 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 46.0 in stage 7.0 (TID 54) (95675304fa2d, executor driver, partition 46, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.159 172.17.0.2:54321      6000   0 (TID 54)  INFO org.apache.spark.executor.Executor: Running task 46.0 in stage 7.0 (TID 54)\n",
      "10-20 14:40:35.159 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 45.0 in stage 7.0 (TID 53) in 20 ms on 95675304fa2d (executor driver) (44/200)\n",
      "10-20 14:40:35.160 172.17.0.2:54321      6000   0 (TID 52)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.160 172.17.0.2:54321      6000   0 (TID 52)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.165 172.17.0.2:54321      6000   0 (TID 51)  INFO org.apache.spark.executor.Executor: Finished task 42.0 in stage 7.0 (TID 51). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.165 172.17.0.2:54321      6000   0 (TID 54)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.166 172.17.0.2:54321      6000   0 (TID 54)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:40:35.167 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 47.0 in stage 7.0 (TID 55) (95675304fa2d, executor driver, partition 47, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.167 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 42.0 in stage 7.0 (TID 51) in 32 ms on 95675304fa2d (executor driver) (45/200)\n",
      "10-20 14:40:35.169 172.17.0.2:54321      6000   0 (TID 52)  INFO org.apache.spark.executor.Executor: Finished task 44.0 in stage 7.0 (TID 52). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.170 172.17.0.2:54321      6000   0 (TID 50)  INFO org.apache.spark.executor.Executor: Finished task 41.0 in stage 7.0 (TID 50). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.170 172.17.0.2:54321      6000   0 (TID 55)  INFO org.apache.spark.executor.Executor: Running task 47.0 in stage 7.0 (TID 55)\n",
      "10-20 14:40:35.170 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 48.0 in stage 7.0 (TID 56) (95675304fa2d, executor driver, partition 48, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.172 172.17.0.2:54321      6000   0 (TID 54)  INFO org.apache.spark.executor.Executor: Finished task 46.0 in stage 7.0 (TID 54). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.172 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 49.0 in stage 7.0 (TID 57) (95675304fa2d, executor driver, partition 49, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.173 172.17.0.2:54321      6000   0 (TID 57)  INFO org.apache.spark.executor.Executor: Running task 49.0 in stage 7.0 (TID 57)\n",
      "10-20 14:40:35.173 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 50.0 in stage 7.0 (TID 58) (95675304fa2d, executor driver, partition 50, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.173 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 41.0 in stage 7.0 (TID 50) in 44 ms on 95675304fa2d (executor driver) (46/200)\n",
      "10-20 14:40:35.174 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 44.0 in stage 7.0 (TID 52) in 37 ms on 95675304fa2d (executor driver) (47/200)\n",
      "10-20 14:40:35.174 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 46.0 in stage 7.0 (TID 54) in 16 ms on 95675304fa2d (executor driver) (48/200)\n",
      "10-20 14:40:35.174 172.17.0.2:54321      6000   0 (TID 58)  INFO org.apache.spark.executor.Executor: Running task 50.0 in stage 7.0 (TID 58)\n",
      "10-20 14:40:35.175 172.17.0.2:54321      6000   0 (TID 56)  INFO org.apache.spark.executor.Executor: Running task 48.0 in stage 7.0 (TID 56)\n",
      "10-20 14:40:35.180 172.17.0.2:54321      6000   0 (TID 57)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.180 172.17.0.2:54321      6000   0 (TID 57)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.181 172.17.0.2:54321      6000   0 (TID 55)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.182 172.17.0.2:54321      6000   0 (TID 55)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.183 172.17.0.2:54321      6000   0 (TID 57)  INFO org.apache.spark.executor.Executor: Finished task 49.0 in stage 7.0 (TID 57). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.185 172.17.0.2:54321      6000   0 (TID 55)  INFO org.apache.spark.executor.Executor: Finished task 47.0 in stage 7.0 (TID 55). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.185 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 51.0 in stage 7.0 (TID 59) (95675304fa2d, executor driver, partition 51, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.185 172.17.0.2:54321      6000   0 (TID 59)  INFO org.apache.spark.executor.Executor: Running task 51.0 in stage 7.0 (TID 59)\n",
      "10-20 14:40:35.185 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 52.0 in stage 7.0 (TID 60) (95675304fa2d, executor driver, partition 52, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.186 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 49.0 in stage 7.0 (TID 57) in 14 ms on 95675304fa2d (executor driver) (49/200)\n",
      "10-20 14:40:35.186 172.17.0.2:54321      6000   0 (TID 60)  INFO org.apache.spark.executor.Executor: Running task 52.0 in stage 7.0 (TID 60)\n",
      "10-20 14:40:35.187 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 47.0 in stage 7.0 (TID 55) in 20 ms on 95675304fa2d (executor driver) (50/200)\n",
      "10-20 14:40:35.190 172.17.0.2:54321      6000   0 (TID 58)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.190 172.17.0.2:54321      6000   0 (TID 58)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.192 172.17.0.2:54321      6000   0 (TID 59)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.192 172.17.0.2:54321      6000   0 (TID 59)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.193 172.17.0.2:54321      6000   0 (TID 60)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.193 172.17.0.2:54321      6000   0 (TID 60)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.195 172.17.0.2:54321      6000   0 (TID 56)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.199 172.17.0.2:54321      6000   0 (TID 56)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:40:35.197 172.17.0.2:54321      6000   0 (TID 59)  INFO org.apache.spark.executor.Executor: Finished task 51.0 in stage 7.0 (TID 59). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.197 172.17.0.2:54321      6000   0 (TID 60)  INFO org.apache.spark.executor.Executor: Finished task 52.0 in stage 7.0 (TID 60). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.201 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 53.0 in stage 7.0 (TID 61) (95675304fa2d, executor driver, partition 53, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.202 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 54.0 in stage 7.0 (TID 62) (95675304fa2d, executor driver, partition 54, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.202 172.17.0.2:54321      6000   0 (TID 61)  INFO org.apache.spark.executor.Executor: Running task 53.0 in stage 7.0 (TID 61)\n",
      "10-20 14:40:35.203 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 52.0 in stage 7.0 (TID 60) in 18 ms on 95675304fa2d (executor driver) (51/200)\n",
      "10-20 14:40:35.203 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 51.0 in stage 7.0 (TID 59) in 18 ms on 95675304fa2d (executor driver) (52/200)\n",
      "10-20 14:40:35.206 172.17.0.2:54321      6000   0 (TID 58)  INFO org.apache.spark.executor.Executor: Finished task 50.0 in stage 7.0 (TID 58). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.206 172.17.0.2:54321      6000   0 (TID 62)  INFO org.apache.spark.executor.Executor: Running task 54.0 in stage 7.0 (TID 62)\n",
      "10-20 14:40:35.207 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 55.0 in stage 7.0 (TID 63) (95675304fa2d, executor driver, partition 55, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.208 172.17.0.2:54321      6000   0 (TID 63)  INFO org.apache.spark.executor.Executor: Running task 55.0 in stage 7.0 (TID 63)\n",
      "10-20 14:40:35.209 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 50.0 in stage 7.0 (TID 58) in 36 ms on 95675304fa2d (executor driver) (53/200)\n",
      "10-20 14:40:35.214 172.17.0.2:54321      6000   0 (TID 63)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.214 172.17.0.2:54321      6000   0 (TID 63)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.215 172.17.0.2:54321      6000   0 (TID 61)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.215 172.17.0.2:54321      6000   0 (TID 61)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.215 172.17.0.2:54321      6000   0 (TID 56)  INFO org.apache.spark.executor.Executor: Finished task 48.0 in stage 7.0 (TID 56). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.216 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 56.0 in stage 7.0 (TID 64) (95675304fa2d, executor driver, partition 56, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.217 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 48.0 in stage 7.0 (TID 56) in 47 ms on 95675304fa2d (executor driver) (54/200)\n",
      "10-20 14:40:35.214 172.17.0.2:54321      6000   0 (TID 62)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.217 172.17.0.2:54321      6000   0 (TID 62)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:40:35.218 172.17.0.2:54321      6000   0 (TID 64)  INFO org.apache.spark.executor.Executor: Running task 56.0 in stage 7.0 (TID 64)\n",
      "10-20 14:40:35.221 172.17.0.2:54321      6000   0 (TID 61)  INFO org.apache.spark.executor.Executor: Finished task 53.0 in stage 7.0 (TID 61). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.222 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 57.0 in stage 7.0 (TID 65) (95675304fa2d, executor driver, partition 57, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.222 172.17.0.2:54321      6000   0 (TID 65)  INFO org.apache.spark.executor.Executor: Running task 57.0 in stage 7.0 (TID 65)\n",
      "10-20 14:40:35.222 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 53.0 in stage 7.0 (TID 61) in 22 ms on 95675304fa2d (executor driver) (55/200)\n",
      "10-20 14:40:35.223 172.17.0.2:54321      6000   0 (TID 63)  INFO org.apache.spark.executor.Executor: Finished task 55.0 in stage 7.0 (TID 63). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.226 172.17.0.2:54321      6000   0 (TID 62)  INFO org.apache.spark.executor.Executor: Finished task 54.0 in stage 7.0 (TID 62). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.227 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 58.0 in stage 7.0 (TID 66) (95675304fa2d, executor driver, partition 58, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.227 172.17.0.2:54321      6000   0 (TID 64)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.227 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 54.0 in stage 7.0 (TID 62) in 25 ms on 95675304fa2d (executor driver) (56/200)\n",
      "10-20 14:40:35.227 172.17.0.2:54321      6000   0 (TID 64)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.228 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 59.0 in stage 7.0 (TID 67) (95675304fa2d, executor driver, partition 59, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.229 172.17.0.2:54321      6000   0 (TID 67)  INFO org.apache.spark.executor.Executor: Running task 59.0 in stage 7.0 (TID 67)\n",
      "10-20 14:40:35.229 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 55.0 in stage 7.0 (TID 63) in 22 ms on 95675304fa2d (executor driver) (57/200)\n",
      "10-20 14:40:35.228 172.17.0.2:54321      6000   0 (TID 66)  INFO org.apache.spark.executor.Executor: Running task 58.0 in stage 7.0 (TID 66)\n",
      "10-20 14:40:35.233 172.17.0.2:54321      6000   0 (TID 64)  INFO org.apache.spark.executor.Executor: Finished task 56.0 in stage 7.0 (TID 64). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.234 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 60.0 in stage 7.0 (TID 68) (95675304fa2d, executor driver, partition 60, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.234 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 56.0 in stage 7.0 (TID 64) in 18 ms on 95675304fa2d (executor driver) (58/200)\n",
      "10-20 14:40:35.234 172.17.0.2:54321      6000   0 (TID 65)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.235 172.17.0.2:54321      6000   0 (TID 65)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.236 172.17.0.2:54321      6000   0 (TID 67)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.236 172.17.0.2:54321      6000   0 (TID 67)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.236 172.17.0.2:54321      6000   0 (TID 66)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.237 172.17.0.2:54321      6000   0 (TID 66)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.239 172.17.0.2:54321      6000   0 (TID 65)  INFO org.apache.spark.executor.Executor: Finished task 57.0 in stage 7.0 (TID 65). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.240 172.17.0.2:54321      6000   0 (TID 68)  INFO org.apache.spark.executor.Executor: Running task 60.0 in stage 7.0 (TID 68)\n",
      "10-20 14:40:35.240 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 61.0 in stage 7.0 (TID 69) (95675304fa2d, executor driver, partition 61, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.240 172.17.0.2:54321      6000   0 (TID 66)  INFO org.apache.spark.executor.Executor: Finished task 58.0 in stage 7.0 (TID 66). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.240 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 57.0 in stage 7.0 (TID 65) in 19 ms on 95675304fa2d (executor driver) (59/200)\n",
      "10-20 14:40:35.241 172.17.0.2:54321      6000   0 (TID 69)  INFO org.apache.spark.executor.Executor: Running task 61.0 in stage 7.0 (TID 69)\n",
      "10-20 14:40:35.244 172.17.0.2:54321      6000   0 (TID 67)  INFO org.apache.spark.executor.Executor: Finished task 59.0 in stage 7.0 (TID 67). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.244 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 62.0 in stage 7.0 (TID 70) (95675304fa2d, executor driver, partition 62, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.245 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 59.0 in stage 7.0 (TID 67) in 17 ms on 95675304fa2d (executor driver) (60/200)\n",
      "10-20 14:40:35.245 172.17.0.2:54321      6000   0 (TID 70)  INFO org.apache.spark.executor.Executor: Running task 62.0 in stage 7.0 (TID 70)\n",
      "10-20 14:40:35.248 172.17.0.2:54321      6000   0 (TID 69)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.248 172.17.0.2:54321      6000   0 (TID 69)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.249 172.17.0.2:54321      6000   0 (TID 70)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.257 172.17.0.2:54321      6000   0 (TID 70)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "10-20 14:40:35.254 172.17.0.2:54321      6000   0 (TID 68)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.258 172.17.0.2:54321      6000   0 (TID 68)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:40:35.251 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 63.0 in stage 7.0 (TID 71) (95675304fa2d, executor driver, partition 63, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.252 172.17.0.2:54321      6000   0 (TID 69)  INFO org.apache.spark.executor.Executor: Finished task 61.0 in stage 7.0 (TID 69). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.261 172.17.0.2:54321      6000   0 (TID 71)  INFO org.apache.spark.executor.Executor: Running task 63.0 in stage 7.0 (TID 71)\n",
      "10-20 14:40:35.261 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 58.0 in stage 7.0 (TID 66) in 34 ms on 95675304fa2d (executor driver) (61/200)\n",
      "10-20 14:40:35.262 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 64.0 in stage 7.0 (TID 72) (95675304fa2d, executor driver, partition 64, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.263 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 61.0 in stage 7.0 (TID 69) in 23 ms on 95675304fa2d (executor driver) (62/200)\n",
      "10-20 14:40:35.264 172.17.0.2:54321      6000   0 (TID 72)  INFO org.apache.spark.executor.Executor: Running task 64.0 in stage 7.0 (TID 72)\n",
      "10-20 14:40:35.266 172.17.0.2:54321      6000   0 (TID 68)  INFO org.apache.spark.executor.Executor: Finished task 60.0 in stage 7.0 (TID 68). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.266 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 65.0 in stage 7.0 (TID 73) (95675304fa2d, executor driver, partition 65, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.267 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 60.0 in stage 7.0 (TID 68) in 34 ms on 95675304fa2d (executor driver) (63/200)\n",
      "10-20 14:40:35.268 172.17.0.2:54321      6000   0 (TID 73)  INFO org.apache.spark.executor.Executor: Running task 65.0 in stage 7.0 (TID 73)\n",
      "10-20 14:40:35.270 172.17.0.2:54321      6000   0 (TID 72)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.272 172.17.0.2:54321      6000   0 (TID 72)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:40:35.274 172.17.0.2:54321      6000   0 (TID 73)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.275 172.17.0.2:54321      6000   0 (TID 73)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.276 172.17.0.2:54321      6000   0 (TID 72)  INFO org.apache.spark.executor.Executor: Finished task 64.0 in stage 7.0 (TID 72). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.272 172.17.0.2:54321      6000   0 (TID 70)  INFO org.apache.spark.executor.Executor: Finished task 62.0 in stage 7.0 (TID 70). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.272 172.17.0.2:54321      6000   0 (TID 71)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.277 172.17.0.2:54321      6000   0 (TID 71)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:40:35.277 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 66.0 in stage 7.0 (TID 74) (95675304fa2d, executor driver, partition 66, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.278 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 62.0 in stage 7.0 (TID 70) in 34 ms on 95675304fa2d (executor driver) (64/200)\n",
      "10-20 14:40:35.278 172.17.0.2:54321      6000   0 (TID 74)  INFO org.apache.spark.executor.Executor: Running task 66.0 in stage 7.0 (TID 74)\n",
      "10-20 14:40:35.279 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 67.0 in stage 7.0 (TID 75) (95675304fa2d, executor driver, partition 67, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.280 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 64.0 in stage 7.0 (TID 72) in 18 ms on 95675304fa2d (executor driver) (65/200)\n",
      "10-20 14:40:35.280 172.17.0.2:54321      6000   0 (TID 75)  INFO org.apache.spark.executor.Executor: Running task 67.0 in stage 7.0 (TID 75)\n",
      "10-20 14:40:35.285 172.17.0.2:54321      6000   0 (TID 71)  INFO org.apache.spark.executor.Executor: Finished task 63.0 in stage 7.0 (TID 71). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.287 172.17.0.2:54321      6000   0 (TID 75)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.288 172.17.0.2:54321      6000   0 (TID 75)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:40:35.288 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 68.0 in stage 7.0 (TID 76) (95675304fa2d, executor driver, partition 68, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.289 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 63.0 in stage 7.0 (TID 71) in 39 ms on 95675304fa2d (executor driver) (66/200)\n",
      "10-20 14:40:35.289 172.17.0.2:54321      6000   0 (TID 76)  INFO org.apache.spark.executor.Executor: Running task 68.0 in stage 7.0 (TID 76)\n",
      "10-20 14:40:35.290 172.17.0.2:54321      6000   0 (TID 74)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.290 172.17.0.2:54321      6000   0 (TID 74)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.285 172.17.0.2:54321      6000   0 (TID 73)  INFO org.apache.spark.executor.Executor: Finished task 65.0 in stage 7.0 (TID 73). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.296 172.17.0.2:54321      6000   0 (TID 76)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.296 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 69.0 in stage 7.0 (TID 77) (95675304fa2d, executor driver, partition 69, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.297 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 65.0 in stage 7.0 (TID 73) in 31 ms on 95675304fa2d (executor driver) (67/200)\n",
      "10-20 14:40:35.296 172.17.0.2:54321      6000   0 (TID 76)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.297 172.17.0.2:54321      6000   0 (TID 77)  INFO org.apache.spark.executor.Executor: Running task 69.0 in stage 7.0 (TID 77)\n",
      "10-20 14:40:35.298 172.17.0.2:54321      6000   0 (TID 74)  INFO org.apache.spark.executor.Executor: Finished task 66.0 in stage 7.0 (TID 74). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.298 172.17.0.2:54321      6000   0 (TID 75)  INFO org.apache.spark.executor.Executor: Finished task 67.0 in stage 7.0 (TID 75). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.298 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 70.0 in stage 7.0 (TID 78) (95675304fa2d, executor driver, partition 70, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.299 172.17.0.2:54321      6000   0 (TID 78)  INFO org.apache.spark.executor.Executor: Running task 70.0 in stage 7.0 (TID 78)\n",
      "10-20 14:40:35.299 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 66.0 in stage 7.0 (TID 74) in 22 ms on 95675304fa2d (executor driver) (68/200)\n",
      "10-20 14:40:35.301 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 71.0 in stage 7.0 (TID 79) (95675304fa2d, executor driver, partition 71, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.302 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 67.0 in stage 7.0 (TID 75) in 23 ms on 95675304fa2d (executor driver) (69/200)\n",
      "10-20 14:40:35.304 172.17.0.2:54321      6000   0 (TID 77)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.304 172.17.0.2:54321      6000   0 (TID 77)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.309 172.17.0.2:54321      6000   0 (TID 79)  INFO org.apache.spark.executor.Executor: Running task 71.0 in stage 7.0 (TID 79)\n",
      "10-20 14:40:35.310 172.17.0.2:54321      6000   0 (TID 76)  INFO org.apache.spark.executor.Executor: Finished task 68.0 in stage 7.0 (TID 76). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.311 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 72.0 in stage 7.0 (TID 80) (95675304fa2d, executor driver, partition 72, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.312 172.17.0.2:54321      6000   0 (TID 80)  INFO org.apache.spark.executor.Executor: Running task 72.0 in stage 7.0 (TID 80)\n",
      "10-20 14:40:35.312 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 68.0 in stage 7.0 (TID 76) in 24 ms on 95675304fa2d (executor driver) (70/200)\n",
      "10-20 14:40:35.315 172.17.0.2:54321      6000   0 (TID 77)  INFO org.apache.spark.executor.Executor: Finished task 69.0 in stage 7.0 (TID 77). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.316 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 73.0 in stage 7.0 (TID 81) (95675304fa2d, executor driver, partition 73, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.316 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 69.0 in stage 7.0 (TID 77) in 20 ms on 95675304fa2d (executor driver) (71/200)\n",
      "10-20 14:40:35.317 172.17.0.2:54321      6000   0 (TID 81)  INFO org.apache.spark.executor.Executor: Running task 73.0 in stage 7.0 (TID 81)\n",
      "10-20 14:40:35.318 172.17.0.2:54321      6000   0 (TID 80)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.322 172.17.0.2:54321      6000   0 (TID 80)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:40:35.323 172.17.0.2:54321      6000   0 (TID 81)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.323 172.17.0.2:54321      6000   0 (TID 81)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.326 172.17.0.2:54321      6000   0 (TID 80)  INFO org.apache.spark.executor.Executor: Finished task 72.0 in stage 7.0 (TID 80). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.327 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 74.0 in stage 7.0 (TID 82) (95675304fa2d, executor driver, partition 74, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.328 172.17.0.2:54321      6000   0 (TID 82)  INFO org.apache.spark.executor.Executor: Running task 74.0 in stage 7.0 (TID 82)\n",
      "10-20 14:40:35.322 172.17.0.2:54321      6000   0 (TID 78)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.318 172.17.0.2:54321      6000   0 (TID 79)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.328 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 72.0 in stage 7.0 (TID 80) in 17 ms on 95675304fa2d (executor driver) (72/200)\n",
      "10-20 14:40:35.328 172.17.0.2:54321      6000   0 (TID 79)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms\n",
      "10-20 14:40:35.330 172.17.0.2:54321      6000   0 (TID 81)  INFO org.apache.spark.executor.Executor: Finished task 73.0 in stage 7.0 (TID 81). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.332 172.17.0.2:54321      6000   0 (TID 78)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms\n",
      "10-20 14:40:35.332 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 75.0 in stage 7.0 (TID 83) (95675304fa2d, executor driver, partition 75, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.333 172.17.0.2:54321      6000   0 (TID 79)  INFO org.apache.spark.executor.Executor: Finished task 71.0 in stage 7.0 (TID 79). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.334 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 76.0 in stage 7.0 (TID 84) (95675304fa2d, executor driver, partition 76, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.334 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 73.0 in stage 7.0 (TID 81) in 18 ms on 95675304fa2d (executor driver) (73/200)\n",
      "10-20 14:40:35.334 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 71.0 in stage 7.0 (TID 79) in 33 ms on 95675304fa2d (executor driver) (74/200)\n",
      "10-20 14:40:35.335 172.17.0.2:54321      6000   0 (TID 84)  INFO org.apache.spark.executor.Executor: Running task 76.0 in stage 7.0 (TID 84)\n",
      "10-20 14:40:35.336 172.17.0.2:54321      6000   0 (TID 83)  INFO org.apache.spark.executor.Executor: Running task 75.0 in stage 7.0 (TID 83)\n",
      "10-20 14:40:35.338 172.17.0.2:54321      6000   0 (TID 82)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.338 172.17.0.2:54321      6000   0 (TID 82)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.340 172.17.0.2:54321      6000   0 (TID 83)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.340 172.17.0.2:54321      6000   0 (TID 83)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.341 172.17.0.2:54321      6000   0 (TID 84)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.342 172.17.0.2:54321      6000   0 (TID 84)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.343 172.17.0.2:54321      6000   0 (TID 78)  INFO org.apache.spark.executor.Executor: Finished task 70.0 in stage 7.0 (TID 78). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.344 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 77.0 in stage 7.0 (TID 85) (95675304fa2d, executor driver, partition 77, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.345 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 70.0 in stage 7.0 (TID 78) in 47 ms on 95675304fa2d (executor driver) (75/200)\n",
      "10-20 14:40:35.346 172.17.0.2:54321      6000   0 (TID 85)  INFO org.apache.spark.executor.Executor: Running task 77.0 in stage 7.0 (TID 85)\n",
      "10-20 14:40:35.351 172.17.0.2:54321      6000   0 (TID 85)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.351 172.17.0.2:54321      6000   0 (TID 85)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.344 172.17.0.2:54321      6000   0 (TID 82)  INFO org.apache.spark.executor.Executor: Finished task 74.0 in stage 7.0 (TID 82). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.352 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 78.0 in stage 7.0 (TID 86) (95675304fa2d, executor driver, partition 78, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.353 172.17.0.2:54321      6000   0 (TID 86)  INFO org.apache.spark.executor.Executor: Running task 78.0 in stage 7.0 (TID 86)\n",
      "10-20 14:40:35.353 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 74.0 in stage 7.0 (TID 82) in 26 ms on 95675304fa2d (executor driver) (76/200)\n",
      "10-20 14:40:35.344 172.17.0.2:54321      6000   0 (TID 83)  INFO org.apache.spark.executor.Executor: Finished task 75.0 in stage 7.0 (TID 83). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.354 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 79.0 in stage 7.0 (TID 87) (95675304fa2d, executor driver, partition 79, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.354 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 75.0 in stage 7.0 (TID 83) in 22 ms on 95675304fa2d (executor driver) (77/200)\n",
      "10-20 14:40:35.354 172.17.0.2:54321      6000   0 (TID 87)  INFO org.apache.spark.executor.Executor: Running task 79.0 in stage 7.0 (TID 87)\n",
      "10-20 14:40:35.359 172.17.0.2:54321      6000   0 (TID 87)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.359 172.17.0.2:54321      6000   0 (TID 87)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.360 172.17.0.2:54321      6000   0 (TID 85)  INFO org.apache.spark.executor.Executor: Finished task 77.0 in stage 7.0 (TID 85). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.363 172.17.0.2:54321      6000   0 (TID 86)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.363 172.17.0.2:54321      6000   0 (TID 86)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.363 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 80.0 in stage 7.0 (TID 88) (95675304fa2d, executor driver, partition 80, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.364 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 77.0 in stage 7.0 (TID 85) in 20 ms on 95675304fa2d (executor driver) (78/200)\n",
      "10-20 14:40:35.365 172.17.0.2:54321      6000   0 (TID 84)  INFO org.apache.spark.executor.Executor: Finished task 76.0 in stage 7.0 (TID 84). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.367 172.17.0.2:54321      6000   0 (TID 88)  INFO org.apache.spark.executor.Executor: Running task 80.0 in stage 7.0 (TID 88)\n",
      "10-20 14:40:35.368 172.17.0.2:54321      6000   0 (TID 87)  INFO org.apache.spark.executor.Executor: Finished task 79.0 in stage 7.0 (TID 87). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.369 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 81.0 in stage 7.0 (TID 89) (95675304fa2d, executor driver, partition 81, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.371 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 82.0 in stage 7.0 (TID 90) (95675304fa2d, executor driver, partition 82, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.371 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 76.0 in stage 7.0 (TID 84) in 38 ms on 95675304fa2d (executor driver) (79/200)\n",
      "10-20 14:40:35.371 172.17.0.2:54321      6000   0 (TID 89)  INFO org.apache.spark.executor.Executor: Running task 81.0 in stage 7.0 (TID 89)\n",
      "10-20 14:40:35.372 172.17.0.2:54321      6000   0 (TID 90)  INFO org.apache.spark.executor.Executor: Running task 82.0 in stage 7.0 (TID 90)\n",
      "10-20 14:40:35.374 172.17.0.2:54321      6000   0 (TID 86)  INFO org.apache.spark.executor.Executor: Finished task 78.0 in stage 7.0 (TID 86). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.375 172.17.0.2:54321      6000   0 (TID 88)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.375 172.17.0.2:54321      6000   0 (TID 88)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.372 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 79.0 in stage 7.0 (TID 87) in 17 ms on 95675304fa2d (executor driver) (80/200)\n",
      "10-20 14:40:35.378 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 83.0 in stage 7.0 (TID 91) (95675304fa2d, executor driver, partition 83, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.379 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 78.0 in stage 7.0 (TID 86) in 27 ms on 95675304fa2d (executor driver) (81/200)\n",
      "10-20 14:40:35.379 172.17.0.2:54321      6000   0 (TID 91)  INFO org.apache.spark.executor.Executor: Running task 83.0 in stage 7.0 (TID 91)\n",
      "10-20 14:40:35.380 172.17.0.2:54321      6000   0 (TID 88)  INFO org.apache.spark.executor.Executor: Finished task 80.0 in stage 7.0 (TID 88). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.382 172.17.0.2:54321      6000   0 (TID 90)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.382 172.17.0.2:54321      6000   0 (TID 90)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=============================>                         (106 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:40:35.389 172.17.0.2:54321      6000   0 (TID 91)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.389 172.17.0.2:54321      6000   0 (TID 91)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.395 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 84.0 in stage 7.0 (TID 92) (95675304fa2d, executor driver, partition 84, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.395 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 80.0 in stage 7.0 (TID 88) in 32 ms on 95675304fa2d (executor driver) (82/200)\n",
      "10-20 14:40:35.397 172.17.0.2:54321      6000   0 (TID 92)  INFO org.apache.spark.executor.Executor: Running task 84.0 in stage 7.0 (TID 92)\n",
      "10-20 14:40:35.404 172.17.0.2:54321      6000   0 (TID 90)  INFO org.apache.spark.executor.Executor: Finished task 82.0 in stage 7.0 (TID 90). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.404 172.17.0.2:54321      6000   0 (TID 91)  INFO org.apache.spark.executor.Executor: Finished task 83.0 in stage 7.0 (TID 91). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.405 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 85.0 in stage 7.0 (TID 93) (95675304fa2d, executor driver, partition 85, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.405 172.17.0.2:54321      6000   0 (TID 93)  INFO org.apache.spark.executor.Executor: Running task 85.0 in stage 7.0 (TID 93)\n",
      "10-20 14:40:35.405 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 82.0 in stage 7.0 (TID 90) in 34 ms on 95675304fa2d (executor driver) (83/200)\n",
      "10-20 14:40:35.409 172.17.0.2:54321      6000   0 (TID 92)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.409 172.17.0.2:54321      6000   0 (TID 92)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.410 172.17.0.2:54321      6000   0 (TID 89)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.410 172.17.0.2:54321      6000   0 (TID 89)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.415 172.17.0.2:54321      6000   0 (TID 89)  INFO org.apache.spark.executor.Executor: Finished task 81.0 in stage 7.0 (TID 89). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.416 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 86.0 in stage 7.0 (TID 94) (95675304fa2d, executor driver, partition 86, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.417 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 83.0 in stage 7.0 (TID 91) in 39 ms on 95675304fa2d (executor driver) (84/200)\n",
      "10-20 14:40:35.418 172.17.0.2:54321      6000   0 (TID 94)  INFO org.apache.spark.executor.Executor: Running task 86.0 in stage 7.0 (TID 94)\n",
      "10-20 14:40:35.415 172.17.0.2:54321      6000   0 (TID 93)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.418 172.17.0.2:54321      6000   0 (TID 93)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:40:35.423 172.17.0.2:54321      6000   0 (TID 92)  INFO org.apache.spark.executor.Executor: Finished task 84.0 in stage 7.0 (TID 92). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.427 172.17.0.2:54321      6000   0 (TID 93)  INFO org.apache.spark.executor.Executor: Finished task 85.0 in stage 7.0 (TID 93). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.429 172.17.0.2:54321      6000   0 (TID 94)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.429 172.17.0.2:54321      6000   0 (TID 94)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.434 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 87.0 in stage 7.0 (TID 95) (95675304fa2d, executor driver, partition 87, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.435 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 88.0 in stage 7.0 (TID 96) (95675304fa2d, executor driver, partition 88, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.436 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 81.0 in stage 7.0 (TID 89) in 67 ms on 95675304fa2d (executor driver) (85/200)\n",
      "10-20 14:40:35.436 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 84.0 in stage 7.0 (TID 92) in 42 ms on 95675304fa2d (executor driver) (86/200)\n",
      "10-20 14:40:35.437 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 89.0 in stage 7.0 (TID 97) (95675304fa2d, executor driver, partition 89, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.437 172.17.0.2:54321      6000   0 (TID 97)  INFO org.apache.spark.executor.Executor: Running task 89.0 in stage 7.0 (TID 97)\n",
      "10-20 14:40:35.438 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 85.0 in stage 7.0 (TID 93) in 34 ms on 95675304fa2d (executor driver) (87/200)\n",
      "10-20 14:40:35.440 172.17.0.2:54321      6000   0 (TID 96)  INFO org.apache.spark.executor.Executor: Running task 88.0 in stage 7.0 (TID 96)\n",
      "10-20 14:40:35.442 172.17.0.2:54321      6000   0 (TID 95)  INFO org.apache.spark.executor.Executor: Running task 87.0 in stage 7.0 (TID 95)\n",
      "10-20 14:40:35.444 172.17.0.2:54321      6000   0 (TID 94)  INFO org.apache.spark.executor.Executor: Finished task 86.0 in stage 7.0 (TID 94). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.445 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 90.0 in stage 7.0 (TID 98) (95675304fa2d, executor driver, partition 90, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.464 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 86.0 in stage 7.0 (TID 94) in 48 ms on 95675304fa2d (executor driver) (88/200)\n",
      "10-20 14:40:35.467 172.17.0.2:54321      6000   0 (TID 96)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.468 172.17.0.2:54321      6000   0 (TID 96)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.473 172.17.0.2:54321      6000   0 (TID 96)  INFO org.apache.spark.executor.Executor: Finished task 88.0 in stage 7.0 (TID 96). 3875 bytes result sent to driver\n",
      "10-20 14:40:35.475 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 91.0 in stage 7.0 (TID 99) (95675304fa2d, executor driver, partition 91, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.476 172.17.0.2:54321      6000   0 (TID 99)  INFO org.apache.spark.executor.Executor: Running task 91.0 in stage 7.0 (TID 99)\n",
      "10-20 14:40:35.478 172.17.0.2:54321      6000   0 (TID 98)  INFO org.apache.spark.executor.Executor: Running task 90.0 in stage 7.0 (TID 98)\n",
      "10-20 14:40:35.479 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 88.0 in stage 7.0 (TID 96) in 44 ms on 95675304fa2d (executor driver) (89/200)\n",
      "10-20 14:40:35.479 172.17.0.2:54321      6000   0 (TID 97)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.480 172.17.0.2:54321      6000   0 (TID 97)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.484 172.17.0.2:54321      6000   0 (TID 98)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.484 172.17.0.2:54321      6000   0 (TID 98)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.491 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_10_piece0 on 95675304fa2d:39707 in memory (size: 18.0 KiB, free: 434.4 MiB)\n",
      "10-20 14:40:35.499 172.17.0.2:54321      6000   0 (TID 99)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.499 172.17.0.2:54321      6000   0 (TID 99)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.500 172.17.0.2:54321      6000   0 (TID 95)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.500 172.17.0.2:54321      6000   0 (TID 95)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms\n",
      "10-20 14:40:35.501 172.17.0.2:54321      6000   0 (TID 97)  INFO org.apache.spark.executor.Executor: Finished task 89.0 in stage 7.0 (TID 97). 3918 bytes result sent to driver\n",
      "10-20 14:40:35.502 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 92.0 in stage 7.0 (TID 100) (95675304fa2d, executor driver, partition 92, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.502 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 89.0 in stage 7.0 (TID 97) in 65 ms on 95675304fa2d (executor driver) (90/200)\n",
      "10-20 14:40:35.503 172.17.0.2:54321      6000   0 (TID 95)  INFO org.apache.spark.executor.Executor: Finished task 87.0 in stage 7.0 (TID 95). 3875 bytes result sent to driver\n",
      "10-20 14:40:35.504 172.17.0.2:54321      6000   0 (TID 98)  INFO org.apache.spark.executor.Executor: Finished task 90.0 in stage 7.0 (TID 98). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.504 172.17.0.2:54321      6000    (TID 100)  INFO org.apache.spark.executor.Executor: Running task 92.0 in stage 7.0 (TID 100)\n",
      "10-20 14:40:35.504 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 93.0 in stage 7.0 (TID 101) (95675304fa2d, executor driver, partition 93, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.505 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 94.0 in stage 7.0 (TID 102) (95675304fa2d, executor driver, partition 94, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.505 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 87.0 in stage 7.0 (TID 95) in 72 ms on 95675304fa2d (executor driver) (91/200)\n",
      "10-20 14:40:35.505 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 90.0 in stage 7.0 (TID 98) in 60 ms on 95675304fa2d (executor driver) (92/200)\n",
      "10-20 14:40:35.505 172.17.0.2:54321      6000    (TID 101)  INFO org.apache.spark.executor.Executor: Running task 93.0 in stage 7.0 (TID 101)\n",
      "10-20 14:40:35.508 172.17.0.2:54321      6000    (TID 100)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.508 172.17.0.2:54321      6000    (TID 100)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.508 172.17.0.2:54321      6000    (TID 102)  INFO org.apache.spark.executor.Executor: Running task 94.0 in stage 7.0 (TID 102)\n",
      "10-20 14:40:35.510 172.17.0.2:54321      6000    (TID 101)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.510 172.17.0.2:54321      6000    (TID 101)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.513 172.17.0.2:54321      6000    (TID 100)  INFO org.apache.spark.executor.Executor: Finished task 92.0 in stage 7.0 (TID 100). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.513 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 95.0 in stage 7.0 (TID 103) (95675304fa2d, executor driver, partition 95, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.514 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 92.0 in stage 7.0 (TID 100) in 12 ms on 95675304fa2d (executor driver) (93/200)\n",
      "10-20 14:40:35.514 172.17.0.2:54321      6000    (TID 103)  INFO org.apache.spark.executor.Executor: Running task 95.0 in stage 7.0 (TID 103)\n",
      "10-20 14:40:35.515 172.17.0.2:54321      6000   0 (TID 99)  INFO org.apache.spark.executor.Executor: Finished task 91.0 in stage 7.0 (TID 99). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.516 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 96.0 in stage 7.0 (TID 104) (95675304fa2d, executor driver, partition 96, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.516 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 91.0 in stage 7.0 (TID 99) in 42 ms on 95675304fa2d (executor driver) (94/200)\n",
      "10-20 14:40:35.517 172.17.0.2:54321      6000    (TID 102)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.517 172.17.0.2:54321      6000    (TID 104)  INFO org.apache.spark.executor.Executor: Running task 96.0 in stage 7.0 (TID 104)\n",
      "10-20 14:40:35.517 172.17.0.2:54321      6000    (TID 102)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.518 172.17.0.2:54321      6000    (TID 101)  INFO org.apache.spark.executor.Executor: Finished task 93.0 in stage 7.0 (TID 101). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.519 172.17.0.2:54321      6000    (TID 103)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.519 172.17.0.2:54321      6000    (TID 103)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.520 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 97.0 in stage 7.0 (TID 105) (95675304fa2d, executor driver, partition 97, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.520 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 93.0 in stage 7.0 (TID 101) in 16 ms on 95675304fa2d (executor driver) (95/200)\n",
      "10-20 14:40:35.520 172.17.0.2:54321      6000    (TID 105)  INFO org.apache.spark.executor.Executor: Running task 97.0 in stage 7.0 (TID 105)\n",
      "10-20 14:40:35.522 172.17.0.2:54321      6000    (TID 103)  INFO org.apache.spark.executor.Executor: Finished task 95.0 in stage 7.0 (TID 103). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.523 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 98.0 in stage 7.0 (TID 106) (95675304fa2d, executor driver, partition 98, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.524 172.17.0.2:54321      6000    (TID 106)  INFO org.apache.spark.executor.Executor: Running task 98.0 in stage 7.0 (TID 106)\n",
      "10-20 14:40:35.524 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 95.0 in stage 7.0 (TID 103) in 11 ms on 95675304fa2d (executor driver) (96/200)\n",
      "10-20 14:40:35.525 172.17.0.2:54321      6000    (TID 104)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.525 172.17.0.2:54321      6000    (TID 104)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.528 172.17.0.2:54321      6000    (TID 106)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.528 172.17.0.2:54321      6000    (TID 106)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.528 172.17.0.2:54321      6000    (TID 102)  INFO org.apache.spark.executor.Executor: Finished task 94.0 in stage 7.0 (TID 102). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.529 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 99.0 in stage 7.0 (TID 107) (95675304fa2d, executor driver, partition 99, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.530 172.17.0.2:54321      6000    (TID 107)  INFO org.apache.spark.executor.Executor: Running task 99.0 in stage 7.0 (TID 107)\n",
      "10-20 14:40:35.530 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 94.0 in stage 7.0 (TID 102) in 25 ms on 95675304fa2d (executor driver) (97/200)\n",
      "10-20 14:40:35.531 172.17.0.2:54321      6000    (TID 105)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.531 172.17.0.2:54321      6000    (TID 105)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.532 172.17.0.2:54321      6000    (TID 104)  INFO org.apache.spark.executor.Executor: Finished task 96.0 in stage 7.0 (TID 104). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.533 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 100.0 in stage 7.0 (TID 108) (95675304fa2d, executor driver, partition 100, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.533 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 96.0 in stage 7.0 (TID 104) in 17 ms on 95675304fa2d (executor driver) (98/200)\n",
      "10-20 14:40:35.534 172.17.0.2:54321      6000    (TID 108)  INFO org.apache.spark.executor.Executor: Running task 100.0 in stage 7.0 (TID 108)\n",
      "10-20 14:40:35.535 172.17.0.2:54321      6000    (TID 107)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.535 172.17.0.2:54321      6000    (TID 107)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.536 172.17.0.2:54321      6000    (TID 106)  INFO org.apache.spark.executor.Executor: Finished task 98.0 in stage 7.0 (TID 106). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.536 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 101.0 in stage 7.0 (TID 109) (95675304fa2d, executor driver, partition 101, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.537 172.17.0.2:54321      6000    (TID 109)  INFO org.apache.spark.executor.Executor: Running task 101.0 in stage 7.0 (TID 109)\n",
      "10-20 14:40:35.537 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 98.0 in stage 7.0 (TID 106) in 15 ms on 95675304fa2d (executor driver) (99/200)\n",
      "10-20 14:40:35.539 172.17.0.2:54321      6000    (TID 107)  INFO org.apache.spark.executor.Executor: Finished task 99.0 in stage 7.0 (TID 107). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.540 172.17.0.2:54321      6000    (TID 105)  INFO org.apache.spark.executor.Executor: Finished task 97.0 in stage 7.0 (TID 105). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.540 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 102.0 in stage 7.0 (TID 110) (95675304fa2d, executor driver, partition 102, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.541 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 99.0 in stage 7.0 (TID 107) in 12 ms on 95675304fa2d (executor driver) (100/200)\n",
      "10-20 14:40:35.541 172.17.0.2:54321      6000    (TID 110)  INFO org.apache.spark.executor.Executor: Running task 102.0 in stage 7.0 (TID 110)\n",
      "10-20 14:40:35.542 172.17.0.2:54321      6000    (TID 109)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.542 172.17.0.2:54321      6000    (TID 109)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.544 172.17.0.2:54321      6000    (TID 108)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.544 172.17.0.2:54321      6000    (TID 108)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:40:35.546 172.17.0.2:54321      6000    (TID 110)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.546 172.17.0.2:54321      6000    (TID 110)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.548 172.17.0.2:54321      6000    (TID 110)  INFO org.apache.spark.executor.Executor: Finished task 102.0 in stage 7.0 (TID 110). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.549 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 103.0 in stage 7.0 (TID 111) (95675304fa2d, executor driver, partition 103, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.549 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 102.0 in stage 7.0 (TID 110) in 9 ms on 95675304fa2d (executor driver) (101/200)\n",
      "10-20 14:40:35.550 172.17.0.2:54321      6000    (TID 108)  INFO org.apache.spark.executor.Executor: Finished task 100.0 in stage 7.0 (TID 108). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.550 172.17.0.2:54321      6000    (TID 111)  INFO org.apache.spark.executor.Executor: Running task 103.0 in stage 7.0 (TID 111)\n",
      "10-20 14:40:35.551 172.17.0.2:54321      6000    (TID 109)  INFO org.apache.spark.executor.Executor: Finished task 101.0 in stage 7.0 (TID 109). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.552 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 104.0 in stage 7.0 (TID 112) (95675304fa2d, executor driver, partition 104, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.552 172.17.0.2:54321      6000    (TID 112)  INFO org.apache.spark.executor.Executor: Running task 104.0 in stage 7.0 (TID 112)\n",
      "10-20 14:40:35.552 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 105.0 in stage 7.0 (TID 113) (95675304fa2d, executor driver, partition 105, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.552 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 106.0 in stage 7.0 (TID 114) (95675304fa2d, executor driver, partition 106, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.553 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 97.0 in stage 7.0 (TID 105) in 33 ms on 95675304fa2d (executor driver) (102/200)\n",
      "10-20 14:40:35.553 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 100.0 in stage 7.0 (TID 108) in 20 ms on 95675304fa2d (executor driver) (103/200)\n",
      "10-20 14:40:35.553 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 101.0 in stage 7.0 (TID 109) in 17 ms on 95675304fa2d (executor driver) (104/200)\n",
      "10-20 14:40:35.554 172.17.0.2:54321      6000    (TID 114)  INFO org.apache.spark.executor.Executor: Running task 106.0 in stage 7.0 (TID 114)\n",
      "10-20 14:40:35.554 172.17.0.2:54321      6000    (TID 113)  INFO org.apache.spark.executor.Executor: Running task 105.0 in stage 7.0 (TID 113)\n",
      "10-20 14:40:35.555 172.17.0.2:54321      6000    (TID 111)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.555 172.17.0.2:54321      6000    (TID 111)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.557 172.17.0.2:54321      6000    (TID 111)  INFO org.apache.spark.executor.Executor: Finished task 103.0 in stage 7.0 (TID 111). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.558 172.17.0.2:54321      6000    (TID 113)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.558 172.17.0.2:54321      6000    (TID 113)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.558 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 107.0 in stage 7.0 (TID 115) (95675304fa2d, executor driver, partition 107, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.558 172.17.0.2:54321      6000    (TID 114)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.561 172.17.0.2:54321      6000    (TID 113)  INFO org.apache.spark.executor.Executor: Finished task 105.0 in stage 7.0 (TID 113). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.558 172.17.0.2:54321      6000    (TID 112)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.558 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 103.0 in stage 7.0 (TID 111) in 9 ms on 95675304fa2d (executor driver) (105/200)\n",
      "10-20 14:40:35.558 172.17.0.2:54321      6000    (TID 115)  INFO org.apache.spark.executor.Executor: Running task 107.0 in stage 7.0 (TID 115)\n",
      "10-20 14:40:35.562 172.17.0.2:54321      6000    (TID 112)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:40:35.562 172.17.0.2:54321      6000    (TID 114)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:40:35.563 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 108.0 in stage 7.0 (TID 116) (95675304fa2d, executor driver, partition 108, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.563 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 105.0 in stage 7.0 (TID 113) in 11 ms on 95675304fa2d (executor driver) (106/200)\n",
      "10-20 14:40:35.563 172.17.0.2:54321      6000    (TID 116)  INFO org.apache.spark.executor.Executor: Running task 108.0 in stage 7.0 (TID 116)\n",
      "10-20 14:40:35.568 172.17.0.2:54321      6000    (TID 116)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.568 172.17.0.2:54321      6000    (TID 116)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.568 172.17.0.2:54321      6000    (TID 115)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.568 172.17.0.2:54321      6000    (TID 115)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.570 172.17.0.2:54321      6000    (TID 112)  INFO org.apache.spark.executor.Executor: Finished task 104.0 in stage 7.0 (TID 112). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.570 172.17.0.2:54321      6000    (TID 114)  INFO org.apache.spark.executor.Executor: Finished task 106.0 in stage 7.0 (TID 114). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.570 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 109.0 in stage 7.0 (TID 117) (95675304fa2d, executor driver, partition 109, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.571 172.17.0.2:54321      6000    (TID 117)  INFO org.apache.spark.executor.Executor: Running task 109.0 in stage 7.0 (TID 117)\n",
      "10-20 14:40:35.571 172.17.0.2:54321      6000    (TID 116)  INFO org.apache.spark.executor.Executor: Finished task 108.0 in stage 7.0 (TID 116). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.570 172.17.0.2:54321      6000    (TID 115)  INFO org.apache.spark.executor.Executor: Finished task 107.0 in stage 7.0 (TID 115). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.571 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 110.0 in stage 7.0 (TID 118) (95675304fa2d, executor driver, partition 110, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.573 172.17.0.2:54321      6000    (TID 118)  INFO org.apache.spark.executor.Executor: Running task 110.0 in stage 7.0 (TID 118)\n",
      "10-20 14:40:35.573 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 111.0 in stage 7.0 (TID 119) (95675304fa2d, executor driver, partition 111, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.574 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 104.0 in stage 7.0 (TID 112) in 23 ms on 95675304fa2d (executor driver) (107/200)\n",
      "10-20 14:40:35.574 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 108.0 in stage 7.0 (TID 116) in 11 ms on 95675304fa2d (executor driver) (108/200)\n",
      "10-20 14:40:35.575 172.17.0.2:54321      6000    (TID 119)  INFO org.apache.spark.executor.Executor: Running task 111.0 in stage 7.0 (TID 119)\n",
      "10-20 14:40:35.575 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 112.0 in stage 7.0 (TID 120) (95675304fa2d, executor driver, partition 112, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.576 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 106.0 in stage 7.0 (TID 114) in 24 ms on 95675304fa2d (executor driver) (109/200)\n",
      "10-20 14:40:35.576 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 107.0 in stage 7.0 (TID 115) in 18 ms on 95675304fa2d (executor driver) (110/200)\n",
      "10-20 14:40:35.576 172.17.0.2:54321      6000    (TID 120)  INFO org.apache.spark.executor.Executor: Running task 112.0 in stage 7.0 (TID 120)\n",
      "10-20 14:40:35.580 172.17.0.2:54321      6000    (TID 119)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.580 172.17.0.2:54321      6000    (TID 120)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.580 172.17.0.2:54321      6000    (TID 120)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.580 172.17.0.2:54321      6000    (TID 117)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.580 172.17.0.2:54321      6000    (TID 117)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.584 172.17.0.2:54321      6000    (TID 120)  INFO org.apache.spark.executor.Executor: Finished task 112.0 in stage 7.0 (TID 120). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.585 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 112.0 in stage 7.0 (TID 120) in 10 ms on 95675304fa2d (executor driver) (111/200)\n",
      "10-20 14:40:35.580 172.17.0.2:54321      6000    (TID 119)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.586 172.17.0.2:54321      6000    (TID 118)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.586 172.17.0.2:54321      6000    (TID 118)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.589 172.17.0.2:54321      6000    (TID 119)  INFO org.apache.spark.executor.Executor: Finished task 111.0 in stage 7.0 (TID 119). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.591 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 113.0 in stage 7.0 (TID 121) (95675304fa2d, executor driver, partition 113, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.591 172.17.0.2:54321      6000    (TID 117)  INFO org.apache.spark.executor.Executor: Finished task 109.0 in stage 7.0 (TID 117). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.592 172.17.0.2:54321      6000    (TID 121)  INFO org.apache.spark.executor.Executor: Running task 113.0 in stage 7.0 (TID 121)\n",
      "10-20 14:40:35.592 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 114.0 in stage 7.0 (TID 122) (95675304fa2d, executor driver, partition 114, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.592 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 115.0 in stage 7.0 (TID 123) (95675304fa2d, executor driver, partition 115, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.593 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 111.0 in stage 7.0 (TID 119) in 20 ms on 95675304fa2d (executor driver) (112/200)\n",
      "10-20 14:40:35.594 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 109.0 in stage 7.0 (TID 117) in 24 ms on 95675304fa2d (executor driver) (113/200)\n",
      "10-20 14:40:35.594 172.17.0.2:54321      6000    (TID 122)  INFO org.apache.spark.executor.Executor: Running task 114.0 in stage 7.0 (TID 122)\n",
      "10-20 14:40:35.594 172.17.0.2:54321      6000    (TID 123)  INFO org.apache.spark.executor.Executor: Running task 115.0 in stage 7.0 (TID 123)\n",
      "10-20 14:40:35.599 172.17.0.2:54321      6000    (TID 122)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.599 172.17.0.2:54321      6000    (TID 118)  INFO org.apache.spark.executor.Executor: Finished task 110.0 in stage 7.0 (TID 118). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.601 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 116.0 in stage 7.0 (TID 124) (95675304fa2d, executor driver, partition 116, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.601 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 110.0 in stage 7.0 (TID 118) in 30 ms on 95675304fa2d (executor driver) (114/200)\n",
      "10-20 14:40:35.602 172.17.0.2:54321      6000    (TID 124)  INFO org.apache.spark.executor.Executor: Running task 116.0 in stage 7.0 (TID 124)\n",
      "10-20 14:40:35.604 172.17.0.2:54321      6000    (TID 123)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.604 172.17.0.2:54321      6000    (TID 123)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.607 172.17.0.2:54321      6000    (TID 124)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.607 172.17.0.2:54321      6000    (TID 124)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.609 172.17.0.2:54321      6000    (TID 121)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.609 172.17.0.2:54321      6000    (TID 121)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.612 172.17.0.2:54321      6000    (TID 122)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms\n",
      "10-20 14:40:35.612 172.17.0.2:54321      6000    (TID 124)  INFO org.apache.spark.executor.Executor: Finished task 116.0 in stage 7.0 (TID 124). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.614 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 117.0 in stage 7.0 (TID 125) (95675304fa2d, executor driver, partition 117, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.615 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 116.0 in stage 7.0 (TID 124) in 14 ms on 95675304fa2d (executor driver) (115/200)\n",
      "10-20 14:40:35.607 172.17.0.2:54321      6000    (TID 123)  INFO org.apache.spark.executor.Executor: Finished task 115.0 in stage 7.0 (TID 123). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.615 172.17.0.2:54321      6000    (TID 125)  INFO org.apache.spark.executor.Executor: Running task 117.0 in stage 7.0 (TID 125)\n",
      "10-20 14:40:35.618 172.17.0.2:54321      6000    (TID 122)  INFO org.apache.spark.executor.Executor: Finished task 114.0 in stage 7.0 (TID 122). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.619 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 118.0 in stage 7.0 (TID 126) (95675304fa2d, executor driver, partition 118, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.619 172.17.0.2:54321      6000    (TID 126)  INFO org.apache.spark.executor.Executor: Running task 118.0 in stage 7.0 (TID 126)\n",
      "10-20 14:40:35.619 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 114.0 in stage 7.0 (TID 122) in 27 ms on 95675304fa2d (executor driver) (116/200)\n",
      "10-20 14:40:35.621 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 119.0 in stage 7.0 (TID 127) (95675304fa2d, executor driver, partition 119, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.622 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 115.0 in stage 7.0 (TID 123) in 29 ms on 95675304fa2d (executor driver) (117/200)\n",
      "10-20 14:40:35.623 172.17.0.2:54321      6000    (TID 125)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.624 172.17.0.2:54321      6000    (TID 125)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.628 172.17.0.2:54321      6000    (TID 125)  INFO org.apache.spark.executor.Executor: Finished task 117.0 in stage 7.0 (TID 125). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.629 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 120.0 in stage 7.0 (TID 128) (95675304fa2d, executor driver, partition 120, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.629 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 117.0 in stage 7.0 (TID 125) in 15 ms on 95675304fa2d (executor driver) (118/200)\n",
      "10-20 14:40:35.630 172.17.0.2:54321      6000    (TID 128)  INFO org.apache.spark.executor.Executor: Running task 120.0 in stage 7.0 (TID 128)\n",
      "10-20 14:40:35.631 172.17.0.2:54321      6000    (TID 127)  INFO org.apache.spark.executor.Executor: Running task 119.0 in stage 7.0 (TID 127)\n",
      "10-20 14:40:35.632 172.17.0.2:54321      6000    (TID 126)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.632 172.17.0.2:54321      6000    (TID 126)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.635 172.17.0.2:54321      6000    (TID 126)  INFO org.apache.spark.executor.Executor: Finished task 118.0 in stage 7.0 (TID 126). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.636 172.17.0.2:54321      6000    (TID 121)  INFO org.apache.spark.executor.Executor: Finished task 113.0 in stage 7.0 (TID 121). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.638 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 121.0 in stage 7.0 (TID 129) (95675304fa2d, executor driver, partition 121, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.639 172.17.0.2:54321      6000    (TID 129)  INFO org.apache.spark.executor.Executor: Running task 121.0 in stage 7.0 (TID 129)\n",
      "10-20 14:40:35.639 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 113.0 in stage 7.0 (TID 121) in 48 ms on 95675304fa2d (executor driver) (119/200)\n",
      "10-20 14:40:35.643 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 122.0 in stage 7.0 (TID 130) (95675304fa2d, executor driver, partition 122, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.644 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 118.0 in stage 7.0 (TID 126) in 26 ms on 95675304fa2d (executor driver) (120/200)\n",
      "10-20 14:40:35.645 172.17.0.2:54321      6000    (TID 130)  INFO org.apache.spark.executor.Executor: Running task 122.0 in stage 7.0 (TID 130)\n",
      "10-20 14:40:35.646 172.17.0.2:54321      6000    (TID 129)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.647 172.17.0.2:54321      6000    (TID 129)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.647 172.17.0.2:54321      6000    (TID 128)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.647 172.17.0.2:54321      6000    (TID 128)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.650 172.17.0.2:54321      6000    (TID 130)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.650 172.17.0.2:54321      6000    (TID 130)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.652 172.17.0.2:54321      6000    (TID 129)  INFO org.apache.spark.executor.Executor: Finished task 121.0 in stage 7.0 (TID 129). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.653 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 123.0 in stage 7.0 (TID 131) (95675304fa2d, executor driver, partition 123, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.654 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 121.0 in stage 7.0 (TID 129) in 16 ms on 95675304fa2d (executor driver) (121/200)\n",
      "10-20 14:40:35.654 172.17.0.2:54321      6000    (TID 131)  INFO org.apache.spark.executor.Executor: Running task 123.0 in stage 7.0 (TID 131)\n",
      "10-20 14:40:35.655 172.17.0.2:54321      6000    (TID 127)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.655 172.17.0.2:54321      6000    (TID 127)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.655 172.17.0.2:54321      6000    (TID 128)  INFO org.apache.spark.executor.Executor: Finished task 120.0 in stage 7.0 (TID 128). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.656 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 124.0 in stage 7.0 (TID 132) (95675304fa2d, executor driver, partition 124, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.656 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 120.0 in stage 7.0 (TID 128) in 28 ms on 95675304fa2d (executor driver) (122/200)\n",
      "10-20 14:40:35.657 172.17.0.2:54321      6000    (TID 132)  INFO org.apache.spark.executor.Executor: Running task 124.0 in stage 7.0 (TID 132)\n",
      "10-20 14:40:35.660 172.17.0.2:54321      6000    (TID 131)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.661 172.17.0.2:54321      6000    (TID 131)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.662 172.17.0.2:54321      6000    (TID 132)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.662 172.17.0.2:54321      6000    (TID 132)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.664 172.17.0.2:54321      6000    (TID 130)  INFO org.apache.spark.executor.Executor: Finished task 122.0 in stage 7.0 (TID 130). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.664 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 125.0 in stage 7.0 (TID 133) (95675304fa2d, executor driver, partition 125, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.664 172.17.0.2:54321      6000    (TID 133)  INFO org.apache.spark.executor.Executor: Running task 125.0 in stage 7.0 (TID 133)\n",
      "10-20 14:40:35.665 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 122.0 in stage 7.0 (TID 130) in 21 ms on 95675304fa2d (executor driver) (123/200)\n",
      "10-20 14:40:35.665 172.17.0.2:54321      6000    (TID 127)  INFO org.apache.spark.executor.Executor: Finished task 119.0 in stage 7.0 (TID 127). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.666 172.17.0.2:54321      6000    (TID 131)  INFO org.apache.spark.executor.Executor: Finished task 123.0 in stage 7.0 (TID 131). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.667 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 126.0 in stage 7.0 (TID 134) (95675304fa2d, executor driver, partition 126, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.667 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 123.0 in stage 7.0 (TID 131) in 14 ms on 95675304fa2d (executor driver) (124/200)\n",
      "10-20 14:40:35.668 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 127.0 in stage 7.0 (TID 135) (95675304fa2d, executor driver, partition 127, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.669 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 119.0 in stage 7.0 (TID 127) in 49 ms on 95675304fa2d (executor driver) (125/200)\n",
      "10-20 14:40:35.669 172.17.0.2:54321      6000    (TID 134)  INFO org.apache.spark.executor.Executor: Running task 126.0 in stage 7.0 (TID 134)\n",
      "10-20 14:40:35.669 172.17.0.2:54321      6000    (TID 135)  INFO org.apache.spark.executor.Executor: Running task 127.0 in stage 7.0 (TID 135)\n",
      "10-20 14:40:35.672 172.17.0.2:54321      6000    (TID 134)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.672 172.17.0.2:54321      6000    (TID 134)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.673 172.17.0.2:54321      6000    (TID 135)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.674 172.17.0.2:54321      6000    (TID 135)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.675 172.17.0.2:54321      6000    (TID 134)  INFO org.apache.spark.executor.Executor: Finished task 126.0 in stage 7.0 (TID 134). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.675 172.17.0.2:54321      6000    (TID 133)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.675 172.17.0.2:54321      6000    (TID 133)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.675 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 128.0 in stage 7.0 (TID 136) (95675304fa2d, executor driver, partition 128, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.675 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 126.0 in stage 7.0 (TID 134) in 8 ms on 95675304fa2d (executor driver) (126/200)\n",
      "10-20 14:40:35.676 172.17.0.2:54321      6000    (TID 136)  INFO org.apache.spark.executor.Executor: Running task 128.0 in stage 7.0 (TID 136)\n",
      "10-20 14:40:35.676 172.17.0.2:54321      6000    (TID 132)  INFO org.apache.spark.executor.Executor: Finished task 124.0 in stage 7.0 (TID 132). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.676 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 129.0 in stage 7.0 (TID 137) (95675304fa2d, executor driver, partition 129, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.677 172.17.0.2:54321      6000    (TID 137)  INFO org.apache.spark.executor.Executor: Running task 129.0 in stage 7.0 (TID 137)\n",
      "10-20 14:40:35.677 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 124.0 in stage 7.0 (TID 132) in 21 ms on 95675304fa2d (executor driver) (127/200)\n",
      "10-20 14:40:35.679 172.17.0.2:54321      6000    (TID 135)  INFO org.apache.spark.executor.Executor: Finished task 127.0 in stage 7.0 (TID 135). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.679 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 130.0 in stage 7.0 (TID 138) (95675304fa2d, executor driver, partition 130, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.680 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 127.0 in stage 7.0 (TID 135) in 11 ms on 95675304fa2d (executor driver) (128/200)\n",
      "10-20 14:40:35.680 172.17.0.2:54321      6000    (TID 138)  INFO org.apache.spark.executor.Executor: Running task 130.0 in stage 7.0 (TID 138)\n",
      "10-20 14:40:35.681 172.17.0.2:54321      6000    (TID 136)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.681 172.17.0.2:54321      6000    (TID 136)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.682 172.17.0.2:54321      6000    (TID 137)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.683 172.17.0.2:54321      6000    (TID 137)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.684 172.17.0.2:54321      6000    (TID 136)  INFO org.apache.spark.executor.Executor: Finished task 128.0 in stage 7.0 (TID 136). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.684 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 131.0 in stage 7.0 (TID 139) (95675304fa2d, executor driver, partition 131, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.685 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 128.0 in stage 7.0 (TID 136) in 10 ms on 95675304fa2d (executor driver) (129/200)\n",
      "10-20 14:40:35.685 172.17.0.2:54321      6000    (TID 139)  INFO org.apache.spark.executor.Executor: Running task 131.0 in stage 7.0 (TID 139)\n",
      "10-20 14:40:35.686 172.17.0.2:54321      6000    (TID 138)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.686 172.17.0.2:54321      6000    (TID 138)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.688 172.17.0.2:54321      6000    (TID 139)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.688 172.17.0.2:54321      6000    (TID 139)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.688 172.17.0.2:54321      6000    (TID 133)  INFO org.apache.spark.executor.Executor: Finished task 125.0 in stage 7.0 (TID 133). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.689 172.17.0.2:54321      6000    (TID 137)  INFO org.apache.spark.executor.Executor: Finished task 129.0 in stage 7.0 (TID 137). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.690 172.17.0.2:54321      6000    (TID 138)  INFO org.apache.spark.executor.Executor: Finished task 130.0 in stage 7.0 (TID 138). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.690 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 132.0 in stage 7.0 (TID 140) (95675304fa2d, executor driver, partition 132, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.691 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 129.0 in stage 7.0 (TID 137) in 15 ms on 95675304fa2d (executor driver) (130/200)\n",
      "10-20 14:40:35.691 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 133.0 in stage 7.0 (TID 141) (95675304fa2d, executor driver, partition 133, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.692 172.17.0.2:54321      6000    (TID 141)  INFO org.apache.spark.executor.Executor: Running task 133.0 in stage 7.0 (TID 141)\n",
      "10-20 14:40:35.692 172.17.0.2:54321      6000    (TID 139)  INFO org.apache.spark.executor.Executor: Finished task 131.0 in stage 7.0 (TID 139). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.692 172.17.0.2:54321      6000    (TID 140)  INFO org.apache.spark.executor.Executor: Running task 132.0 in stage 7.0 (TID 140)\n",
      "10-20 14:40:35.692 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 134.0 in stage 7.0 (TID 142) (95675304fa2d, executor driver, partition 134, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.693 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 125.0 in stage 7.0 (TID 133) in 29 ms on 95675304fa2d (executor driver) (131/200)\n",
      "10-20 14:40:35.693 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 130.0 in stage 7.0 (TID 138) in 14 ms on 95675304fa2d (executor driver) (132/200)\n",
      "10-20 14:40:35.693 172.17.0.2:54321      6000    (TID 142)  INFO org.apache.spark.executor.Executor: Running task 134.0 in stage 7.0 (TID 142)\n",
      "10-20 14:40:35.697 172.17.0.2:54321      6000    (TID 141)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.697 172.17.0.2:54321      6000    (TID 140)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.697 172.17.0.2:54321      6000    (TID 140)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.698 172.17.0.2:54321      6000    (TID 141)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.698 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 135.0 in stage 7.0 (TID 143) (95675304fa2d, executor driver, partition 135, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.698 172.17.0.2:54321      6000    (TID 143)  INFO org.apache.spark.executor.Executor: Running task 135.0 in stage 7.0 (TID 143)\n",
      "10-20 14:40:35.701 172.17.0.2:54321      6000    (TID 141)  INFO org.apache.spark.executor.Executor: Finished task 133.0 in stage 7.0 (TID 141). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.697 172.17.0.2:54321      6000    (TID 142)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.701 172.17.0.2:54321      6000    (TID 142)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:40:35.701 172.17.0.2:54321      6000    (TID 143)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.702 172.17.0.2:54321      6000    (TID 143)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:40:35.698 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 131.0 in stage 7.0 (TID 139) in 14 ms on 95675304fa2d (executor driver) (133/200)\n",
      "10-20 14:40:35.703 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 136.0 in stage 7.0 (TID 144) (95675304fa2d, executor driver, partition 136, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.704 172.17.0.2:54321      6000    (TID 144)  INFO org.apache.spark.executor.Executor: Running task 136.0 in stage 7.0 (TID 144)\n",
      "10-20 14:40:35.704 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 133.0 in stage 7.0 (TID 141) in 13 ms on 95675304fa2d (executor driver) (134/200)\n",
      "10-20 14:40:35.706 172.17.0.2:54321      6000    (TID 143)  INFO org.apache.spark.executor.Executor: Finished task 135.0 in stage 7.0 (TID 143). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.707 172.17.0.2:54321      6000    (TID 140)  INFO org.apache.spark.executor.Executor: Finished task 132.0 in stage 7.0 (TID 140). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.707 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 137.0 in stage 7.0 (TID 145) (95675304fa2d, executor driver, partition 137, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.708 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 138.0 in stage 7.0 (TID 146) (95675304fa2d, executor driver, partition 138, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.708 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 135.0 in stage 7.0 (TID 143) in 10 ms on 95675304fa2d (executor driver) (135/200)\n",
      "10-20 14:40:35.709 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 132.0 in stage 7.0 (TID 140) in 19 ms on 95675304fa2d (executor driver) (136/200)\n",
      "10-20 14:40:35.709 172.17.0.2:54321      6000    (TID 146)  INFO org.apache.spark.executor.Executor: Running task 138.0 in stage 7.0 (TID 146)\n",
      "10-20 14:40:35.710 172.17.0.2:54321      6000    (TID 145)  INFO org.apache.spark.executor.Executor: Running task 137.0 in stage 7.0 (TID 145)\n",
      "10-20 14:40:35.711 172.17.0.2:54321      6000    (TID 144)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.711 172.17.0.2:54321      6000    (TID 144)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.713 172.17.0.2:54321      6000    (TID 146)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.714 172.17.0.2:54321      6000    (TID 146)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.714 172.17.0.2:54321      6000    (TID 142)  INFO org.apache.spark.executor.Executor: Finished task 134.0 in stage 7.0 (TID 142). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.715 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 139.0 in stage 7.0 (TID 147) (95675304fa2d, executor driver, partition 139, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.715 172.17.0.2:54321      6000    (TID 145)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.715 172.17.0.2:54321      6000    (TID 145)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.715 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 134.0 in stage 7.0 (TID 142) in 23 ms on 95675304fa2d (executor driver) (137/200)\n",
      "10-20 14:40:35.716 172.17.0.2:54321      6000    (TID 147)  INFO org.apache.spark.executor.Executor: Running task 139.0 in stage 7.0 (TID 147)\n",
      "10-20 14:40:35.717 172.17.0.2:54321      6000    (TID 144)  INFO org.apache.spark.executor.Executor: Finished task 136.0 in stage 7.0 (TID 144). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.719 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 140.0 in stage 7.0 (TID 148) (95675304fa2d, executor driver, partition 140, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.719 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 136.0 in stage 7.0 (TID 144) in 16 ms on 95675304fa2d (executor driver) (138/200)\n",
      "10-20 14:40:35.719 172.17.0.2:54321      6000    (TID 148)  INFO org.apache.spark.executor.Executor: Running task 140.0 in stage 7.0 (TID 148)\n",
      "10-20 14:40:35.720 172.17.0.2:54321      6000    (TID 146)  INFO org.apache.spark.executor.Executor: Finished task 138.0 in stage 7.0 (TID 146). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.721 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 141.0 in stage 7.0 (TID 149) (95675304fa2d, executor driver, partition 141, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.721 172.17.0.2:54321      6000    (TID 149)  INFO org.apache.spark.executor.Executor: Running task 141.0 in stage 7.0 (TID 149)\n",
      "10-20 14:40:35.721 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 138.0 in stage 7.0 (TID 146) in 13 ms on 95675304fa2d (executor driver) (139/200)\n",
      "10-20 14:40:35.723 172.17.0.2:54321      6000    (TID 147)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.723 172.17.0.2:54321      6000    (TID 147)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.725 172.17.0.2:54321      6000    (TID 149)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.725 172.17.0.2:54321      6000    (TID 149)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.725 172.17.0.2:54321      6000    (TID 145)  INFO org.apache.spark.executor.Executor: Finished task 137.0 in stage 7.0 (TID 145). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.726 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 142.0 in stage 7.0 (TID 150) (95675304fa2d, executor driver, partition 142, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.726 172.17.0.2:54321      6000    (TID 150)  INFO org.apache.spark.executor.Executor: Running task 142.0 in stage 7.0 (TID 150)\n",
      "10-20 14:40:35.726 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 137.0 in stage 7.0 (TID 145) in 19 ms on 95675304fa2d (executor driver) (140/200)\n",
      "10-20 14:40:35.728 172.17.0.2:54321      6000    (TID 149)  INFO org.apache.spark.executor.Executor: Finished task 141.0 in stage 7.0 (TID 149). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.729 172.17.0.2:54321      6000    (TID 148)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.729 172.17.0.2:54321      6000    (TID 148)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.730 172.17.0.2:54321      6000    (TID 147)  INFO org.apache.spark.executor.Executor: Finished task 139.0 in stage 7.0 (TID 147). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.730 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 143.0 in stage 7.0 (TID 151) (95675304fa2d, executor driver, partition 143, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.730 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 141.0 in stage 7.0 (TID 149) in 9 ms on 95675304fa2d (executor driver) (141/200)\n",
      "10-20 14:40:35.730 172.17.0.2:54321      6000    (TID 151)  INFO org.apache.spark.executor.Executor: Running task 143.0 in stage 7.0 (TID 151)\n",
      "10-20 14:40:35.733 172.17.0.2:54321      6000    (TID 150)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.733 172.17.0.2:54321      6000    (TID 150)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.734 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 144.0 in stage 7.0 (TID 152) (95675304fa2d, executor driver, partition 144, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.735 172.17.0.2:54321      6000    (TID 151)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.735 172.17.0.2:54321      6000    (TID 152)  INFO org.apache.spark.executor.Executor: Running task 144.0 in stage 7.0 (TID 152)\n",
      "10-20 14:40:35.735 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 139.0 in stage 7.0 (TID 147) in 20 ms on 95675304fa2d (executor driver) (142/200)\n",
      "10-20 14:40:35.735 172.17.0.2:54321      6000    (TID 148)  INFO org.apache.spark.executor.Executor: Finished task 140.0 in stage 7.0 (TID 148). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.736 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 145.0 in stage 7.0 (TID 153) (95675304fa2d, executor driver, partition 145, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.736 172.17.0.2:54321      6000    (TID 153)  INFO org.apache.spark.executor.Executor: Running task 145.0 in stage 7.0 (TID 153)\n",
      "10-20 14:40:35.737 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 140.0 in stage 7.0 (TID 148) in 19 ms on 95675304fa2d (executor driver) (143/200)\n",
      "10-20 14:40:35.738 172.17.0.2:54321      6000    (TID 150)  INFO org.apache.spark.executor.Executor: Finished task 142.0 in stage 7.0 (TID 150). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.738 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 146.0 in stage 7.0 (TID 154) (95675304fa2d, executor driver, partition 146, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.738 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 142.0 in stage 7.0 (TID 150) in 12 ms on 95675304fa2d (executor driver) (144/200)\n",
      "10-20 14:40:35.741 172.17.0.2:54321      6000    (TID 151)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.741 172.17.0.2:54321      6000    (TID 152)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.741 172.17.0.2:54321      6000    (TID 152)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.742 172.17.0.2:54321      6000    (TID 153)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.742 172.17.0.2:54321      6000    (TID 153)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.743 172.17.0.2:54321      6000    (TID 151)  INFO org.apache.spark.executor.Executor: Finished task 143.0 in stage 7.0 (TID 151). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.744 172.17.0.2:54321      6000    (TID 152)  INFO org.apache.spark.executor.Executor: Finished task 144.0 in stage 7.0 (TID 152). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.744 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 147.0 in stage 7.0 (TID 155) (95675304fa2d, executor driver, partition 147, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.744 172.17.0.2:54321      6000    (TID 155)  INFO org.apache.spark.executor.Executor: Running task 147.0 in stage 7.0 (TID 155)\n",
      "10-20 14:40:35.744 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 143.0 in stage 7.0 (TID 151) in 14 ms on 95675304fa2d (executor driver) (145/200)\n",
      "10-20 14:40:35.745 172.17.0.2:54321      6000    (TID 153)  INFO org.apache.spark.executor.Executor: Finished task 145.0 in stage 7.0 (TID 153). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.748 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 148.0 in stage 7.0 (TID 156) (95675304fa2d, executor driver, partition 148, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.748 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 145.0 in stage 7.0 (TID 153) in 12 ms on 95675304fa2d (executor driver) (146/200)\n",
      "10-20 14:40:35.749 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 149.0 in stage 7.0 (TID 157) (95675304fa2d, executor driver, partition 149, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.750 172.17.0.2:54321      6000    (TID 157)  INFO org.apache.spark.executor.Executor: Running task 149.0 in stage 7.0 (TID 157)\n",
      "10-20 14:40:35.750 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 144.0 in stage 7.0 (TID 152) in 16 ms on 95675304fa2d (executor driver) (147/200)\n",
      "10-20 14:40:35.752 172.17.0.2:54321      6000    (TID 154)  INFO org.apache.spark.executor.Executor: Running task 146.0 in stage 7.0 (TID 154)\n",
      "10-20 14:40:35.753 172.17.0.2:54321      6000    (TID 156)  INFO org.apache.spark.executor.Executor: Running task 148.0 in stage 7.0 (TID 156)\n",
      "10-20 14:40:35.755 172.17.0.2:54321      6000    (TID 155)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.755 172.17.0.2:54321      6000    (TID 155)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.756 172.17.0.2:54321      6000    (TID 157)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.756 172.17.0.2:54321      6000    (TID 157)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.758 172.17.0.2:54321      6000    (TID 155)  INFO org.apache.spark.executor.Executor: Finished task 147.0 in stage 7.0 (TID 155). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.758 172.17.0.2:54321      6000    (TID 154)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.759 172.17.0.2:54321      6000    (TID 154)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 14:40:35.758 172.17.0.2:54321      6000    (TID 156)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.759 172.17.0.2:54321      6000    (TID 156)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.759 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 150.0 in stage 7.0 (TID 158) (95675304fa2d, executor driver, partition 150, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.759 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 147.0 in stage 7.0 (TID 155) in 15 ms on 95675304fa2d (executor driver) (148/200)\n",
      "10-20 14:40:35.763 172.17.0.2:54321      6000    (TID 156)  INFO org.apache.spark.executor.Executor: Finished task 148.0 in stage 7.0 (TID 156). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.764 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 151.0 in stage 7.0 (TID 159) (95675304fa2d, executor driver, partition 151, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.764 172.17.0.2:54321      6000    (TID 157)  INFO org.apache.spark.executor.Executor: Finished task 149.0 in stage 7.0 (TID 157). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.764 172.17.0.2:54321      6000    (TID 158)  INFO org.apache.spark.executor.Executor: Running task 150.0 in stage 7.0 (TID 158)\n",
      "10-20 14:40:35.764 172.17.0.2:54321      6000    (TID 159)  INFO org.apache.spark.executor.Executor: Running task 151.0 in stage 7.0 (TID 159)\n",
      "10-20 14:40:35.764 172.17.0.2:54321      6000    (TID 154)  INFO org.apache.spark.executor.Executor: Finished task 146.0 in stage 7.0 (TID 154). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.764 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 148.0 in stage 7.0 (TID 156) in 17 ms on 95675304fa2d (executor driver) (149/200)\n",
      "10-20 14:40:35.765 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 152.0 in stage 7.0 (TID 160) (95675304fa2d, executor driver, partition 152, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.765 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 146.0 in stage 7.0 (TID 154) in 27 ms on 95675304fa2d (executor driver) (150/200)\n",
      "10-20 14:40:35.766 172.17.0.2:54321      6000    (TID 160)  INFO org.apache.spark.executor.Executor: Running task 152.0 in stage 7.0 (TID 160)\n",
      "10-20 14:40:35.769 172.17.0.2:54321      6000    (TID 159)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.769 172.17.0.2:54321      6000    (TID 159)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.769 172.17.0.2:54321      6000    (TID 158)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.769 172.17.0.2:54321      6000    (TID 158)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.770 172.17.0.2:54321      6000    (TID 160)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.770 172.17.0.2:54321      6000    (TID 160)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.771 172.17.0.2:54321      6000    (TID 159)  INFO org.apache.spark.executor.Executor: Finished task 151.0 in stage 7.0 (TID 159). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.772 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 153.0 in stage 7.0 (TID 161) (95675304fa2d, executor driver, partition 153, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.772 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 149.0 in stage 7.0 (TID 157) in 23 ms on 95675304fa2d (executor driver) (151/200)\n",
      "10-20 14:40:35.772 172.17.0.2:54321      6000    (TID 160)  INFO org.apache.spark.executor.Executor: Finished task 152.0 in stage 7.0 (TID 160). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.772 172.17.0.2:54321      6000    (TID 161)  INFO org.apache.spark.executor.Executor: Running task 153.0 in stage 7.0 (TID 161)\n",
      "10-20 14:40:35.773 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 151.0 in stage 7.0 (TID 159) in 10 ms on 95675304fa2d (executor driver) (152/200)\n",
      "10-20 14:40:35.774 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 154.0 in stage 7.0 (TID 162) (95675304fa2d, executor driver, partition 154, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.774 172.17.0.2:54321      6000    (TID 162)  INFO org.apache.spark.executor.Executor: Running task 154.0 in stage 7.0 (TID 162)\n",
      "10-20 14:40:35.774 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 155.0 in stage 7.0 (TID 163) (95675304fa2d, executor driver, partition 155, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.775 172.17.0.2:54321      6000    (TID 163)  INFO org.apache.spark.executor.Executor: Running task 155.0 in stage 7.0 (TID 163)\n",
      "10-20 14:40:35.775 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 152.0 in stage 7.0 (TID 160) in 10 ms on 95675304fa2d (executor driver) (153/200)\n",
      "10-20 14:40:35.776 172.17.0.2:54321      6000    (TID 161)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.776 172.17.0.2:54321      6000    (TID 161)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.778 172.17.0.2:54321      6000    (TID 162)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.778 172.17.0.2:54321      6000    (TID 162)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.778 172.17.0.2:54321      6000    (TID 163)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.778 172.17.0.2:54321      6000    (TID 158)  INFO org.apache.spark.executor.Executor: Finished task 150.0 in stage 7.0 (TID 158). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.778 172.17.0.2:54321      6000    (TID 163)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.779 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 156.0 in stage 7.0 (TID 164) (95675304fa2d, executor driver, partition 156, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.779 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 150.0 in stage 7.0 (TID 158) in 20 ms on 95675304fa2d (executor driver) (154/200)\n",
      "10-20 14:40:35.780 172.17.0.2:54321      6000    (TID 164)  INFO org.apache.spark.executor.Executor: Running task 156.0 in stage 7.0 (TID 164)\n",
      "10-20 14:40:35.778 172.17.0.2:54321      6000    (TID 161)  INFO org.apache.spark.executor.Executor: Finished task 153.0 in stage 7.0 (TID 161). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.781 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 157.0 in stage 7.0 (TID 165) (95675304fa2d, executor driver, partition 157, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.781 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 153.0 in stage 7.0 (TID 161) in 9 ms on 95675304fa2d (executor driver) (155/200)\n",
      "10-20 14:40:35.783 172.17.0.2:54321      6000    (TID 163)  INFO org.apache.spark.executor.Executor: Finished task 155.0 in stage 7.0 (TID 163). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.781 172.17.0.2:54321      6000    (TID 162)  INFO org.apache.spark.executor.Executor: Finished task 154.0 in stage 7.0 (TID 162). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.783 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 158.0 in stage 7.0 (TID 166) (95675304fa2d, executor driver, partition 158, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.784 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 159.0 in stage 7.0 (TID 167) (95675304fa2d, executor driver, partition 159, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.784 172.17.0.2:54321      6000    (TID 167)  INFO org.apache.spark.executor.Executor: Running task 159.0 in stage 7.0 (TID 167)\n",
      "10-20 14:40:35.784 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 155.0 in stage 7.0 (TID 163) in 10 ms on 95675304fa2d (executor driver) (156/200)\n",
      "10-20 14:40:35.784 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 154.0 in stage 7.0 (TID 162) in 10 ms on 95675304fa2d (executor driver) (157/200)\n",
      "10-20 14:40:35.785 172.17.0.2:54321      6000    (TID 164)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.785 172.17.0.2:54321      6000    (TID 164)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.786 172.17.0.2:54321      6000    (TID 166)  INFO org.apache.spark.executor.Executor: Running task 158.0 in stage 7.0 (TID 166)\n",
      "10-20 14:40:35.788 172.17.0.2:54321      6000    (TID 164)  INFO org.apache.spark.executor.Executor: Finished task 156.0 in stage 7.0 (TID 164). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.789 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 160.0 in stage 7.0 (TID 168) (95675304fa2d, executor driver, partition 160, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.789 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 156.0 in stage 7.0 (TID 164) in 10 ms on 95675304fa2d (executor driver) (158/200)\n",
      "10-20 14:40:35.790 172.17.0.2:54321      6000    (TID 168)  INFO org.apache.spark.executor.Executor: Running task 160.0 in stage 7.0 (TID 168)\n",
      "10-20 14:40:35.790 172.17.0.2:54321      6000    (TID 166)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.790 172.17.0.2:54321      6000    (TID 166)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.790 172.17.0.2:54321      6000    (TID 167)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.791 172.17.0.2:54321      6000    (TID 167)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:40:35.790 172.17.0.2:54321      6000    (TID 165)  INFO org.apache.spark.executor.Executor: Running task 157.0 in stage 7.0 (TID 165)\n",
      "10-20 14:40:35.794 172.17.0.2:54321      6000    (TID 168)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.794 172.17.0.2:54321      6000    (TID 168)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.794 172.17.0.2:54321      6000    (TID 167)  INFO org.apache.spark.executor.Executor: Finished task 159.0 in stage 7.0 (TID 167). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.795 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 161.0 in stage 7.0 (TID 169) (95675304fa2d, executor driver, partition 161, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.796 172.17.0.2:54321      6000    (TID 169)  INFO org.apache.spark.executor.Executor: Running task 161.0 in stage 7.0 (TID 169)\n",
      "10-20 14:40:35.796 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 159.0 in stage 7.0 (TID 167) in 13 ms on 95675304fa2d (executor driver) (159/200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=====================================================> (195 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:40:35.799 172.17.0.2:54321      6000    (TID 169)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.799 172.17.0.2:54321      6000    (TID 169)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.801 172.17.0.2:54321      6000    (TID 166)  INFO org.apache.spark.executor.Executor: Finished task 158.0 in stage 7.0 (TID 166). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.802 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 162.0 in stage 7.0 (TID 170) (95675304fa2d, executor driver, partition 162, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.802 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 158.0 in stage 7.0 (TID 166) in 19 ms on 95675304fa2d (executor driver) (160/200)\n",
      "10-20 14:40:35.803 172.17.0.2:54321      6000    (TID 165)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.803 172.17.0.2:54321      6000    (TID 165)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.804 172.17.0.2:54321      6000    (TID 170)  INFO org.apache.spark.executor.Executor: Running task 162.0 in stage 7.0 (TID 170)\n",
      "10-20 14:40:35.808 172.17.0.2:54321      6000    (TID 169)  INFO org.apache.spark.executor.Executor: Finished task 161.0 in stage 7.0 (TID 169). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.808 172.17.0.2:54321      6000    (TID 168)  INFO org.apache.spark.executor.Executor: Finished task 160.0 in stage 7.0 (TID 168). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.809 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 163.0 in stage 7.0 (TID 171) (95675304fa2d, executor driver, partition 163, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.809 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 161.0 in stage 7.0 (TID 169) in 14 ms on 95675304fa2d (executor driver) (161/200)\n",
      "10-20 14:40:35.809 172.17.0.2:54321      6000    (TID 171)  INFO org.apache.spark.executor.Executor: Running task 163.0 in stage 7.0 (TID 171)\n",
      "10-20 14:40:35.810 172.17.0.2:54321      6000    (TID 170)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.810 172.17.0.2:54321      6000    (TID 170)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:40:35.811 172.17.0.2:54321      6000    (TID 165)  INFO org.apache.spark.executor.Executor: Finished task 157.0 in stage 7.0 (TID 165). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.812 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 164.0 in stage 7.0 (TID 172) (95675304fa2d, executor driver, partition 164, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.813 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 157.0 in stage 7.0 (TID 165) in 33 ms on 95675304fa2d (executor driver) (162/200)\n",
      "10-20 14:40:35.813 172.17.0.2:54321      6000    (TID 172)  INFO org.apache.spark.executor.Executor: Running task 164.0 in stage 7.0 (TID 172)\n",
      "10-20 14:40:35.814 172.17.0.2:54321      6000    (TID 170)  INFO org.apache.spark.executor.Executor: Finished task 162.0 in stage 7.0 (TID 170). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.814 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 165.0 in stage 7.0 (TID 173) (95675304fa2d, executor driver, partition 165, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.818 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 166.0 in stage 7.0 (TID 174) (95675304fa2d, executor driver, partition 166, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.818 172.17.0.2:54321      6000    (TID 172)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.818 172.17.0.2:54321      6000    (TID 172)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.818 172.17.0.2:54321      6000    (TID 174)  INFO org.apache.spark.executor.Executor: Running task 166.0 in stage 7.0 (TID 174)\n",
      "10-20 14:40:35.819 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 162.0 in stage 7.0 (TID 170) in 17 ms on 95675304fa2d (executor driver) (163/200)\n",
      "10-20 14:40:35.819 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 160.0 in stage 7.0 (TID 168) in 30 ms on 95675304fa2d (executor driver) (164/200)\n",
      "10-20 14:40:35.820 172.17.0.2:54321      6000    (TID 171)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.821 172.17.0.2:54321      6000    (TID 171)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.822 172.17.0.2:54321      6000    (TID 174)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.822 172.17.0.2:54321      6000    (TID 174)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.822 172.17.0.2:54321      6000    (TID 172)  INFO org.apache.spark.executor.Executor: Finished task 164.0 in stage 7.0 (TID 172). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.823 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 167.0 in stage 7.0 (TID 175) (95675304fa2d, executor driver, partition 167, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.823 172.17.0.2:54321      6000    (TID 171)  INFO org.apache.spark.executor.Executor: Finished task 163.0 in stage 7.0 (TID 171). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.824 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 164.0 in stage 7.0 (TID 172) in 12 ms on 95675304fa2d (executor driver) (165/200)\n",
      "10-20 14:40:35.824 172.17.0.2:54321      6000    (TID 175)  INFO org.apache.spark.executor.Executor: Running task 167.0 in stage 7.0 (TID 175)\n",
      "10-20 14:40:35.826 172.17.0.2:54321      6000    (TID 174)  INFO org.apache.spark.executor.Executor: Finished task 166.0 in stage 7.0 (TID 174). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.828 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 168.0 in stage 7.0 (TID 176) (95675304fa2d, executor driver, partition 168, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.829 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 166.0 in stage 7.0 (TID 174) in 11 ms on 95675304fa2d (executor driver) (166/200)\n",
      "10-20 14:40:35.829 172.17.0.2:54321      6000    (TID 176)  INFO org.apache.spark.executor.Executor: Running task 168.0 in stage 7.0 (TID 176)\n",
      "10-20 14:40:35.830 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 169.0 in stage 7.0 (TID 177) (95675304fa2d, executor driver, partition 169, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.830 172.17.0.2:54321      6000    (TID 177)  INFO org.apache.spark.executor.Executor: Running task 169.0 in stage 7.0 (TID 177)\n",
      "10-20 14:40:35.831 172.17.0.2:54321      6000    (TID 175)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.831 172.17.0.2:54321      6000    (TID 175)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.833 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 163.0 in stage 7.0 (TID 171) in 24 ms on 95675304fa2d (executor driver) (167/200)\n",
      "10-20 14:40:35.833 172.17.0.2:54321      6000    (TID 176)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.834 172.17.0.2:54321      6000    (TID 176)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.835 172.17.0.2:54321      6000    (TID 177)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.835 172.17.0.2:54321      6000    (TID 177)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.835 172.17.0.2:54321      6000    (TID 175)  INFO org.apache.spark.executor.Executor: Finished task 167.0 in stage 7.0 (TID 175). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.836 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 170.0 in stage 7.0 (TID 178) (95675304fa2d, executor driver, partition 170, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.837 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 167.0 in stage 7.0 (TID 175) in 14 ms on 95675304fa2d (executor driver) (168/200)\n",
      "10-20 14:40:35.837 172.17.0.2:54321      6000    (TID 178)  INFO org.apache.spark.executor.Executor: Running task 170.0 in stage 7.0 (TID 178)\n",
      "10-20 14:40:35.840 172.17.0.2:54321      6000    (TID 173)  INFO org.apache.spark.executor.Executor: Running task 165.0 in stage 7.0 (TID 173)\n",
      "10-20 14:40:35.841 172.17.0.2:54321      6000    (TID 178)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.841 172.17.0.2:54321      6000    (TID 178)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.844 172.17.0.2:54321      6000    (TID 173)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.844 172.17.0.2:54321      6000    (TID 173)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.844 172.17.0.2:54321      6000    (TID 178)  INFO org.apache.spark.executor.Executor: Finished task 170.0 in stage 7.0 (TID 178). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.844 172.17.0.2:54321      6000    (TID 176)  INFO org.apache.spark.executor.Executor: Finished task 168.0 in stage 7.0 (TID 176). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.845 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 171.0 in stage 7.0 (TID 179) (95675304fa2d, executor driver, partition 171, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.845 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 170.0 in stage 7.0 (TID 178) in 9 ms on 95675304fa2d (executor driver) (169/200)\n",
      "10-20 14:40:35.845 172.17.0.2:54321      6000    (TID 179)  INFO org.apache.spark.executor.Executor: Running task 171.0 in stage 7.0 (TID 179)\n",
      "10-20 14:40:35.846 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 172.0 in stage 7.0 (TID 180) (95675304fa2d, executor driver, partition 172, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.846 172.17.0.2:54321      6000    (TID 180)  INFO org.apache.spark.executor.Executor: Running task 172.0 in stage 7.0 (TID 180)\n",
      "10-20 14:40:35.846 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 168.0 in stage 7.0 (TID 176) in 18 ms on 95675304fa2d (executor driver) (170/200)\n",
      "10-20 14:40:35.849 172.17.0.2:54321      6000    (TID 173)  INFO org.apache.spark.executor.Executor: Finished task 165.0 in stage 7.0 (TID 173). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.849 172.17.0.2:54321      6000    (TID 180)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.849 172.17.0.2:54321      6000    (TID 180)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.849 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 173.0 in stage 7.0 (TID 181) (95675304fa2d, executor driver, partition 173, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.850 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 165.0 in stage 7.0 (TID 173) in 36 ms on 95675304fa2d (executor driver) (171/200)\n",
      "10-20 14:40:35.850 172.17.0.2:54321      6000    (TID 177)  INFO org.apache.spark.executor.Executor: Finished task 169.0 in stage 7.0 (TID 177). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.851 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 174.0 in stage 7.0 (TID 182) (95675304fa2d, executor driver, partition 174, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.851 172.17.0.2:54321      6000    (TID 181)  INFO org.apache.spark.executor.Executor: Running task 173.0 in stage 7.0 (TID 181)\n",
      "10-20 14:40:35.851 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 169.0 in stage 7.0 (TID 177) in 22 ms on 95675304fa2d (executor driver) (172/200)\n",
      "10-20 14:40:35.851 172.17.0.2:54321      6000    (TID 182)  INFO org.apache.spark.executor.Executor: Running task 174.0 in stage 7.0 (TID 182)\n",
      "10-20 14:40:35.853 172.17.0.2:54321      6000    (TID 179)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.853 172.17.0.2:54321      6000    (TID 179)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.855 172.17.0.2:54321      6000    (TID 182)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.855 172.17.0.2:54321      6000    (TID 182)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.856 172.17.0.2:54321      6000    (TID 179)  INFO org.apache.spark.executor.Executor: Finished task 171.0 in stage 7.0 (TID 179). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.856 172.17.0.2:54321      6000    (TID 181)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.856 172.17.0.2:54321      6000    (TID 181)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:40:35.859 172.17.0.2:54321      6000    (TID 181)  INFO org.apache.spark.executor.Executor: Finished task 173.0 in stage 7.0 (TID 181). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.853 172.17.0.2:54321      6000    (TID 180)  INFO org.apache.spark.executor.Executor: Finished task 172.0 in stage 7.0 (TID 180). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.856 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 175.0 in stage 7.0 (TID 183) (95675304fa2d, executor driver, partition 175, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.860 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 176.0 in stage 7.0 (TID 184) (95675304fa2d, executor driver, partition 176, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.860 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 171.0 in stage 7.0 (TID 179) in 15 ms on 95675304fa2d (executor driver) (173/200)\n",
      "10-20 14:40:35.860 172.17.0.2:54321      6000    (TID 184)  INFO org.apache.spark.executor.Executor: Running task 176.0 in stage 7.0 (TID 184)\n",
      "10-20 14:40:35.860 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 177.0 in stage 7.0 (TID 185) (95675304fa2d, executor driver, partition 177, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.861 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 172.0 in stage 7.0 (TID 180) in 15 ms on 95675304fa2d (executor driver) (174/200)\n",
      "10-20 14:40:35.861 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 173.0 in stage 7.0 (TID 181) in 12 ms on 95675304fa2d (executor driver) (175/200)\n",
      "10-20 14:40:35.861 172.17.0.2:54321      6000    (TID 185)  INFO org.apache.spark.executor.Executor: Running task 177.0 in stage 7.0 (TID 185)\n",
      "10-20 14:40:35.862 172.17.0.2:54321      6000    (TID 183)  INFO org.apache.spark.executor.Executor: Running task 175.0 in stage 7.0 (TID 183)\n",
      "10-20 14:40:35.865 172.17.0.2:54321      6000    (TID 182)  INFO org.apache.spark.executor.Executor: Finished task 174.0 in stage 7.0 (TID 182). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.866 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 178.0 in stage 7.0 (TID 186) (95675304fa2d, executor driver, partition 178, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.866 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 174.0 in stage 7.0 (TID 182) in 15 ms on 95675304fa2d (executor driver) (176/200)\n",
      "10-20 14:40:35.867 172.17.0.2:54321      6000    (TID 186)  INFO org.apache.spark.executor.Executor: Running task 178.0 in stage 7.0 (TID 186)\n",
      "10-20 14:40:35.868 172.17.0.2:54321      6000    (TID 185)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.868 172.17.0.2:54321      6000    (TID 185)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.869 172.17.0.2:54321      6000    (TID 184)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.869 172.17.0.2:54321      6000    (TID 184)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.869 172.17.0.2:54321      6000    (TID 186)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.869 172.17.0.2:54321      6000    (TID 186)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.870 172.17.0.2:54321      6000    (TID 183)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.870 172.17.0.2:54321      6000    (TID 183)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.873 172.17.0.2:54321      6000    (TID 183)  INFO org.apache.spark.executor.Executor: Finished task 175.0 in stage 7.0 (TID 183). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.873 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 179.0 in stage 7.0 (TID 187) (95675304fa2d, executor driver, partition 179, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.874 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 175.0 in stage 7.0 (TID 183) in 18 ms on 95675304fa2d (executor driver) (177/200)\n",
      "10-20 14:40:35.876 172.17.0.2:54321      6000    (TID 184)  INFO org.apache.spark.executor.Executor: Finished task 176.0 in stage 7.0 (TID 184). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.877 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 180.0 in stage 7.0 (TID 188) (95675304fa2d, executor driver, partition 180, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.878 172.17.0.2:54321      6000    (TID 188)  INFO org.apache.spark.executor.Executor: Running task 180.0 in stage 7.0 (TID 188)\n",
      "10-20 14:40:35.878 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 176.0 in stage 7.0 (TID 184) in 18 ms on 95675304fa2d (executor driver) (178/200)\n",
      "10-20 14:40:35.882 172.17.0.2:54321      6000    (TID 185)  INFO org.apache.spark.executor.Executor: Finished task 177.0 in stage 7.0 (TID 185). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.883 172.17.0.2:54321      6000    (TID 187)  INFO org.apache.spark.executor.Executor: Running task 179.0 in stage 7.0 (TID 187)\n",
      "10-20 14:40:35.885 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 181.0 in stage 7.0 (TID 189) (95675304fa2d, executor driver, partition 181, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.885 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 177.0 in stage 7.0 (TID 185) in 25 ms on 95675304fa2d (executor driver) (179/200)\n",
      "10-20 14:40:35.885 172.17.0.2:54321      6000    (TID 186)  INFO org.apache.spark.executor.Executor: Finished task 178.0 in stage 7.0 (TID 186). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.886 172.17.0.2:54321      6000    (TID 189)  INFO org.apache.spark.executor.Executor: Running task 181.0 in stage 7.0 (TID 189)\n",
      "10-20 14:40:35.886 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 182.0 in stage 7.0 (TID 190) (95675304fa2d, executor driver, partition 182, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.886 172.17.0.2:54321      6000    (TID 190)  INFO org.apache.spark.executor.Executor: Running task 182.0 in stage 7.0 (TID 190)\n",
      "10-20 14:40:35.887 172.17.0.2:54321      6000    (TID 188)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.887 172.17.0.2:54321      6000    (TID 188)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.889 172.17.0.2:54321      6000    (TID 189)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.889 172.17.0.2:54321      6000    (TID 189)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.890 172.17.0.2:54321      6000    (TID 188)  INFO org.apache.spark.executor.Executor: Finished task 180.0 in stage 7.0 (TID 188). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.890 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 183.0 in stage 7.0 (TID 191) (95675304fa2d, executor driver, partition 183, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.891 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 178.0 in stage 7.0 (TID 186) in 26 ms on 95675304fa2d (executor driver) (180/200)\n",
      "10-20 14:40:35.891 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 180.0 in stage 7.0 (TID 188) in 14 ms on 95675304fa2d (executor driver) (181/200)\n",
      "10-20 14:40:35.891 172.17.0.2:54321      6000    (TID 191)  INFO org.apache.spark.executor.Executor: Running task 183.0 in stage 7.0 (TID 191)\n",
      "10-20 14:40:35.892 172.17.0.2:54321      6000    (TID 187)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.892 172.17.0.2:54321      6000    (TID 187)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.894 172.17.0.2:54321      6000    (TID 190)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.895 172.17.0.2:54321      6000    (TID 190)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.894 172.17.0.2:54321      6000    (TID 191)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.895 172.17.0.2:54321      6000    (TID 191)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.895 172.17.0.2:54321      6000    (TID 187)  INFO org.apache.spark.executor.Executor: Finished task 179.0 in stage 7.0 (TID 187). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.896 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 184.0 in stage 7.0 (TID 192) (95675304fa2d, executor driver, partition 184, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.896 172.17.0.2:54321      6000    (TID 192)  INFO org.apache.spark.executor.Executor: Running task 184.0 in stage 7.0 (TID 192)\n",
      "10-20 14:40:35.896 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 179.0 in stage 7.0 (TID 187) in 23 ms on 95675304fa2d (executor driver) (182/200)\n",
      "10-20 14:40:35.899 172.17.0.2:54321      6000    (TID 191)  INFO org.apache.spark.executor.Executor: Finished task 183.0 in stage 7.0 (TID 191). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.899 172.17.0.2:54321      6000    (TID 190)  INFO org.apache.spark.executor.Executor: Finished task 182.0 in stage 7.0 (TID 190). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.903 172.17.0.2:54321      6000    (TID 189)  INFO org.apache.spark.executor.Executor: Finished task 181.0 in stage 7.0 (TID 189). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.904 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 185.0 in stage 7.0 (TID 193) (95675304fa2d, executor driver, partition 185, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.904 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 181.0 in stage 7.0 (TID 189) in 20 ms on 95675304fa2d (executor driver) (183/200)\n",
      "10-20 14:40:35.904 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 186.0 in stage 7.0 (TID 194) (95675304fa2d, executor driver, partition 186, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.905 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 187.0 in stage 7.0 (TID 195) (95675304fa2d, executor driver, partition 187, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.905 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 182.0 in stage 7.0 (TID 190) in 19 ms on 95675304fa2d (executor driver) (184/200)\n",
      "10-20 14:40:35.905 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 183.0 in stage 7.0 (TID 191) in 15 ms on 95675304fa2d (executor driver) (185/200)\n",
      "10-20 14:40:35.908 172.17.0.2:54321      6000    (TID 192)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.908 172.17.0.2:54321      6000    (TID 192)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.912 172.17.0.2:54321      6000    (TID 192)  INFO org.apache.spark.executor.Executor: Finished task 184.0 in stage 7.0 (TID 192). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.912 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 188.0 in stage 7.0 (TID 196) (95675304fa2d, executor driver, partition 188, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.913 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 184.0 in stage 7.0 (TID 192) in 18 ms on 95675304fa2d (executor driver) (186/200)\n",
      "10-20 14:40:35.913 172.17.0.2:54321      6000    (TID 196)  INFO org.apache.spark.executor.Executor: Running task 188.0 in stage 7.0 (TID 196)\n",
      "10-20 14:40:35.905 172.17.0.2:54321      6000    (TID 195)  INFO org.apache.spark.executor.Executor: Running task 187.0 in stage 7.0 (TID 195)\n",
      "10-20 14:40:35.917 172.17.0.2:54321      6000    (TID 195)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.917 172.17.0.2:54321      6000    (TID 195)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.905 172.17.0.2:54321      6000    (TID 193)  INFO org.apache.spark.executor.Executor: Running task 185.0 in stage 7.0 (TID 193)\n",
      "10-20 14:40:35.905 172.17.0.2:54321      6000    (TID 194)  INFO org.apache.spark.executor.Executor: Running task 186.0 in stage 7.0 (TID 194)\n",
      "10-20 14:40:35.919 172.17.0.2:54321      6000    (TID 195)  INFO org.apache.spark.executor.Executor: Finished task 187.0 in stage 7.0 (TID 195). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.920 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 189.0 in stage 7.0 (TID 197) (95675304fa2d, executor driver, partition 189, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.920 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 187.0 in stage 7.0 (TID 195) in 15 ms on 95675304fa2d (executor driver) (187/200)\n",
      "10-20 14:40:35.920 172.17.0.2:54321      6000    (TID 197)  INFO org.apache.spark.executor.Executor: Running task 189.0 in stage 7.0 (TID 197)\n",
      "10-20 14:40:35.923 172.17.0.2:54321      6000    (TID 194)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.923 172.17.0.2:54321      6000    (TID 194)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.923 172.17.0.2:54321      6000    (TID 197)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.923 172.17.0.2:54321      6000    (TID 197)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.925 172.17.0.2:54321      6000    (TID 197)  INFO org.apache.spark.executor.Executor: Finished task 189.0 in stage 7.0 (TID 197). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.926 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 190.0 in stage 7.0 (TID 198) (95675304fa2d, executor driver, partition 190, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.926 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 189.0 in stage 7.0 (TID 197) in 6 ms on 95675304fa2d (executor driver) (188/200)\n",
      "10-20 14:40:35.927 172.17.0.2:54321      6000    (TID 194)  INFO org.apache.spark.executor.Executor: Finished task 186.0 in stage 7.0 (TID 194). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.927 172.17.0.2:54321      6000    (TID 198)  INFO org.apache.spark.executor.Executor: Running task 190.0 in stage 7.0 (TID 198)\n",
      "10-20 14:40:35.930 172.17.0.2:54321      6000    (TID 196)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.930 172.17.0.2:54321      6000    (TID 196)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.931 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 192.0 in stage 7.0 (TID 199) (95675304fa2d, executor driver, partition 192, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.932 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 186.0 in stage 7.0 (TID 194) in 28 ms on 95675304fa2d (executor driver) (189/200)\n",
      "10-20 14:40:35.934 172.17.0.2:54321      6000    (TID 199)  INFO org.apache.spark.executor.Executor: Running task 192.0 in stage 7.0 (TID 199)\n",
      "10-20 14:40:35.935 172.17.0.2:54321      6000    (TID 198)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.935 172.17.0.2:54321      6000    (TID 198)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.937 172.17.0.2:54321      6000    (TID 199)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.941 172.17.0.2:54321      6000    (TID 199)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 14:40:35.940 172.17.0.2:54321      6000    (TID 196)  INFO org.apache.spark.executor.Executor: Finished task 188.0 in stage 7.0 (TID 196). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.938 172.17.0.2:54321      6000    (TID 193)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.941 172.17.0.2:54321      6000    (TID 193)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:40:35.941 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 193.0 in stage 7.0 (TID 200) (95675304fa2d, executor driver, partition 193, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.942 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 188.0 in stage 7.0 (TID 196) in 30 ms on 95675304fa2d (executor driver) (190/200)\n",
      "10-20 14:40:35.938 172.17.0.2:54321      6000    (TID 198)  INFO org.apache.spark.executor.Executor: Finished task 190.0 in stage 7.0 (TID 198). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.943 172.17.0.2:54321      6000    (TID 200)  INFO org.apache.spark.executor.Executor: Running task 193.0 in stage 7.0 (TID 200)\n",
      "10-20 14:40:35.944 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 194.0 in stage 7.0 (TID 201) (95675304fa2d, executor driver, partition 194, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.944 172.17.0.2:54321      6000    (TID 201)  INFO org.apache.spark.executor.Executor: Running task 194.0 in stage 7.0 (TID 201)\n",
      "10-20 14:40:35.944 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 190.0 in stage 7.0 (TID 198) in 18 ms on 95675304fa2d (executor driver) (191/200)\n",
      "10-20 14:40:35.949 172.17.0.2:54321      6000    (TID 201)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.949 172.17.0.2:54321      6000    (TID 201)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.958 172.17.0.2:54321      6000    (TID 200)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.959 172.17.0.2:54321      6000    (TID 200)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.959 172.17.0.2:54321      6000    (TID 199)  INFO org.apache.spark.executor.Executor: Finished task 192.0 in stage 7.0 (TID 199). 3875 bytes result sent to driver\n",
      "10-20 14:40:35.959 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 195.0 in stage 7.0 (TID 202) (95675304fa2d, executor driver, partition 195, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.959 172.17.0.2:54321      6000    (TID 201)  INFO org.apache.spark.executor.Executor: Finished task 194.0 in stage 7.0 (TID 201). 3875 bytes result sent to driver\n",
      "10-20 14:40:35.959 172.17.0.2:54321      6000    (TID 193)  INFO org.apache.spark.executor.Executor: Finished task 185.0 in stage 7.0 (TID 193). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.960 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 192.0 in stage 7.0 (TID 199) in 29 ms on 95675304fa2d (executor driver) (192/200)\n",
      "10-20 14:40:35.960 172.17.0.2:54321      6000    (TID 202)  INFO org.apache.spark.executor.Executor: Running task 195.0 in stage 7.0 (TID 202)\n",
      "10-20 14:40:35.961 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 196.0 in stage 7.0 (TID 203) (95675304fa2d, executor driver, partition 196, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.961 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 185.0 in stage 7.0 (TID 193) in 58 ms on 95675304fa2d (executor driver) (193/200)\n",
      "10-20 14:40:35.962 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 197.0 in stage 7.0 (TID 204) (95675304fa2d, executor driver, partition 197, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.962 172.17.0.2:54321      6000    (TID 204)  INFO org.apache.spark.executor.Executor: Running task 197.0 in stage 7.0 (TID 204)\n",
      "10-20 14:40:35.962 172.17.0.2:54321      6000    (TID 200)  INFO org.apache.spark.executor.Executor: Finished task 193.0 in stage 7.0 (TID 200). 3875 bytes result sent to driver\n",
      "10-20 14:40:35.962 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 194.0 in stage 7.0 (TID 201) in 18 ms on 95675304fa2d (executor driver) (194/200)\n",
      "10-20 14:40:35.962 172.17.0.2:54321      6000    (TID 203)  INFO org.apache.spark.executor.Executor: Running task 196.0 in stage 7.0 (TID 203)\n",
      "10-20 14:40:35.964 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 198.0 in stage 7.0 (TID 205) (95675304fa2d, executor driver, partition 198, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.965 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 193.0 in stage 7.0 (TID 200) in 24 ms on 95675304fa2d (executor driver) (195/200)\n",
      "10-20 14:40:35.966 172.17.0.2:54321      6000    (TID 205)  INFO org.apache.spark.executor.Executor: Running task 198.0 in stage 7.0 (TID 205)\n",
      "10-20 14:40:35.968 172.17.0.2:54321      6000    (TID 202)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.970 172.17.0.2:54321      6000    (TID 202)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:40:35.973 172.17.0.2:54321      6000    (TID 204)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.973 172.17.0.2:54321      6000    (TID 204)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.970 172.17.0.2:54321      6000    (TID 203)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.973 172.17.0.2:54321      6000    (TID 203)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "10-20 14:40:35.977 172.17.0.2:54321      6000    (TID 203)  INFO org.apache.spark.executor.Executor: Finished task 196.0 in stage 7.0 (TID 203). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.977 172.17.0.2:54321      6000    (TID 205)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.979 172.17.0.2:54321      6000    (TID 205)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:40:35.979 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 199.0 in stage 7.0 (TID 206) (95675304fa2d, executor driver, partition 199, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:35.980 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 196.0 in stage 7.0 (TID 203) in 19 ms on 95675304fa2d (executor driver) (196/200)\n",
      "10-20 14:40:35.978 172.17.0.2:54321      6000    (TID 202)  INFO org.apache.spark.executor.Executor: Finished task 195.0 in stage 7.0 (TID 202). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.983 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 195.0 in stage 7.0 (TID 202) in 24 ms on 95675304fa2d (executor driver) (197/200)\n",
      "10-20 14:40:35.986 172.17.0.2:54321      6000    (TID 205)  INFO org.apache.spark.executor.Executor: Finished task 198.0 in stage 7.0 (TID 205). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.987 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 198.0 in stage 7.0 (TID 205) in 23 ms on 95675304fa2d (executor driver) (198/200)\n",
      "10-20 14:40:35.990 172.17.0.2:54321      6000    (TID 206)  INFO org.apache.spark.executor.Executor: Running task 199.0 in stage 7.0 (TID 206)\n",
      "10-20 14:40:35.991 172.17.0.2:54321      6000    (TID 204)  INFO org.apache.spark.executor.Executor: Finished task 197.0 in stage 7.0 (TID 204). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.992 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 197.0 in stage 7.0 (TID 204) in 30 ms on 95675304fa2d (executor driver) (199/200)\n",
      "10-20 14:40:35.994 172.17.0.2:54321      6000    (TID 206)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:40:35.994 172.17.0.2:54321      6000    (TID 206)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:40:35.997 172.17.0.2:54321      6000    (TID 206)  INFO org.apache.spark.executor.Executor: Finished task 199.0 in stage 7.0 (TID 206). 3832 bytes result sent to driver\n",
      "10-20 14:40:35.998 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 199.0 in stage 7.0 (TID 206) in 19 ms on 95675304fa2d (executor driver) (200/200)\n",
      "10-20 14:40:35.998 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:35.999 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 7 (toPandas at /tmp/ipykernel_5962/3328129577.py:1) finished in 1.208 s\n",
      "10-20 14:40:35.999 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:36.000 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished\n",
      "10-20 14:40:36.000 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 3 finished: toPandas at /tmp/ipykernel_5962/3328129577.py:1, took 1.702862 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  count\n",
       "0      1   6289\n",
       "1      0  19787"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupBy('label').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eead67-429f-443a-acfe-f4b3a777e1a3",
   "metadata": {},
   "source": [
    "### ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6499e814-2c77-4da0-b7a4-8d6ec0052e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    StringIndexer,\n",
    "    VectorAssembler,\n",
    "    OneHotEncoder,\n",
    "    Imputer,\n",
    ")\n",
    "from pyspark.ml import (\n",
    "    Pipeline\n",
    ")\n",
    "from pyspark.ml.classification import(\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "\n",
    "cols_to_impute = ['fnlwgt', 'age', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "cat_cols = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\"]\n",
    "imputed_cols = [f'{x}_IMPUTED' for x in cols_to_impute]\n",
    "imputer = Imputer(strategy='mean', inputCols=cols_to_impute, outputCols=imputed_cols)\n",
    "string_indexers = []\n",
    "ohe_indexers = []\n",
    "for cat_col in cat_cols:\n",
    "    si = StringIndexer(inputCol=cat_col, outputCol=f'{cat_col}_idx').setHandleInvalid('keep')\n",
    "    enc = OneHotEncoder(inputCols=[si.getOutputCol()], outputCols=[f'{cat_col}_vec'])\n",
    "    string_indexers.append(si)\n",
    "    ohe_indexers.append(enc)\n",
    "\n",
    "assembler_cols = [f'{c}_vec' for c in cat_cols] + imputed_cols\n",
    "vector_assembler = VectorAssembler(inputCols=assembler_cols, outputCol='features')\n",
    "rf = RandomForestClassifier(labelCol='label', featuresCol='features')\n",
    "rf_stages = [imputer] + string_indexers + ohe_indexers + [vector_assembler] + [rf]\n",
    "pipeline = Pipeline().setStages(rf_stages)\n",
    "rf_model = pipeline.fit(train_df)\n",
    "rf_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f90f4-dec8-4e8b-bc9a-74e72cd09149",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e775a201-b769-412a-9841-5535dba8fe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:40:55.289 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_68 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 14:40:55.314 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:55.315 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:55.317 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 68 from textFile at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:40:55.417 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at PythonRDD.scala:166\n",
      "10-20 14:40:55.420 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 24 (runJob at PythonRDD.scala:166) with 1 output partitions\n",
      "10-20 14:40:55.420 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 44 (runJob at PythonRDD.scala:166)\n",
      "10-20 14:40:55.420 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:55.420 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:55.421 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 44 (PythonRDD[165] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "10-20 14:40:55.433 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_69 stored as values in memory (estimated size 6.7 KiB, free 433.4 MiB)\n",
      "10-20 14:40:55.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.4 MiB)\n",
      "10-20 14:40:55.435 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on 95675304fa2d:39707 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:55.436 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:55.436 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (PythonRDD[165] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:55.436 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:55.447 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 245) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4540 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:55.448 172.17.0.2:54321      6000    (TID 245)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 44.0 (TID 245)\n",
      "10-20 14:40:55.473 172.17.0.2:54321      6000    (TID 245)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/metadata/part-00000:0+734\n",
      "10-20 14:40:55.571 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_41_piece0 on 95675304fa2d:39707 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:55.573 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_45_piece0 on 95675304fa2d:39707 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:55.920 172.17.0.2:54321      6000    (TID 245)  INFO org.apache.spark.api.python.PythonRunner: Times: total = 438, boot = 425, init = 13, finish = 0\n",
      "10-20 14:40:55.922 172.17.0.2:54321      6000    (TID 245)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 44.0 (TID 245). 2137 bytes result sent to driver\n",
      "10-20 14:40:55.923 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 245) in 486 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:55.923 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:55.925 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.api.python.PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 56777\n",
      "10-20 14:40:55.926 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 44 (runJob at PythonRDD.scala:166) finished in 0.503 s\n",
      "10-20 14:40:55.926 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:55.926 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished\n",
      "10-20 14:40:55.927 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 24 finished: runJob at PythonRDD.scala:166, took 0.509728 s\n",
      "10-20 14:40:55.939 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_70 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 14:40:55.951 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_69_piece0 on 95675304fa2d:39707 in memory (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:55.952 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.6 MiB)\n",
      "10-20 14:40:55.953 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:55.953 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 70 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:55.985 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:55.985 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 25 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:55.985 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 45 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:55.985 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:55.985 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:55.986 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 45 (outputs/income_rf_spark/metadata MapPartitionsRDD[167] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:55.987 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_71 stored as values in memory (estimated size 4.1 KiB, free 433.6 MiB)\n",
      "10-20 14:40:55.988 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:40:55.988 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_71_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:55.988 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:55.989 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (outputs/income_rf_spark/metadata MapPartitionsRDD[167] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:55.989 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:55.990 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 246) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4540 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:55.990 172.17.0.2:54321      6000    (TID 246)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 45.0 (TID 246)\n",
      "10-20 14:40:55.993 172.17.0.2:54321      6000    (TID 246)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/metadata/part-00000:0+734\n",
      "10-20 14:40:55.995 172.17.0.2:54321      6000    (TID 246)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 45.0 (TID 246). 1662 bytes result sent to driver\n",
      "10-20 14:40:55.995 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 246) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:55.995 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:55.996 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 45 (first at ReadWrite.scala:587) finished in 0.010 s\n",
      "10-20 14:40:55.996 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:55.996 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished\n",
      "10-20 14:40:55.997 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 25 finished: first at ReadWrite.scala:587, took 0.011774 s\n",
      "10-20 14:40:56.031 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_72 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 14:40:56.036 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:56.036 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_72_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:56.037 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 72 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:56.066 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:56.067 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 26 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:56.067 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 46 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:56.067 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:56.067 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:56.067 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 46 (outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata MapPartitionsRDD[169] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:56.069 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_73 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:56.070 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:40:56.070 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_73_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:56.071 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:56.071 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata MapPartitionsRDD[169] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:56.071 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:56.072 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 247) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4571 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:56.073 172.17.0.2:54321      6000    (TID 247)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 46.0 (TID 247)\n",
      "10-20 14:40:56.074 172.17.0.2:54321      6000    (TID 247)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata/part-00000:0+479\n",
      "10-20 14:40:56.079 172.17.0.2:54321      6000    (TID 247)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 46.0 (TID 247). 1407 bytes result sent to driver\n",
      "10-20 14:40:56.079 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 247) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:56.079 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:56.080 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 46 (first at ReadWrite.scala:587) finished in 0.012 s\n",
      "10-20 14:40:56.081 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:56.081 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished\n",
      "10-20 14:40:56.081 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 26 finished: first at ReadWrite.scala:587, took 0.014767 s\n",
      "10-20 14:40:56.086 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_74 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 14:40:56.091 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.2 MiB)\n",
      "10-20 14:40:56.092 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_74_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:56.092 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 74 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:56.123 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:56.125 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 27 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:56.125 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 47 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:56.125 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:56.125 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:56.126 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 47 (outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:56.127 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_75 stored as values in memory (estimated size 4.2 KiB, free 433.2 MiB)\n",
      "10-20 14:40:56.128 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.2 MiB)\n",
      "10-20 14:40:56.128 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_75_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:56.129 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:56.129 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:56.129 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:56.130 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 248) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4571 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:56.131 172.17.0.2:54321      6000    (TID 248)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 47.0 (TID 248)\n",
      "10-20 14:40:56.133 172.17.0.2:54321      6000    (TID 248)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata/part-00000:0+479\n",
      "10-20 14:40:56.136 172.17.0.2:54321      6000    (TID 248)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 47.0 (TID 248). 1407 bytes result sent to driver\n",
      "10-20 14:40:56.136 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 248) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:56.136 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:56.176 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 47 (first at ReadWrite.scala:587) finished in 0.050 s\n",
      "10-20 14:40:56.176 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:56.176 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished\n",
      "10-20 14:40:56.176 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 27 finished: first at ReadWrite.scala:587, took 0.051689 s\n",
      "10-20 14:40:56.198 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:56.234 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at Imputer.scala:320\n",
      "10-20 14:40:56.234 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 28 (parquet at Imputer.scala:320) with 1 output partitions\n",
      "10-20 14:40:56.234 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 48 (parquet at Imputer.scala:320)\n",
      "10-20 14:40:56.234 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:56.234 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:56.235 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[173] at parquet at Imputer.scala:320), which has no missing parents\n",
      "10-20 14:40:56.240 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_76 stored as values in memory (estimated size 84.5 KiB, free 433.1 MiB)\n",
      "10-20 14:40:56.241 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.1 MiB)\n",
      "10-20 14:40:56.241 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_76_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:56.241 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:56.242 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[173] at parquet at Imputer.scala:320) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:56.242 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:56.242 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 48.0 (TID 249) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4731 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:56.243 172.17.0.2:54321      6000    (TID 249)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 48.0 (TID 249)\n",
      "10-20 14:40:56.430 172.17.0.2:54321      6000    (TID 249)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 48.0 (TID 249). 1774 bytes result sent to driver\n",
      "10-20 14:40:56.433 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 48.0 (TID 249) in 191 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:56.433 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:56.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 48 (parquet at Imputer.scala:320) finished in 0.198 s\n",
      "10-20 14:40:56.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:56.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished\n",
      "10-20 14:40:56.434 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 28 finished: parquet at Imputer.scala:320, took 0.200162 s\n",
      "10-20 14:40:56.442 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_77 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:40:56.454 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_73_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:56.455 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_70_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:56.456 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_76_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:56.457 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.2 MiB)\n",
      "10-20 14:40:56.457 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_72_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:56.458 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_77_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:56.458 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 77 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:56.460 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_75_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:56.462 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_71_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:56.463 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_74_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:56.484 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:56.485 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 29 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:56.485 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 49 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:56.485 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:56.485 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:56.486 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 49 (outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata MapPartitionsRDD[175] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:56.487 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_78 stored as values in memory (estimated size 4.2 KiB, free 433.6 MiB)\n",
      "10-20 14:40:56.488 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:40:56.489 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_78_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:56.489 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:56.489 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata MapPartitionsRDD[175] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:56.489 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:56.490 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 250) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:56.491 172.17.0.2:54321      6000    (TID 250)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 49.0 (TID 250)\n",
      "10-20 14:40:56.492 172.17.0.2:54321      6000    (TID 250)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata/part-00000:0+357\n",
      "10-20 14:40:56.495 172.17.0.2:54321      6000    (TID 250)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 49.0 (TID 250). 1285 bytes result sent to driver\n",
      "10-20 14:40:56.495 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 250) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:56.495 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:56.496 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 49 (first at ReadWrite.scala:587) finished in 0.010 s\n",
      "10-20 14:40:56.496 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:56.496 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished\n",
      "10-20 14:40:56.497 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 29 finished: first at ReadWrite.scala:587, took 0.012412 s\n",
      "10-20 14:40:56.500 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_79 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 14:40:56.509 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:56.510 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_79_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:56.510 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 79 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:56.544 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:56.545 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 30 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:56.545 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 50 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:56.545 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:56.545 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:56.545 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 50 (outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata MapPartitionsRDD[177] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:56.546 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_80 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:56.547 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:40:56.548 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_80_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:56.549 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:56.549 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata MapPartitionsRDD[177] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:56.549 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:56.550 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 50.0 (TID 251) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:56.551 172.17.0.2:54321      6000    (TID 251)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 50.0 (TID 251)\n",
      "10-20 14:40:56.553 172.17.0.2:54321      6000    (TID 251)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata/part-00000:0+357\n",
      "10-20 14:40:56.555 172.17.0.2:54321      6000    (TID 251)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 50.0 (TID 251). 1285 bytes result sent to driver\n",
      "10-20 14:40:56.556 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 50.0 (TID 251) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:56.556 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:56.557 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 50 (first at ReadWrite.scala:587) finished in 0.012 s\n",
      "10-20 14:40:56.557 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:56.557 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished\n",
      "10-20 14:40:56.558 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 30 finished: first at ReadWrite.scala:587, took 0.013052 s\n",
      "10-20 14:40:56.566 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:56.590 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:40:56.591 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 31 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:40:56.591 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 51 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:40:56.591 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:56.591 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:56.591 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[179] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:40:56.597 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_81 stored as values in memory (estimated size 84.5 KiB, free 433.3 MiB)\n",
      "10-20 14:40:56.598 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.3 MiB)\n",
      "10-20 14:40:56.598 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_81_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:56.599 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:56.599 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[179] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:56.600 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:56.601 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 51.0 (TID 252) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:56.602 172.17.0.2:54321      6000    (TID 252)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 51.0 (TID 252)\n",
      "10-20 14:40:56.613 172.17.0.2:54321      6000    (TID 252)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 51.0 (TID 252). 1709 bytes result sent to driver\n",
      "10-20 14:40:56.614 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 51.0 (TID 252) in 13 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:56.614 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:56.615 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 51 (parquet at StringIndexer.scala:523) finished in 0.023 s\n",
      "10-20 14:40:56.615 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:56.615 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished\n",
      "10-20 14:40:56.616 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 31 finished: parquet at StringIndexer.scala:523, took 0.025884 s\n",
      "10-20 14:40:56.645 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:56.645 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:56.645 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:40:56.663 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_82 stored as values in memory (estimated size 177.5 KiB, free 433.1 MiB)\n",
      "10-20 14:40:56.670 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.1 MiB)\n",
      "10-20 14:40:56.670 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_82_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:56.696 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 82 from head at StringIndexer.scala:524\n",
      "10-20 14:40:56.699 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:56.704 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:40:56.704 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 32 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:40:56.704 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 52 (head at StringIndexer.scala:524)\n",
      "10-20 14:40:56.704 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:56.704 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:56.704 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[182] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:40:56.712 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_83 stored as values in memory (estimated size 8.9 KiB, free 433.1 MiB)\n",
      "10-20 14:40:56.713 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.1 MiB)\n",
      "10-20 14:40:56.713 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_83_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:56.714 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:56.714 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[182] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:56.714 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:56.715 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 52.0 (TID 253) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:56.715 172.17.0.2:54321      6000    (TID 253)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 52.0 (TID 253)\n",
      "10-20 14:40:56.732 172.17.0.2:54321      6000    (TID 253)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.729621 ms\n",
      "10-20 14:40:56.733 172.17.0.2:54321      6000    (TID 253)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/data/part-00000-d14895eb-d962-484e-b0f1-6314a71ecfea-c000.snappy.parquet, range: 0-750, partition values: [empty row]\n",
      "10-20 14:40:56.838 172.17.0.2:54321      6000    (TID 253)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:56.838 172.17.0.2:54321      6000    (TID 253)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:56.859 172.17.0.2:54321      6000    (TID 253)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 20 ms. row count = 1\n",
      "10-20 14:40:57.002 172.17.0.2:54321      6000    (TID 253)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 52.0 (TID 253). 1804 bytes result sent to driver\n",
      "10-20 14:40:57.002 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 52.0 (TID 253) in 287 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.002 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.003 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 52 (head at StringIndexer.scala:524) finished in 0.298 s\n",
      "10-20 14:40:57.003 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.003 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished\n",
      "10-20 14:40:57.003 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 32 finished: head at StringIndexer.scala:524, took 0.299337 s\n",
      "10-20 14:40:57.018 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.101802 ms\n",
      "10-20 14:40:57.021 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_84 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:40:57.037 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_82_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.038 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_80_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.040 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.041 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_84_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.041 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_78_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.042 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 84 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:57.042 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_79_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.043 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_77_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.044 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_83_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.045 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_81_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.080 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:57.081 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 33 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:57.081 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 53 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:57.081 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.081 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.081 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 53 (outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata MapPartitionsRDD[184] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:57.084 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_85 stored as values in memory (estimated size 4.2 KiB, free 433.6 MiB)\n",
      "10-20 14:40:57.085 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:40:57.086 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_85_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.086 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.087 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata MapPartitionsRDD[184] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.087 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.088 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 53.0 (TID 254) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.089 172.17.0.2:54321      6000    (TID 254)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 53.0 (TID 254)\n",
      "10-20 14:40:57.091 172.17.0.2:54321      6000    (TID 254)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata/part-00000:0+357\n",
      "10-20 14:40:57.092 172.17.0.2:54321      6000    (TID 254)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 53.0 (TID 254). 1285 bytes result sent to driver\n",
      "10-20 14:40:57.093 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 53.0 (TID 254) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.093 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.093 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 53 (first at ReadWrite.scala:587) finished in 0.010 s\n",
      "10-20 14:40:57.093 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.093 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished\n",
      "10-20 14:40:57.094 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 33 finished: first at ReadWrite.scala:587, took 0.013115 s\n",
      "10-20 14:40:57.096 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_86 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 14:40:57.101 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:57.102 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_86_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.102 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 86 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:57.129 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:57.130 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 34 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:57.130 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 54 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:57.130 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.130 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.130 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 54 (outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata MapPartitionsRDD[186] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:57.132 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_87 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:57.133 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:40:57.133 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_87_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.134 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.134 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata MapPartitionsRDD[186] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.135 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.136 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 54.0 (TID 255) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.137 172.17.0.2:54321      6000    (TID 255)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 54.0 (TID 255)\n",
      "10-20 14:40:57.139 172.17.0.2:54321      6000    (TID 255)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata/part-00000:0+357\n",
      "10-20 14:40:57.141 172.17.0.2:54321      6000    (TID 255)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 54.0 (TID 255). 1285 bytes result sent to driver\n",
      "10-20 14:40:57.141 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 54.0 (TID 255) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.141 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 54 (first at ReadWrite.scala:587) finished in 0.011 s\n",
      "10-20 14:40:57.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished\n",
      "10-20 14:40:57.143 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 34 finished: first at ReadWrite.scala:587, took 0.013544 s\n",
      "10-20 14:40:57.151 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:57.169 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:40:57.170 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 35 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:40:57.170 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 55 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:40:57.170 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.170 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.170 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[188] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:40:57.176 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_88 stored as values in memory (estimated size 84.5 KiB, free 433.3 MiB)\n",
      "10-20 14:40:57.177 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.3 MiB)\n",
      "10-20 14:40:57.177 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_88_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.178 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.179 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[188] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.179 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.180 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 55.0 (TID 256) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.180 172.17.0.2:54321      6000    (TID 256)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 55.0 (TID 256)\n",
      "10-20 14:40:57.189 172.17.0.2:54321      6000    (TID 256)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 55.0 (TID 256). 1709 bytes result sent to driver\n",
      "10-20 14:40:57.190 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 55.0 (TID 256) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.190 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.190 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 55 (parquet at StringIndexer.scala:523) finished in 0.019 s\n",
      "10-20 14:40:57.191 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.191 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished\n",
      "10-20 14:40:57.191 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 35 finished: parquet at StringIndexer.scala:523, took 0.021512 s\n",
      "10-20 14:40:57.199 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:57.199 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:57.199 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:40:57.205 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_89 stored as values in memory (estimated size 177.5 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.210 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.210 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_89_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.211 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 89 from head at StringIndexer.scala:524\n",
      "10-20 14:40:57.212 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:57.215 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:40:57.216 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 36 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:40:57.216 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 56 (head at StringIndexer.scala:524)\n",
      "10-20 14:40:57.216 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.216 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.216 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[191] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:40:57.218 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_90 stored as values in memory (estimated size 8.9 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.218 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.219 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_90_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.219 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.219 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[191] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.219 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.220 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 56.0 (TID 257) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.220 172.17.0.2:54321      6000    (TID 257)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 56.0 (TID 257)\n",
      "10-20 14:40:57.223 172.17.0.2:54321      6000    (TID 257)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/data/part-00000-be9cdc38-257f-4bf0-93c8-c37b6939d3b6-c000.snappy.parquet, range: 0-813, partition values: [empty row]\n",
      "10-20 14:40:57.226 172.17.0.2:54321      6000    (TID 257)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:57.227 172.17.0.2:54321      6000    (TID 257)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:57.227 172.17.0.2:54321      6000    (TID 257)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:40:57.228 172.17.0.2:54321      6000    (TID 257)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 56.0 (TID 257). 1888 bytes result sent to driver\n",
      "10-20 14:40:57.229 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 56.0 (TID 257) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.229 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.230 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 56 (head at StringIndexer.scala:524) finished in 0.014 s\n",
      "10-20 14:40:57.230 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.230 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished\n",
      "10-20 14:40:57.230 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 36 finished: head at StringIndexer.scala:524, took 0.015066 s\n",
      "10-20 14:40:57.263 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_91 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:40:57.269 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:57.269 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_91_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.270 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 91 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:57.303 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:57.305 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 37 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:57.306 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 57 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:57.306 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.306 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.306 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 57 (outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata MapPartitionsRDD[193] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:57.307 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_92 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:57.307 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:40:57.308 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_92_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.309 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.309 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata MapPartitionsRDD[193] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.309 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.310 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 57.0 (TID 258) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.311 172.17.0.2:54321      6000    (TID 258)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 57.0 (TID 258)\n",
      "10-20 14:40:57.312 172.17.0.2:54321      6000    (TID 258)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata/part-00000:0+367\n",
      "10-20 14:40:57.314 172.17.0.2:54321      6000    (TID 258)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 57.0 (TID 258). 1295 bytes result sent to driver\n",
      "10-20 14:40:57.315 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 57.0 (TID 258) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.315 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 57 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:40:57.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished\n",
      "10-20 14:40:57.317 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 37 finished: first at ReadWrite.scala:587, took 0.011530 s\n",
      "10-20 14:40:57.321 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_93 stored as values in memory (estimated size 176.1 KiB, free 432.7 MiB)\n",
      "10-20 14:40:57.328 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:40:57.329 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_93_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.330 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 93 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:57.350 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:57.351 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 38 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:57.351 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 58 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:57.351 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.351 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.351 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 58 (outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata MapPartitionsRDD[195] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:57.352 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_94 stored as values in memory (estimated size 4.2 KiB, free 432.7 MiB)\n",
      "10-20 14:40:57.352 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.7 MiB)\n",
      "10-20 14:40:57.353 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_94_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.353 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.354 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata MapPartitionsRDD[195] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.354 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.354 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 58.0 (TID 259) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.355 172.17.0.2:54321      6000    (TID 259)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 58.0 (TID 259)\n",
      "10-20 14:40:57.356 172.17.0.2:54321      6000    (TID 259)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata/part-00000:0+367\n",
      "10-20 14:40:57.357 172.17.0.2:54321      6000    (TID 259)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 58.0 (TID 259). 1295 bytes result sent to driver\n",
      "10-20 14:40:57.358 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 58.0 (TID 259) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.358 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.359 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 58 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:40:57.360 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.360 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished\n",
      "10-20 14:40:57.361 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 38 finished: first at ReadWrite.scala:587, took 0.010344 s\n",
      "10-20 14:40:57.380 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:57.403 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:40:57.403 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 39 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:40:57.404 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 59 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:40:57.404 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.404 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.404 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[197] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:40:57.411 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_95 stored as values in memory (estimated size 84.5 KiB, free 432.6 MiB)\n",
      "10-20 14:40:57.425 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.5 MiB)\n",
      "10-20 14:40:57.426 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_90_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.427 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_95_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.427 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.427 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_92_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.428 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[197] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.429 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.429 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_94_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.430 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 59.0 (TID 260) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.430 172.17.0.2:54321      6000    (TID 260)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 59.0 (TID 260)\n",
      "10-20 14:40:57.431 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_86_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.434 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_91_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.436 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_89_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.437 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_87_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.438 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_84_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.439 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_85_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.440 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_88_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.441 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_93_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.445 172.17.0.2:54321      6000    (TID 260)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 59.0 (TID 260). 1709 bytes result sent to driver\n",
      "10-20 14:40:57.446 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 59.0 (TID 260) in 16 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.446 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.446 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 59 (parquet at StringIndexer.scala:523) finished in 0.041 s\n",
      "10-20 14:40:57.446 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.446 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished\n",
      "10-20 14:40:57.446 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 39 finished: parquet at StringIndexer.scala:523, took 0.043522 s\n",
      "10-20 14:40:57.455 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:57.455 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:57.455 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:40:57.461 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_96 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:40:57.468 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:40:57.468 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_96_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.469 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 96 from head at StringIndexer.scala:524\n",
      "10-20 14:40:57.470 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:57.474 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:40:57.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 40 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:40:57.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 60 (head at StringIndexer.scala:524)\n",
      "10-20 14:40:57.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[200] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:40:57.479 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_97 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:40:57.480 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:40:57.480 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_97_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.481 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.482 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[200] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.482 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.483 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 60.0 (TID 261) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.484 172.17.0.2:54321      6000    (TID 261)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 60.0 (TID 261)\n",
      "10-20 14:40:57.488 172.17.0.2:54321      6000    (TID 261)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/data/part-00000-c883591b-5ee3-46b0-a91b-2b149f54261f-c000.snappy.parquet, range: 0-743, partition values: [empty row]\n",
      "10-20 14:40:57.493 172.17.0.2:54321      6000    (TID 261)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:57.494 172.17.0.2:54321      6000    (TID 261)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:57.495 172.17.0.2:54321      6000    (TID 261)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:40:57.496 172.17.0.2:54321      6000    (TID 261)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 60.0 (TID 261). 1786 bytes result sent to driver\n",
      "10-20 14:40:57.496 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 60.0 (TID 261) in 13 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.496 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.498 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 60 (head at StringIndexer.scala:524) finished in 0.022 s\n",
      "10-20 14:40:57.498 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.498 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished\n",
      "10-20 14:40:57.499 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 40 finished: head at StringIndexer.scala:524, took 0.024273 s\n",
      "10-20 14:40:57.502 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_98 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:40:57.509 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:40:57.509 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_98_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.510 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 98 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:57.537 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:57.538 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 41 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:57.538 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 61 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:57.538 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.538 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.539 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 61 (outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata MapPartitionsRDD[202] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:57.540 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_99 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:40:57.541 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:40:57.541 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_99_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.542 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.542 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata MapPartitionsRDD[202] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.542 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.543 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 61.0 (TID 262) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.543 172.17.0.2:54321      6000    (TID 262)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 61.0 (TID 262)\n",
      "10-20 14:40:57.545 172.17.0.2:54321      6000    (TID 262)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata/part-00000:0+359\n",
      "10-20 14:40:57.546 172.17.0.2:54321      6000    (TID 262)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 61.0 (TID 262). 1287 bytes result sent to driver\n",
      "10-20 14:40:57.547 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 61.0 (TID 262) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.547 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.548 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 61 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:40:57.548 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.548 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished\n",
      "10-20 14:40:57.548 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 41 finished: first at ReadWrite.scala:587, took 0.010831 s\n",
      "10-20 14:40:57.551 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_100 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.557 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.558 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_100_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.558 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 100 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:57.577 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:57.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 42 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:57.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 62 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:57.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.579 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 62 (outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata MapPartitionsRDD[204] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:57.580 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_101 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.581 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.582 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_101_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.582 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.583 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata MapPartitionsRDD[204] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.583 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.584 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 62.0 (TID 263) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.584 172.17.0.2:54321      6000    (TID 263)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 62.0 (TID 263)\n",
      "10-20 14:40:57.586 172.17.0.2:54321      6000    (TID 263)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata/part-00000:0+359\n",
      "10-20 14:40:57.587 172.17.0.2:54321      6000    (TID 263)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 62.0 (TID 263). 1287 bytes result sent to driver\n",
      "10-20 14:40:57.588 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 62.0 (TID 263) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.588 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.588 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 62 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:40:57.589 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.589 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished\n",
      "10-20 14:40:57.589 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 42 finished: first at ReadWrite.scala:587, took 0.011295 s\n",
      "10-20 14:40:57.599 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:57.639 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:40:57.640 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 43 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:40:57.640 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 63 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:40:57.640 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.640 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.640 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[206] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:40:57.654 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_102 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:40:57.655 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.0 MiB)\n",
      "10-20 14:40:57.655 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_102_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.656 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.656 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[206] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.656 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.657 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 63.0 (TID 264) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.658 172.17.0.2:54321      6000    (TID 264)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 63.0 (TID 264)\n",
      "10-20 14:40:57.668 172.17.0.2:54321      6000    (TID 264)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 63.0 (TID 264). 1709 bytes result sent to driver\n",
      "10-20 14:40:57.669 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 63.0 (TID 264) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.669 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.670 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 63 (parquet at StringIndexer.scala:523) finished in 0.030 s\n",
      "10-20 14:40:57.670 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.670 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished\n",
      "10-20 14:40:57.670 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 43 finished: parquet at StringIndexer.scala:523, took 0.031194 s\n",
      "10-20 14:40:57.677 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:57.677 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:57.677 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:40:57.682 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_103 stored as values in memory (estimated size 177.5 KiB, free 432.8 MiB)\n",
      "10-20 14:40:57.687 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.8 MiB)\n",
      "10-20 14:40:57.688 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_103_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.688 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 103 from head at StringIndexer.scala:524\n",
      "10-20 14:40:57.689 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:57.692 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:40:57.692 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 44 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:40:57.693 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 64 (head at StringIndexer.scala:524)\n",
      "10-20 14:40:57.693 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.693 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.693 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[209] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:40:57.695 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_104 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:40:57.695 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:40:57.696 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_104_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.696 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.697 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[209] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.697 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.697 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 64.0 (TID 265) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.698 172.17.0.2:54321      6000    (TID 265)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 64.0 (TID 265)\n",
      "10-20 14:40:57.700 172.17.0.2:54321      6000    (TID 265)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/data/part-00000-3d2f0af4-4c70-4d74-8ebf-19433b143995-c000.snappy.parquet, range: 0-873, partition values: [empty row]\n",
      "10-20 14:40:57.703 172.17.0.2:54321      6000    (TID 265)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:57.704 172.17.0.2:54321      6000    (TID 265)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:57.704 172.17.0.2:54321      6000    (TID 265)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:40:57.706 172.17.0.2:54321      6000    (TID 265)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 64.0 (TID 265). 1969 bytes result sent to driver\n",
      "10-20 14:40:57.706 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 64.0 (TID 265) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.706 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.707 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 64 (head at StringIndexer.scala:524) finished in 0.014 s\n",
      "10-20 14:40:57.707 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.707 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished\n",
      "10-20 14:40:57.708 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 44 finished: head at StringIndexer.scala:524, took 0.015649 s\n",
      "10-20 14:40:57.711 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_105 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:40:57.718 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.5 MiB)\n",
      "10-20 14:40:57.718 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_105_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.719 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 105 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:57.742 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:57.743 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 45 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:57.743 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 65 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:57.743 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.743 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.743 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 65 (outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata MapPartitionsRDD[211] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:57.745 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_106 stored as values in memory (estimated size 4.2 KiB, free 432.5 MiB)\n",
      "10-20 14:40:57.745 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.5 MiB)\n",
      "10-20 14:40:57.746 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_106_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.747 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.747 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata MapPartitionsRDD[211] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.747 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.748 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 65.0 (TID 266) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.749 172.17.0.2:54321      6000    (TID 266)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 65.0 (TID 266)\n",
      "10-20 14:40:57.751 172.17.0.2:54321      6000    (TID 266)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata/part-00000:0+363\n",
      "10-20 14:40:57.753 172.17.0.2:54321      6000    (TID 266)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 65.0 (TID 266). 1291 bytes result sent to driver\n",
      "10-20 14:40:57.753 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 65.0 (TID 266) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.754 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.754 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 65 (first at ReadWrite.scala:587) finished in 0.010 s\n",
      "10-20 14:40:57.754 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.754 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished\n",
      "10-20 14:40:57.755 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 45 finished: first at ReadWrite.scala:587, took 0.012111 s\n",
      "10-20 14:40:57.757 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_107 stored as values in memory (estimated size 176.1 KiB, free 432.4 MiB)\n",
      "10-20 14:40:57.762 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.3 MiB)\n",
      "10-20 14:40:57.763 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_107_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.764 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 107 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:57.783 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:57.784 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 46 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:57.784 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 66 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:57.784 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.784 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.785 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 66 (outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata MapPartitionsRDD[213] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:57.786 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_108 stored as values in memory (estimated size 4.2 KiB, free 432.3 MiB)\n",
      "10-20 14:40:57.796 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.3 MiB)\n",
      "10-20 14:40:57.796 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_108_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.797 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_106_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.797 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.797 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata MapPartitionsRDD[213] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.797 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.798 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 66.0 (TID 267) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.798 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_99_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.800 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_103_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.801 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_96_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.801 172.17.0.2:54321      6000    (TID 267)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 66.0 (TID 267)\n",
      "10-20 14:40:57.802 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_97_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:57.803 172.17.0.2:54321      6000    (TID 267)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata/part-00000:0+363\n",
      "10-20 14:40:57.804 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_105_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.804 172.17.0.2:54321      6000    (TID 267)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 66.0 (TID 267). 1248 bytes result sent to driver\n",
      "10-20 14:40:57.804 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 66.0 (TID 267) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.804 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.805 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 66 (first at ReadWrite.scala:587) finished in 0.020 s\n",
      "10-20 14:40:57.805 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_101_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.806 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.806 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished\n",
      "10-20 14:40:57.807 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_98_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.808 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_104_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.809 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_95_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.810 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 46 finished: first at ReadWrite.scala:587, took 0.026852 s\n",
      "10-20 14:40:57.811 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_100_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.812 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_102_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.821 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:57.842 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:40:57.843 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 47 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:40:57.843 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 67 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:40:57.843 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.843 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.844 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[215] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:40:57.849 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_109 stored as values in memory (estimated size 84.5 KiB, free 433.5 MiB)\n",
      "10-20 14:40:57.850 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.5 MiB)\n",
      "10-20 14:40:57.850 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_109_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:57.851 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.851 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[215] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.851 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.852 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 67.0 (TID 268) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.852 172.17.0.2:54321      6000    (TID 268)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 67.0 (TID 268)\n",
      "10-20 14:40:57.860 172.17.0.2:54321      6000    (TID 268)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 67.0 (TID 268). 1709 bytes result sent to driver\n",
      "10-20 14:40:57.863 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 67.0 (TID 268) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.863 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.863 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 67 (parquet at StringIndexer.scala:523) finished in 0.019 s\n",
      "10-20 14:40:57.863 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.863 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished\n",
      "10-20 14:40:57.864 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 47 finished: parquet at StringIndexer.scala:523, took 0.021136 s\n",
      "10-20 14:40:57.870 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:57.871 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:57.871 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:40:57.876 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_110 stored as values in memory (estimated size 177.5 KiB, free 433.3 MiB)\n",
      "10-20 14:40:57.881 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.3 MiB)\n",
      "10-20 14:40:57.881 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_110_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.882 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 110 from head at StringIndexer.scala:524\n",
      "10-20 14:40:57.882 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:57.885 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:40:57.886 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 48 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:40:57.886 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 68 (head at StringIndexer.scala:524)\n",
      "10-20 14:40:57.886 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.886 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.886 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[218] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:40:57.888 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_111 stored as values in memory (estimated size 8.9 KiB, free 433.3 MiB)\n",
      "10-20 14:40:57.889 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.3 MiB)\n",
      "10-20 14:40:57.889 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_111_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.889 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.890 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[218] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.890 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.891 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 68.0 (TID 269) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.891 172.17.0.2:54321      6000    (TID 269)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 68.0 (TID 269)\n",
      "10-20 14:40:57.893 172.17.0.2:54321      6000    (TID 269)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/data/part-00000-5967b13e-7ecf-4cf2-9ef8-b8ca3676c1ca-c000.snappy.parquet, range: 0-712, partition values: [empty row]\n",
      "10-20 14:40:57.896 172.17.0.2:54321      6000    (TID 269)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:57.897 172.17.0.2:54321      6000    (TID 269)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:57.897 172.17.0.2:54321      6000    (TID 269)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:40:57.899 172.17.0.2:54321      6000    (TID 269)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 68.0 (TID 269). 1758 bytes result sent to driver\n",
      "10-20 14:40:57.899 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 68.0 (TID 269) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.899 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.900 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 68 (head at StringIndexer.scala:524) finished in 0.014 s\n",
      "10-20 14:40:57.900 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.900 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished\n",
      "10-20 14:40:57.900 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 48 finished: head at StringIndexer.scala:524, took 0.014550 s\n",
      "10-20 14:40:57.903 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_112 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.908 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.908 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_112_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.909 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 112 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:57.934 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:57.934 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 49 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:57.934 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 69 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:57.934 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.934 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.934 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 69 (outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata MapPartitionsRDD[220] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:57.935 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_113 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.936 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:40:57.936 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_113_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.938 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:57.938 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata MapPartitionsRDD[220] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:57.939 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:57.939 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 69.0 (TID 270) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:57.940 172.17.0.2:54321      6000    (TID 270)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 69.0 (TID 270)\n",
      "10-20 14:40:57.941 172.17.0.2:54321      6000    (TID 270)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata/part-00000:0+347\n",
      "10-20 14:40:57.943 172.17.0.2:54321      6000    (TID 270)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 69.0 (TID 270). 1275 bytes result sent to driver\n",
      "10-20 14:40:57.944 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 69.0 (TID 270) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:57.944 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:57.944 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 69 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:40:57.944 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:57.944 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished\n",
      "10-20 14:40:57.944 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 49 finished: first at ReadWrite.scala:587, took 0.010497 s\n",
      "10-20 14:40:57.949 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_114 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:40:57.956 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:57.957 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_114_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:57.957 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 114 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:57.995 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:57.996 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 50 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:57.996 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 70 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:57.996 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:57.996 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:57.996 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 70 (outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata MapPartitionsRDD[222] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:57.998 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_115 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:57.999 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:40:57.999 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_115_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.000 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.000 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata MapPartitionsRDD[222] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.000 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.002 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 70.0 (TID 271) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.002 172.17.0.2:54321      6000    (TID 271)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 70.0 (TID 271)\n",
      "10-20 14:40:58.028 172.17.0.2:54321      6000    (TID 271)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata/part-00000:0+347\n",
      "10-20 14:40:58.030 172.17.0.2:54321      6000    (TID 271)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 70.0 (TID 271). 1275 bytes result sent to driver\n",
      "10-20 14:40:58.031 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 70.0 (TID 271) in 30 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.031 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.031 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 70 (first at ReadWrite.scala:587) finished in 0.034 s\n",
      "10-20 14:40:58.032 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.032 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished\n",
      "10-20 14:40:58.033 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 50 finished: first at ReadWrite.scala:587, took 0.037911 s\n",
      "10-20 14:40:58.045 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:58.065 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:40:58.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 51 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:40:58.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 71 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:40:58.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[224] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:40:58.071 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_116 stored as values in memory (estimated size 84.5 KiB, free 432.8 MiB)\n",
      "10-20 14:40:58.072 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.7 MiB)\n",
      "10-20 14:40:58.072 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_116_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.073 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.073 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[224] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.073 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.074 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 71.0 (TID 272) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.074 172.17.0.2:54321      6000    (TID 272)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 71.0 (TID 272)\n",
      "10-20 14:40:58.083 172.17.0.2:54321      6000    (TID 272)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 71.0 (TID 272). 1709 bytes result sent to driver\n",
      "10-20 14:40:58.083 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 71.0 (TID 272) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.083 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.084 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 71 (parquet at StringIndexer.scala:523) finished in 0.017 s\n",
      "10-20 14:40:58.084 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.084 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished\n",
      "10-20 14:40:58.084 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 51 finished: parquet at StringIndexer.scala:523, took 0.018572 s\n",
      "10-20 14:40:58.093 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:58.093 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:58.093 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:40:58.098 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_117 stored as values in memory (estimated size 177.5 KiB, free 432.6 MiB)\n",
      "10-20 14:40:58.103 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.5 MiB)\n",
      "10-20 14:40:58.104 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_117_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.104 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 117 from head at StringIndexer.scala:524\n",
      "10-20 14:40:58.105 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:58.109 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:40:58.109 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 52 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:40:58.109 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 72 (head at StringIndexer.scala:524)\n",
      "10-20 14:40:58.109 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.109 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.110 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[227] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:40:58.111 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_118 stored as values in memory (estimated size 8.9 KiB, free 432.5 MiB)\n",
      "10-20 14:40:58.112 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.5 MiB)\n",
      "10-20 14:40:58.113 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_118_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.113 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.113 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[227] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.113 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.114 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 72.0 (TID 273) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.114 172.17.0.2:54321      6000    (TID 273)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 72.0 (TID 273)\n",
      "10-20 14:40:58.117 172.17.0.2:54321      6000    (TID 273)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/data/part-00000-1f0502b8-35e5-40b2-bf46-70559e28e4de-c000.snappy.parquet, range: 0-725, partition values: [empty row]\n",
      "10-20 14:40:58.121 172.17.0.2:54321      6000    (TID 273)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:58.122 172.17.0.2:54321      6000    (TID 273)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:58.123 172.17.0.2:54321      6000    (TID 273)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:40:58.124 172.17.0.2:54321      6000    (TID 273)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 72.0 (TID 273). 1735 bytes result sent to driver\n",
      "10-20 14:40:58.125 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 72.0 (TID 273) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.125 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.125 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 72 (head at StringIndexer.scala:524) finished in 0.015 s\n",
      "10-20 14:40:58.125 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.125 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished\n",
      "10-20 14:40:58.126 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 52 finished: head at StringIndexer.scala:524, took 0.016834 s\n",
      "10-20 14:40:58.129 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_119 stored as values in memory (estimated size 176.1 KiB, free 432.4 MiB)\n",
      "10-20 14:40:58.133 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.3 MiB)\n",
      "10-20 14:40:58.134 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_119_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.134 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 119 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:58.159 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:58.160 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 53 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:58.160 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 73 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:58.160 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.160 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.160 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 73 (outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata MapPartitionsRDD[229] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:58.161 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_120 stored as values in memory (estimated size 4.2 KiB, free 432.3 MiB)\n",
      "10-20 14:40:58.173 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.3 MiB)\n",
      "10-20 14:40:58.174 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_120_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.174 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.175 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata MapPartitionsRDD[229] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.175 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.175 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_110_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.176 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 73.0 (TID 274) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.178 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_116_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.180 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_109_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.181 172.17.0.2:54321      6000    (TID 274)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 73.0 (TID 274)\n",
      "10-20 14:40:58.182 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_114_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.183 172.17.0.2:54321      6000    (TID 274)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata/part-00000:0+345\n",
      "10-20 14:40:58.184 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_112_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.184 172.17.0.2:54321      6000    (TID 274)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 73.0 (TID 274). 1273 bytes result sent to driver\n",
      "10-20 14:40:58.185 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 73.0 (TID 274) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.185 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.185 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 73 (first at ReadWrite.scala:587) finished in 0.025 s\n",
      "10-20 14:40:58.186 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_111_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.186 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.186 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished\n",
      "10-20 14:40:58.187 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 53 finished: first at ReadWrite.scala:587, took 0.027411 s\n",
      "10-20 14:40:58.188 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_113_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.189 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_117_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.189 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_115_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.190 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_121 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 14:40:58.191 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_107_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.192 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_118_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.194 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_108_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.198 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:58.199 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_121_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.200 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 121 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:58.221 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:58.223 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 54 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:58.223 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 74 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:58.223 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.223 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.224 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 74 (outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata MapPartitionsRDD[231] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:58.225 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_122 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:58.226 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:40:58.226 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_122_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.227 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.228 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata MapPartitionsRDD[231] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.229 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.230 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 74.0 (TID 275) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.231 172.17.0.2:54321      6000    (TID 275)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 74.0 (TID 275)\n",
      "10-20 14:40:58.233 172.17.0.2:54321      6000    (TID 275)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata/part-00000:0+345\n",
      "10-20 14:40:58.234 172.17.0.2:54321      6000    (TID 275)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 74.0 (TID 275). 1273 bytes result sent to driver\n",
      "10-20 14:40:58.235 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 74.0 (TID 275) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.235 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.236 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 74 (first at ReadWrite.scala:587) finished in 0.012 s\n",
      "10-20 14:40:58.236 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.237 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished\n",
      "10-20 14:40:58.237 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 54 finished: first at ReadWrite.scala:587, took 0.015520 s\n",
      "10-20 14:40:58.244 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:58.266 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:40:58.267 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 55 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:40:58.267 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 75 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:40:58.267 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.267 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.268 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[233] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:40:58.273 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_123 stored as values in memory (estimated size 84.5 KiB, free 433.3 MiB)\n",
      "10-20 14:40:58.275 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.3 MiB)\n",
      "10-20 14:40:58.275 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_123_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.276 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.276 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[233] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.277 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.277 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 75.0 (TID 276) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.278 172.17.0.2:54321      6000    (TID 276)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 75.0 (TID 276)\n",
      "10-20 14:40:58.286 172.17.0.2:54321      6000    (TID 276)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 75.0 (TID 276). 1709 bytes result sent to driver\n",
      "10-20 14:40:58.287 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 75.0 (TID 276) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.287 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.288 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 75 (parquet at StringIndexer.scala:523) finished in 0.020 s\n",
      "10-20 14:40:58.288 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.288 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished\n",
      "10-20 14:40:58.288 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 55 finished: parquet at StringIndexer.scala:523, took 0.021468 s\n",
      "10-20 14:40:58.296 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:58.297 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:58.297 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:40:58.303 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_124 stored as values in memory (estimated size 177.5 KiB, free 433.1 MiB)\n",
      "10-20 14:40:58.309 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.1 MiB)\n",
      "10-20 14:40:58.309 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_124_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.310 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 124 from head at StringIndexer.scala:524\n",
      "10-20 14:40:58.310 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:58.314 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:40:58.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 56 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:40:58.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 76 (head at StringIndexer.scala:524)\n",
      "10-20 14:40:58.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[236] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:40:58.318 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_125 stored as values in memory (estimated size 8.9 KiB, free 433.1 MiB)\n",
      "10-20 14:40:58.319 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.1 MiB)\n",
      "10-20 14:40:58.320 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_125_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.320 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.321 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[236] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.321 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.321 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 76.0 (TID 277) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.321 172.17.0.2:54321      6000    (TID 277)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 76.0 (TID 277)\n",
      "10-20 14:40:58.324 172.17.0.2:54321      6000    (TID 277)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/data/part-00000-2dd328c5-8e60-4092-ba23-2d656e8d740d-c000.snappy.parquet, range: 0-648, partition values: [empty row]\n",
      "10-20 14:40:58.328 172.17.0.2:54321      6000    (TID 277)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:58.329 172.17.0.2:54321      6000    (TID 277)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:58.330 172.17.0.2:54321      6000    (TID 277)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:40:58.331 172.17.0.2:54321      6000    (TID 277)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 76.0 (TID 277). 1670 bytes result sent to driver\n",
      "10-20 14:40:58.331 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 76.0 (TID 277) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.332 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.332 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 76 (head at StringIndexer.scala:524) finished in 0.016 s\n",
      "10-20 14:40:58.332 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.332 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished\n",
      "10-20 14:40:58.333 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 56 finished: head at StringIndexer.scala:524, took 0.018145 s\n",
      "10-20 14:40:58.337 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_126 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:40:58.344 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:58.345 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_126_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.346 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 126 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:58.397 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:58.397 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 57 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:58.397 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 77 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:58.397 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.397 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.397 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 77 (outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata MapPartitionsRDD[238] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:58.398 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_127 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:58.400 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:40:58.400 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_127_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.401 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.401 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata MapPartitionsRDD[238] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.401 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.401 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 77.0 (TID 278) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.402 172.17.0.2:54321      6000    (TID 278)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 77.0 (TID 278)\n",
      "10-20 14:40:58.403 172.17.0.2:54321      6000    (TID 278)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata/part-00000:0+367\n",
      "10-20 14:40:58.405 172.17.0.2:54321      6000    (TID 278)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 77.0 (TID 278). 1295 bytes result sent to driver\n",
      "10-20 14:40:58.405 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 77.0 (TID 278) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.405 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.406 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 77 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:40:58.406 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.406 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished\n",
      "10-20 14:40:58.407 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 57 finished: first at ReadWrite.scala:587, took 0.009737 s\n",
      "10-20 14:40:58.409 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_128 stored as values in memory (estimated size 176.1 KiB, free 432.7 MiB)\n",
      "10-20 14:40:58.414 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:40:58.414 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_128_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.415 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 128 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:58.434 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:58.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 58 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:58.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 78 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:58.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 78 (outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata MapPartitionsRDD[240] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:58.435 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_129 stored as values in memory (estimated size 4.2 KiB, free 432.7 MiB)\n",
      "10-20 14:40:58.436 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.7 MiB)\n",
      "10-20 14:40:58.436 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_129_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.436 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.437 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata MapPartitionsRDD[240] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.437 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.437 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 78.0 (TID 279) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.439 172.17.0.2:54321      6000    (TID 279)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 78.0 (TID 279)\n",
      "10-20 14:40:58.440 172.17.0.2:54321      6000    (TID 279)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata/part-00000:0+367\n",
      "10-20 14:40:58.441 172.17.0.2:54321      6000    (TID 279)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 78.0 (TID 279). 1252 bytes result sent to driver\n",
      "10-20 14:40:58.442 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 78.0 (TID 279) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.442 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.442 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 78 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:40:58.443 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.443 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished\n",
      "10-20 14:40:58.443 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 58 finished: first at ReadWrite.scala:587, took 0.009507 s\n",
      "10-20 14:40:58.450 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:58.469 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:40:58.469 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 59 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:40:58.469 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 79 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:40:58.469 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.469 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.470 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[242] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:40:58.476 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_130 stored as values in memory (estimated size 84.5 KiB, free 432.6 MiB)\n",
      "10-20 14:40:58.477 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.5 MiB)\n",
      "10-20 14:40:58.477 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_130_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.477 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.478 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[242] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.478 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.479 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 79.0 (TID 280) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.479 172.17.0.2:54321      6000    (TID 280)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 79.0 (TID 280)\n",
      "10-20 14:40:58.486 172.17.0.2:54321      6000    (TID 280)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 79.0 (TID 280). 1709 bytes result sent to driver\n",
      "10-20 14:40:58.487 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 79.0 (TID 280) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.487 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.488 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 79 (parquet at StringIndexer.scala:523) finished in 0.017 s\n",
      "10-20 14:40:58.488 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.488 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished\n",
      "10-20 14:40:58.488 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 59 finished: parquet at StringIndexer.scala:523, took 0.019564 s\n",
      "10-20 14:40:58.497 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:58.497 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:58.497 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:40:58.502 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_131 stored as values in memory (estimated size 177.5 KiB, free 432.4 MiB)\n",
      "10-20 14:40:58.529 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_127_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.530 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_124_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.532 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_125_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.533 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.6 MiB)\n",
      "10-20 14:40:58.534 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_128_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.535 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_131_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.536 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_122_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.536 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 131 from head at StringIndexer.scala:524\n",
      "10-20 14:40:58.537 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:58.539 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_129_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.543 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:40:58.543 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 60 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:40:58.543 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 80 (head at StringIndexer.scala:524)\n",
      "10-20 14:40:58.543 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.543 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.543 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[245] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:40:58.547 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_132 stored as values in memory (estimated size 8.9 KiB, free 432.8 MiB)\n",
      "10-20 14:40:58.548 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.8 MiB)\n",
      "10-20 14:40:58.548 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_132_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.549 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.549 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[245] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.549 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.550 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 80.0 (TID 281) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.550 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_120_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.550 172.17.0.2:54321      6000    (TID 281)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 80.0 (TID 281)\n",
      "10-20 14:40:58.551 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_123_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.552 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_130_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.553 172.17.0.2:54321      6000    (TID 281)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/data/part-00000-28ad6a8a-320b-413b-8c55-09b9f2ef9bf3-c000.snappy.parquet, range: 0-1080, partition values: [empty row]\n",
      "10-20 14:40:58.554 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_121_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.555 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_119_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.556 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_126_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.558 172.17.0.2:54321      6000    (TID 281)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:58.558 172.17.0.2:54321      6000    (TID 281)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:58.559 172.17.0.2:54321      6000    (TID 281)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:40:58.560 172.17.0.2:54321      6000    (TID 281)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 80.0 (TID 281). 2291 bytes result sent to driver\n",
      "10-20 14:40:58.561 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 80.0 (TID 281) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.561 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.561 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 80 (head at StringIndexer.scala:524) finished in 0.017 s\n",
      "10-20 14:40:58.562 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.562 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished\n",
      "10-20 14:40:58.562 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 60 finished: head at StringIndexer.scala:524, took 0.019276 s\n",
      "10-20 14:40:58.566 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_133 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 14:40:58.574 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:58.575 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_133_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.576 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 133 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:58.610 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:58.611 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 61 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:58.611 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 81 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:58.611 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.611 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.611 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 81 (outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata MapPartitionsRDD[247] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:58.612 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_134 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:58.613 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:40:58.616 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_134_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.617 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.618 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata MapPartitionsRDD[247] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.618 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.618 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 81.0 (TID 282) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.619 172.17.0.2:54321      6000    (TID 282)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 81.0 (TID 282)\n",
      "10-20 14:40:58.620 172.17.0.2:54321      6000    (TID 282)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata/part-00000:0+326\n",
      "10-20 14:40:58.621 172.17.0.2:54321      6000    (TID 282)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 81.0 (TID 282). 1254 bytes result sent to driver\n",
      "10-20 14:40:58.622 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 81.0 (TID 282) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.622 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.623 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 81 (first at ReadWrite.scala:587) finished in 0.012 s\n",
      "10-20 14:40:58.624 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.625 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished\n",
      "10-20 14:40:58.626 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 61 finished: first at ReadWrite.scala:587, took 0.016088 s\n",
      "10-20 14:40:58.629 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_135 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 14:40:58.635 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.2 MiB)\n",
      "10-20 14:40:58.635 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_135_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.637 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 135 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:58.658 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:58.658 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 62 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:58.659 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 82 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:58.659 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.659 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.659 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 82 (outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata MapPartitionsRDD[249] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:58.660 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_136 stored as values in memory (estimated size 4.2 KiB, free 433.2 MiB)\n",
      "10-20 14:40:58.660 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.2 MiB)\n",
      "10-20 14:40:58.660 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_136_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.661 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.662 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata MapPartitionsRDD[249] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.662 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.662 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 82.0 (TID 283) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.663 172.17.0.2:54321      6000    (TID 283)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 82.0 (TID 283)\n",
      "10-20 14:40:58.664 172.17.0.2:54321      6000    (TID 283)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata/part-00000:0+326\n",
      "10-20 14:40:58.666 172.17.0.2:54321      6000    (TID 283)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 82.0 (TID 283). 1254 bytes result sent to driver\n",
      "10-20 14:40:58.666 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 82.0 (TID 283) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.667 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.667 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 82 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:40:58.668 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.668 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished\n",
      "10-20 14:40:58.668 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 62 finished: first at ReadWrite.scala:587, took 0.010245 s\n",
      "10-20 14:40:58.677 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:58.700 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:40:58.701 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 63 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:40:58.701 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 83 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:40:58.701 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.701 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.701 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[251] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:40:58.707 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_137 stored as values in memory (estimated size 84.5 KiB, free 433.1 MiB)\n",
      "10-20 14:40:58.709 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.1 MiB)\n",
      "10-20 14:40:58.709 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_137_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.710 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.710 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[251] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.710 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.711 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 83.0 (TID 284) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.711 172.17.0.2:54321      6000    (TID 284)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 83.0 (TID 284)\n",
      "10-20 14:40:58.721 172.17.0.2:54321      6000    (TID 284)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 83.0 (TID 284). 1705 bytes result sent to driver\n",
      "10-20 14:40:58.727 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 83.0 (TID 284) in 16 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.727 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.728 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 83 (parquet at OneHotEncoder.scala:418) finished in 0.026 s\n",
      "10-20 14:40:58.728 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.728 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished\n",
      "10-20 14:40:58.728 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 63 finished: parquet at OneHotEncoder.scala:418, took 0.027375 s\n",
      "10-20 14:40:58.742 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:58.743 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:58.744 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:40:58.781 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_138 stored as values in memory (estimated size 177.4 KiB, free 432.9 MiB)\n",
      "10-20 14:40:58.788 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.9 MiB)\n",
      "10-20 14:40:58.789 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_138_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.790 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 138 from head at OneHotEncoder.scala:419\n",
      "10-20 14:40:58.790 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:58.794 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:40:58.795 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 64 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:40:58.795 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 84 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:40:58.795 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.795 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.795 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[254] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:40:58.797 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_139 stored as values in memory (estimated size 8.9 KiB, free 432.9 MiB)\n",
      "10-20 14:40:58.798 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.9 MiB)\n",
      "10-20 14:40:58.798 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_139_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.799 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.799 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[254] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.799 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.800 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 84.0 (TID 285) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.800 172.17.0.2:54321      6000    (TID 285)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 84.0 (TID 285)\n",
      "10-20 14:40:58.808 172.17.0.2:54321      6000    (TID 285)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 5.917677 ms\n",
      "10-20 14:40:58.810 172.17.0.2:54321      6000    (TID 285)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/data/part-00000-78b0edea-bc88-4f86-bd46-df3110cd1cc8-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:40:58.815 172.17.0.2:54321      6000    (TID 285)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:58.816 172.17.0.2:54321      6000    (TID 285)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:58.817 172.17.0.2:54321      6000    (TID 285)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:40:58.819 172.17.0.2:54321      6000    (TID 285)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 84.0 (TID 285). 1633 bytes result sent to driver\n",
      "10-20 14:40:58.819 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 84.0 (TID 285) in 19 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.820 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.820 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 84 (head at OneHotEncoder.scala:419) finished in 0.025 s\n",
      "10-20 14:40:58.820 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.820 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished\n",
      "10-20 14:40:58.821 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 64 finished: head at OneHotEncoder.scala:419, took 0.026494 s\n",
      "10-20 14:40:58.831 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.397931 ms\n",
      "10-20 14:40:58.834 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_140 stored as values in memory (estimated size 176.1 KiB, free 432.7 MiB)\n",
      "10-20 14:40:58.838 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:40:58.839 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_140_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.839 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 140 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:58.860 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:58.860 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 65 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:58.860 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 85 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:58.860 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.860 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.860 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 85 (outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata MapPartitionsRDD[256] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:58.861 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_141 stored as values in memory (estimated size 4.2 KiB, free 432.6 MiB)\n",
      "10-20 14:40:58.862 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.6 MiB)\n",
      "10-20 14:40:58.862 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_141_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.862 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.862 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata MapPartitionsRDD[256] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.862 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.863 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 85.0 (TID 286) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.863 172.17.0.2:54321      6000    (TID 286)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 85.0 (TID 286)\n",
      "10-20 14:40:58.866 172.17.0.2:54321      6000    (TID 286)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata/part-00000:0+326\n",
      "10-20 14:40:58.868 172.17.0.2:54321      6000    (TID 286)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 85.0 (TID 286). 1254 bytes result sent to driver\n",
      "10-20 14:40:58.869 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 85.0 (TID 286) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.869 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.870 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 85 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:40:58.870 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.870 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished\n",
      "10-20 14:40:58.870 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 65 finished: first at ReadWrite.scala:587, took 0.010409 s\n",
      "10-20 14:40:58.872 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_142 stored as values in memory (estimated size 176.1 KiB, free 432.5 MiB)\n",
      "10-20 14:40:58.878 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.4 MiB)\n",
      "10-20 14:40:58.878 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_142_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.878 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 142 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:58.898 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:58.898 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 66 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:58.898 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 86 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:58.898 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.899 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.899 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 86 (outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata MapPartitionsRDD[258] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:58.899 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_143 stored as values in memory (estimated size 4.2 KiB, free 432.4 MiB)\n",
      "10-20 14:40:58.911 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.4 MiB)\n",
      "10-20 14:40:58.912 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_143_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.912 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_140_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.912 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.912 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata MapPartitionsRDD[258] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.912 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.913 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 86.0 (TID 287) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.913 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_141_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.914 172.17.0.2:54321      6000    (TID 287)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 86.0 (TID 287)\n",
      "10-20 14:40:58.915 172.17.0.2:54321      6000    (TID 287)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata/part-00000:0+326\n",
      "10-20 14:40:58.916 172.17.0.2:54321      6000    (TID 287)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 86.0 (TID 287). 1211 bytes result sent to driver\n",
      "10-20 14:40:58.917 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 86.0 (TID 287) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.917 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.917 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 86 (first at ReadWrite.scala:587) finished in 0.018 s\n",
      "10-20 14:40:58.917 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.917 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished\n",
      "10-20 14:40:58.917 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_136_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.918 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 66 finished: first at ReadWrite.scala:587, took 0.019518 s\n",
      "10-20 14:40:58.920 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_132_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:58.921 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_133_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.922 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_139_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.923 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_137_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.924 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_134_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.926 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_131_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.927 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_135_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.928 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:58.929 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_138_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.945 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:40:58.946 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 67 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:40:58.946 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 87 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:40:58.946 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.946 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.946 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[260] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:40:58.950 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_144 stored as values in memory (estimated size 84.5 KiB, free 433.5 MiB)\n",
      "10-20 14:40:58.951 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.5 MiB)\n",
      "10-20 14:40:58.951 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_144_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:58.952 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.952 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[260] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.952 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.953 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 87.0 (TID 288) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.953 172.17.0.2:54321      6000    (TID 288)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 87.0 (TID 288)\n",
      "10-20 14:40:58.960 172.17.0.2:54321      6000    (TID 288)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 87.0 (TID 288). 1705 bytes result sent to driver\n",
      "10-20 14:40:58.960 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 87.0 (TID 288) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:58.960 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:58.961 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 87 (parquet at OneHotEncoder.scala:418) finished in 0.015 s\n",
      "10-20 14:40:58.961 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:58.961 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished\n",
      "10-20 14:40:58.961 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 67 finished: parquet at OneHotEncoder.scala:418, took 0.015869 s\n",
      "10-20 14:40:58.968 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:58.968 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:58.968 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:40:58.972 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_145 stored as values in memory (estimated size 177.4 KiB, free 433.3 MiB)\n",
      "10-20 14:40:58.977 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.3 MiB)\n",
      "10-20 14:40:58.978 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_145_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.978 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 145 from head at OneHotEncoder.scala:419\n",
      "10-20 14:40:58.979 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:58.982 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:40:58.984 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 68 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:40:58.984 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 88 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:40:58.984 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:58.984 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:58.984 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[263] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:40:58.987 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_146 stored as values in memory (estimated size 8.9 KiB, free 433.3 MiB)\n",
      "10-20 14:40:58.988 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.3 MiB)\n",
      "10-20 14:40:58.988 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_146_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:58.989 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:58.989 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[263] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:58.989 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:58.991 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 88.0 (TID 289) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:58.991 172.17.0.2:54321      6000    (TID 289)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 88.0 (TID 289)\n",
      "10-20 14:40:58.996 172.17.0.2:54321      6000    (TID 289)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/data/part-00000-9e6216b3-41a9-4b4e-a2ff-f6b5c0484611-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:40:59.000 172.17.0.2:54321      6000    (TID 289)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:59.001 172.17.0.2:54321      6000    (TID 289)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:59.002 172.17.0.2:54321      6000    (TID 289)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:40:59.003 172.17.0.2:54321      6000    (TID 289)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 88.0 (TID 289). 1633 bytes result sent to driver\n",
      "10-20 14:40:59.004 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 88.0 (TID 289) in 14 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.004 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.005 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 88 (head at OneHotEncoder.scala:419) finished in 0.021 s\n",
      "10-20 14:40:59.005 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.005 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished\n",
      "10-20 14:40:59.005 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 68 finished: head at OneHotEncoder.scala:419, took 0.022868 s\n",
      "10-20 14:40:59.009 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_147 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.015 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.015 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_147_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.016 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 147 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:59.041 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:59.042 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 69 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:59.042 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 89 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:59.042 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.042 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.044 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 89 (outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata MapPartitionsRDD[265] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:59.045 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_148 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.046 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.047 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_148_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.047 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.048 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata MapPartitionsRDD[265] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.048 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.049 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 89.0 (TID 290) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.050 172.17.0.2:54321      6000    (TID 290)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 89.0 (TID 290)\n",
      "10-20 14:40:59.053 172.17.0.2:54321      6000    (TID 290)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata/part-00000:0+336\n",
      "10-20 14:40:59.054 172.17.0.2:54321      6000    (TID 290)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 89.0 (TID 290). 1264 bytes result sent to driver\n",
      "10-20 14:40:59.055 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 89.0 (TID 290) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.055 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.056 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 89 (first at ReadWrite.scala:587) finished in 0.012 s\n",
      "10-20 14:40:59.056 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.056 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished\n",
      "10-20 14:40:59.057 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 69 finished: first at ReadWrite.scala:587, took 0.015226 s\n",
      "10-20 14:40:59.059 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_149 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.064 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.065 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_149_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.065 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 149 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:59.084 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:59.085 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 70 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:59.085 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 90 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:59.085 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.085 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.085 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 90 (outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata MapPartitionsRDD[267] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:59.086 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_150 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.086 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.111 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_150_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.112 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.112 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata MapPartitionsRDD[267] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.112 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.113 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 90.0 (TID 291) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.113 172.17.0.2:54321      6000    (TID 291)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 90.0 (TID 291)\n",
      "10-20 14:40:59.115 172.17.0.2:54321      6000    (TID 291)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata/part-00000:0+336\n",
      "10-20 14:40:59.116 172.17.0.2:54321      6000    (TID 291)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 90.0 (TID 291). 1264 bytes result sent to driver\n",
      "10-20 14:40:59.117 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 90.0 (TID 291) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.117 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.117 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 90 (first at ReadWrite.scala:587) finished in 0.032 s\n",
      "10-20 14:40:59.118 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.118 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished\n",
      "10-20 14:40:59.118 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 70 finished: first at ReadWrite.scala:587, took 0.033842 s\n",
      "10-20 14:40:59.127 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:59.145 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:40:59.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 71 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:40:59.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 91 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:40:59.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[269] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:40:59.150 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_151 stored as values in memory (estimated size 84.5 KiB, free 432.8 MiB)\n",
      "10-20 14:40:59.152 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.7 MiB)\n",
      "10-20 14:40:59.152 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_151_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.152 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.152 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[269] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.152 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.153 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 91.0 (TID 292) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.154 172.17.0.2:54321      6000    (TID 292)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 91.0 (TID 292)\n",
      "10-20 14:40:59.161 172.17.0.2:54321      6000    (TID 292)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 91.0 (TID 292). 1705 bytes result sent to driver\n",
      "10-20 14:40:59.162 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 91.0 (TID 292) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.162 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.162 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 91 (parquet at OneHotEncoder.scala:418) finished in 0.016 s\n",
      "10-20 14:40:59.162 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.162 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished\n",
      "10-20 14:40:59.163 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 71 finished: parquet at OneHotEncoder.scala:418, took 0.017880 s\n",
      "10-20 14:40:59.170 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:59.170 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:59.171 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:40:59.176 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_152 stored as values in memory (estimated size 177.4 KiB, free 432.6 MiB)\n",
      "10-20 14:40:59.181 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.5 MiB)\n",
      "10-20 14:40:59.181 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_152_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.181 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 152 from head at OneHotEncoder.scala:419\n",
      "10-20 14:40:59.181 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:59.187 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:40:59.187 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 72 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:40:59.187 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 92 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:40:59.187 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.188 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.188 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[272] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:40:59.190 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_153 stored as values in memory (estimated size 8.9 KiB, free 432.5 MiB)\n",
      "10-20 14:40:59.191 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.5 MiB)\n",
      "10-20 14:40:59.192 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_153_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.192 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.193 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[272] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.193 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.194 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 92.0 (TID 293) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.195 172.17.0.2:54321      6000    (TID 293)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 92.0 (TID 293)\n",
      "10-20 14:40:59.198 172.17.0.2:54321      6000    (TID 293)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/data/part-00000-4eac8902-db0d-4f97-9a53-b0ec6f2f61d6-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:40:59.201 172.17.0.2:54321      6000    (TID 293)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:59.202 172.17.0.2:54321      6000    (TID 293)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:59.203 172.17.0.2:54321      6000    (TID 293)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:40:59.204 172.17.0.2:54321      6000    (TID 293)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 92.0 (TID 293). 1633 bytes result sent to driver\n",
      "10-20 14:40:59.205 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 92.0 (TID 293) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.205 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.205 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 92 (head at OneHotEncoder.scala:419) finished in 0.017 s\n",
      "10-20 14:40:59.205 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.205 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished\n",
      "10-20 14:40:59.206 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 72 finished: head at OneHotEncoder.scala:419, took 0.019109 s\n",
      "10-20 14:40:59.210 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_154 stored as values in memory (estimated size 176.1 KiB, free 432.4 MiB)\n",
      "10-20 14:40:59.217 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.3 MiB)\n",
      "10-20 14:40:59.217 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_154_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.218 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 154 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:59.240 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:59.240 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 73 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:59.240 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 93 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:59.240 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.240 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.241 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 93 (outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata MapPartitionsRDD[274] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:59.244 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_155 stored as values in memory (estimated size 4.2 KiB, free 432.3 MiB)\n",
      "10-20 14:40:59.278 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.3 MiB)\n",
      "10-20 14:40:59.279 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_155_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.282 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.282 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata MapPartitionsRDD[274] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.282 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.286 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 93.0 (TID 294) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.286 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_142_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.287 172.17.0.2:54321      6000    (TID 294)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 93.0 (TID 294)\n",
      "10-20 14:40:59.289 172.17.0.2:54321      6000    (TID 294)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata/part-00000:0+328\n",
      "10-20 14:40:59.291 172.17.0.2:54321      6000    (TID 294)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 93.0 (TID 294). 1256 bytes result sent to driver\n",
      "10-20 14:40:59.292 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 93.0 (TID 294) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.293 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.294 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_143_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.294 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 93 (first at ReadWrite.scala:587) finished in 0.053 s\n",
      "10-20 14:40:59.295 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.295 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished\n",
      "10-20 14:40:59.295 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 73 finished: first at ReadWrite.scala:587, took 0.055241 s\n",
      "10-20 14:40:59.297 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_156 stored as values in memory (estimated size 176.1 KiB, free 432.4 MiB)\n",
      "10-20 14:40:59.304 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.3 MiB)\n",
      "10-20 14:40:59.305 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_156_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.306 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_144_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.306 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 156 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:59.307 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_150_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.308 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_149_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.309 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_151_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.311 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_147_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.312 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_153_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.314 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_152_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.315 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_148_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.316 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_145_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:59.318 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_146_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:59.328 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:59.328 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 74 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:59.328 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 94 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:59.328 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.329 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.329 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 94 (outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata MapPartitionsRDD[276] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:59.330 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_157 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:59.331 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:40:59.331 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_157_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:59.331 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.331 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata MapPartitionsRDD[276] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.332 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.332 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 94.0 (TID 295) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.333 172.17.0.2:54321      6000    (TID 295)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 94.0 (TID 295)\n",
      "10-20 14:40:59.334 172.17.0.2:54321      6000    (TID 295)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata/part-00000:0+328\n",
      "10-20 14:40:59.335 172.17.0.2:54321      6000    (TID 295)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 94.0 (TID 295). 1256 bytes result sent to driver\n",
      "10-20 14:40:59.336 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 94.0 (TID 295) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.336 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.338 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 94 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:40:59.338 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.338 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished\n",
      "10-20 14:40:59.339 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 74 finished: first at ReadWrite.scala:587, took 0.010392 s\n",
      "10-20 14:40:59.346 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:59.365 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:40:59.365 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 75 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:40:59.365 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 95 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:40:59.365 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.365 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.366 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[278] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:40:59.370 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_158 stored as values in memory (estimated size 84.5 KiB, free 433.3 MiB)\n",
      "10-20 14:40:59.372 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.3 MiB)\n",
      "10-20 14:40:59.372 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_158_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.373 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.373 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[278] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.373 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 95.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.374 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 95.0 (TID 296) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.374 172.17.0.2:54321      6000    (TID 296)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 95.0 (TID 296)\n",
      "10-20 14:40:59.385 172.17.0.2:54321      6000    (TID 296)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 95.0 (TID 296). 1705 bytes result sent to driver\n",
      "10-20 14:40:59.386 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 95.0 (TID 296) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.386 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.386 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 95 (parquet at OneHotEncoder.scala:418) finished in 0.020 s\n",
      "10-20 14:40:59.386 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.386 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 95: Stage finished\n",
      "10-20 14:40:59.387 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 75 finished: parquet at OneHotEncoder.scala:418, took 0.021979 s\n",
      "10-20 14:40:59.398 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:59.398 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:59.398 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:40:59.405 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_159 stored as values in memory (estimated size 177.4 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.411 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.412 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_159_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.413 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 159 from head at OneHotEncoder.scala:419\n",
      "10-20 14:40:59.413 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:59.417 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:40:59.418 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 76 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:40:59.418 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 96 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:40:59.418 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.418 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.418 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[281] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:40:59.420 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_160 stored as values in memory (estimated size 8.9 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.421 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.421 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_160_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.422 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.422 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[281] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.422 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.423 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 96.0 (TID 297) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.424 172.17.0.2:54321      6000    (TID 297)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 96.0 (TID 297)\n",
      "10-20 14:40:59.427 172.17.0.2:54321      6000    (TID 297)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/data/part-00000-ef2a2ef5-f2b1-4c06-b402-6c6b518f0107-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:40:59.430 172.17.0.2:54321      6000    (TID 297)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:59.431 172.17.0.2:54321      6000    (TID 297)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:59.431 172.17.0.2:54321      6000    (TID 297)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:40:59.432 172.17.0.2:54321      6000    (TID 297)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 96.0 (TID 297). 1629 bytes result sent to driver\n",
      "10-20 14:40:59.433 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 96.0 (TID 297) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.434 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 96 (head at OneHotEncoder.scala:419) finished in 0.016 s\n",
      "10-20 14:40:59.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.435 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 96: Stage finished\n",
      "10-20 14:40:59.435 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 76 finished: head at OneHotEncoder.scala:419, took 0.017319 s\n",
      "10-20 14:40:59.439 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_161 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.445 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.446 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_161_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.447 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 161 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:59.470 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:59.471 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 77 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:59.471 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 97 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:59.471 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.471 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.472 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 97 (outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata MapPartitionsRDD[283] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:59.473 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_162 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.474 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.475 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_162_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.476 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata MapPartitionsRDD[283] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.476 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.477 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 97.0 (TID 298) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.478 172.17.0.2:54321      6000    (TID 298)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 97.0 (TID 298)\n",
      "10-20 14:40:59.479 172.17.0.2:54321      6000    (TID 298)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata/part-00000:0+332\n",
      "10-20 14:40:59.480 172.17.0.2:54321      6000    (TID 298)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 97.0 (TID 298). 1217 bytes result sent to driver\n",
      "10-20 14:40:59.481 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 97.0 (TID 298) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.481 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.481 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 97 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:40:59.481 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.481 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished\n",
      "10-20 14:40:59.481 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 77 finished: first at ReadWrite.scala:587, took 0.011503 s\n",
      "10-20 14:40:59.483 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_163 stored as values in memory (estimated size 176.1 KiB, free 432.7 MiB)\n",
      "10-20 14:40:59.515 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:40:59.515 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_163_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.516 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 163 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:59.535 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:59.536 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 78 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:59.536 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 98 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:59.536 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.536 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.538 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 98 (outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata MapPartitionsRDD[285] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:59.539 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_164 stored as values in memory (estimated size 4.2 KiB, free 432.7 MiB)\n",
      "10-20 14:40:59.540 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.7 MiB)\n",
      "10-20 14:40:59.540 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_164_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.541 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.541 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata MapPartitionsRDD[285] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.541 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.543 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 98.0 (TID 299) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.543 172.17.0.2:54321      6000    (TID 299)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 98.0 (TID 299)\n",
      "10-20 14:40:59.544 172.17.0.2:54321      6000    (TID 299)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata/part-00000:0+332\n",
      "10-20 14:40:59.545 172.17.0.2:54321      6000    (TID 299)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 98.0 (TID 299). 1260 bytes result sent to driver\n",
      "10-20 14:40:59.546 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 98.0 (TID 299) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.547 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.547 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 98 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:40:59.547 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.547 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished\n",
      "10-20 14:40:59.548 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 78 finished: first at ReadWrite.scala:587, took 0.012123 s\n",
      "10-20 14:40:59.554 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:59.575 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:40:59.575 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 79 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:40:59.575 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 99 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:40:59.575 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.575 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.575 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[287] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:40:59.580 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_165 stored as values in memory (estimated size 84.5 KiB, free 432.6 MiB)\n",
      "10-20 14:40:59.581 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.5 MiB)\n",
      "10-20 14:40:59.581 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_165_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.583 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.583 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[287] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.583 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.584 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 99.0 (TID 300) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.584 172.17.0.2:54321      6000    (TID 300)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 99.0 (TID 300)\n",
      "10-20 14:40:59.591 172.17.0.2:54321      6000    (TID 300)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 99.0 (TID 300). 1705 bytes result sent to driver\n",
      "10-20 14:40:59.592 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 99.0 (TID 300) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.592 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.593 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 99 (parquet at OneHotEncoder.scala:418) finished in 0.016 s\n",
      "10-20 14:40:59.593 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.593 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished\n",
      "10-20 14:40:59.593 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 79 finished: parquet at OneHotEncoder.scala:418, took 0.018205 s\n",
      "10-20 14:40:59.600 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:59.601 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:59.601 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:40:59.607 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_166 stored as values in memory (estimated size 177.4 KiB, free 432.4 MiB)\n",
      "10-20 14:40:59.613 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.3 MiB)\n",
      "10-20 14:40:59.613 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_166_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.614 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 166 from head at OneHotEncoder.scala:419\n",
      "10-20 14:40:59.615 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:59.619 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:40:59.620 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 80 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:40:59.620 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 100 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:40:59.620 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.620 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.620 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[290] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:40:59.622 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_167 stored as values in memory (estimated size 8.9 KiB, free 432.3 MiB)\n",
      "10-20 14:40:59.623 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.3 MiB)\n",
      "10-20 14:40:59.623 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_167_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.624 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.624 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[290] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.624 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.625 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 100.0 (TID 301) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.625 172.17.0.2:54321      6000    (TID 301)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 100.0 (TID 301)\n",
      "10-20 14:40:59.627 172.17.0.2:54321      6000    (TID 301)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/data/part-00000-e76ba9d1-8323-4b58-8a2d-73b24a0df199-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:40:59.630 172.17.0.2:54321      6000    (TID 301)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:59.630 172.17.0.2:54321      6000    (TID 301)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:59.630 172.17.0.2:54321      6000    (TID 301)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:40:59.631 172.17.0.2:54321      6000    (TID 301)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 100.0 (TID 301). 1633 bytes result sent to driver\n",
      "10-20 14:40:59.633 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 100.0 (TID 301) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.633 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.634 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 100 (head at OneHotEncoder.scala:419) finished in 0.014 s\n",
      "10-20 14:40:59.634 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.634 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 100: Stage finished\n",
      "10-20 14:40:59.635 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 80 finished: head at OneHotEncoder.scala:419, took 0.015016 s\n",
      "10-20 14:40:59.638 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_168 stored as values in memory (estimated size 176.1 KiB, free 432.2 MiB)\n",
      "10-20 14:40:59.657 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_165_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.659 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_166_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.660 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.4 MiB)\n",
      "10-20 14:40:59.661 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_168_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.661 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_157_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.662 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 168 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:59.663 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_154_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.665 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_156_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.667 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_163_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.668 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_167_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.669 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_155_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.670 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_159_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.671 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_164_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.673 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_160_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.673 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_162_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.675 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_161_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:59.676 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_158_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:59.687 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:59.688 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 81 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:59.688 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 101 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:59.688 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.688 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.689 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 101 (outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata MapPartitionsRDD[292] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:59.689 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_169 stored as values in memory (estimated size 4.2 KiB, free 433.6 MiB)\n",
      "10-20 14:40:59.690 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:40:59.690 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_169_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:59.691 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.691 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata MapPartitionsRDD[292] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.691 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 101.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.692 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 101.0 (TID 302) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.692 172.17.0.2:54321      6000    (TID 302)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 101.0 (TID 302)\n",
      "10-20 14:40:59.694 172.17.0.2:54321      6000    (TID 302)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata/part-00000:0+316\n",
      "10-20 14:40:59.695 172.17.0.2:54321      6000    (TID 302)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 101.0 (TID 302). 1244 bytes result sent to driver\n",
      "10-20 14:40:59.696 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 101.0 (TID 302) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.696 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.696 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 101 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:40:59.697 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.697 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 101: Stage finished\n",
      "10-20 14:40:59.697 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 81 finished: first at ReadWrite.scala:587, took 0.009567 s\n",
      "10-20 14:40:59.699 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_170 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 14:40:59.704 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:59.705 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_170_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:59.705 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 170 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:59.724 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:59.724 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 82 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:59.725 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 102 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:59.725 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.725 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.725 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 102 (outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata MapPartitionsRDD[294] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:59.727 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_171 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:40:59.728 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:40:59.728 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_171_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:40:59.728 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.729 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata MapPartitionsRDD[294] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.729 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.730 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 102.0 (TID 303) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.730 172.17.0.2:54321      6000    (TID 303)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 102.0 (TID 303)\n",
      "10-20 14:40:59.731 172.17.0.2:54321      6000    (TID 303)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata/part-00000:0+316\n",
      "10-20 14:40:59.733 172.17.0.2:54321      6000    (TID 303)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 102.0 (TID 303). 1244 bytes result sent to driver\n",
      "10-20 14:40:59.733 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 102.0 (TID 303) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.733 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.734 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 102 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:40:59.734 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.734 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 102: Stage finished\n",
      "10-20 14:40:59.734 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 82 finished: first at ReadWrite.scala:587, took 0.010362 s\n",
      "10-20 14:40:59.741 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:59.760 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:40:59.760 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 83 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:40:59.760 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 103 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:40:59.760 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.760 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.760 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[296] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:40:59.765 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_172 stored as values in memory (estimated size 84.5 KiB, free 433.3 MiB)\n",
      "10-20 14:40:59.767 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.3 MiB)\n",
      "10-20 14:40:59.768 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_172_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.768 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.769 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[296] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.769 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.770 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 103.0 (TID 304) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.771 172.17.0.2:54321      6000    (TID 304)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 103.0 (TID 304)\n",
      "10-20 14:40:59.784 172.17.0.2:54321      6000    (TID 304)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 103.0 (TID 304). 1705 bytes result sent to driver\n",
      "10-20 14:40:59.785 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 103.0 (TID 304) in 15 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.785 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.785 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 103 (parquet at OneHotEncoder.scala:418) finished in 0.024 s\n",
      "10-20 14:40:59.786 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.786 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished\n",
      "10-20 14:40:59.786 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 83 finished: parquet at OneHotEncoder.scala:418, took 0.026237 s\n",
      "10-20 14:40:59.799 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:40:59.799 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:40:59.799 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:40:59.809 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_173 stored as values in memory (estimated size 177.4 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.815 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.816 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_173_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.817 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 173 from head at OneHotEncoder.scala:419\n",
      "10-20 14:40:59.817 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:40:59.823 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:40:59.823 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 84 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:40:59.824 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 104 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:40:59.824 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.824 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.824 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[299] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:40:59.831 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_174 stored as values in memory (estimated size 8.9 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.832 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.1 MiB)\n",
      "10-20 14:40:59.833 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_174_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.833 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.834 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[299] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.834 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 104.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.835 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 104.0 (TID 305) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.835 172.17.0.2:54321      6000    (TID 305)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 104.0 (TID 305)\n",
      "10-20 14:40:59.838 172.17.0.2:54321      6000    (TID 305)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/data/part-00000-0f750067-deed-48fb-936b-5d79e4b4a5da-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:40:59.841 172.17.0.2:54321      6000    (TID 305)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:40:59.841 172.17.0.2:54321      6000    (TID 305)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:40:59.842 172.17.0.2:54321      6000    (TID 305)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:40:59.842 172.17.0.2:54321      6000    (TID 305)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 104.0 (TID 305). 1633 bytes result sent to driver\n",
      "10-20 14:40:59.843 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 104.0 (TID 305) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.843 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.843 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 104 (head at OneHotEncoder.scala:419) finished in 0.019 s\n",
      "10-20 14:40:59.843 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.843 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 104: Stage finished\n",
      "10-20 14:40:59.845 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 84 finished: head at OneHotEncoder.scala:419, took 0.021889 s\n",
      "10-20 14:40:59.848 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_175 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.854 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.854 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_175_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.855 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 175 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:59.904 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:59.904 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 85 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:59.904 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 105 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:59.904 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.904 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.904 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 105 (outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata MapPartitionsRDD[301] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:59.905 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_176 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.905 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:40:59.906 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_176_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:40:59.906 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.906 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata MapPartitionsRDD[301] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.906 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.907 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 105.0 (TID 306) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.907 172.17.0.2:54321      6000    (TID 306)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 105.0 (TID 306)\n",
      "10-20 14:40:59.909 172.17.0.2:54321      6000    (TID 306)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata/part-00000:0+314\n",
      "10-20 14:40:59.913 172.17.0.2:54321      6000    (TID 306)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 105.0 (TID 306). 1242 bytes result sent to driver\n",
      "10-20 14:40:59.913 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 105.0 (TID 306) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.913 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.914 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 105 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:40:59.914 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.914 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished\n",
      "10-20 14:40:59.915 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 85 finished: first at ReadWrite.scala:587, took 0.011044 s\n",
      "10-20 14:40:59.917 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_177 stored as values in memory (estimated size 176.1 KiB, free 432.7 MiB)\n",
      "10-20 14:40:59.922 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:40:59.922 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_177_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.923 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 177 from textFile at ReadWrite.scala:587\n",
      "10-20 14:40:59.941 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:40:59.942 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 86 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:40:59.942 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 106 (first at ReadWrite.scala:587)\n",
      "10-20 14:40:59.942 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.942 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.942 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 106 (outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata MapPartitionsRDD[303] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:40:59.943 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_178 stored as values in memory (estimated size 4.2 KiB, free 432.7 MiB)\n",
      "10-20 14:40:59.943 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.7 MiB)\n",
      "10-20 14:40:59.944 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_178_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.945 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.945 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata MapPartitionsRDD[303] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.945 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.945 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 106.0 (TID 307) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.946 172.17.0.2:54321      6000    (TID 307)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 106.0 (TID 307)\n",
      "10-20 14:40:59.948 172.17.0.2:54321      6000    (TID 307)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata/part-00000:0+314\n",
      "10-20 14:40:59.950 172.17.0.2:54321      6000    (TID 307)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 106.0 (TID 307). 1242 bytes result sent to driver\n",
      "10-20 14:40:59.950 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 106.0 (TID 307) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.950 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.951 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 106 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:40:59.951 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.951 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished\n",
      "10-20 14:40:59.951 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 86 finished: first at ReadWrite.scala:587, took 0.009694 s\n",
      "10-20 14:40:59.956 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:40:59.976 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:40:59.977 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 87 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:40:59.977 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 107 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:40:59.977 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:40:59.977 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:40:59.977 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[305] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:40:59.982 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_179 stored as values in memory (estimated size 84.5 KiB, free 432.6 MiB)\n",
      "10-20 14:40:59.983 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.5 MiB)\n",
      "10-20 14:40:59.983 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_179_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:40:59.984 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:40:59.984 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[305] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:40:59.984 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0\n",
      "10-20 14:40:59.985 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 107.0 (TID 308) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:40:59.985 172.17.0.2:54321      6000    (TID 308)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 107.0 (TID 308)\n",
      "10-20 14:40:59.994 172.17.0.2:54321      6000    (TID 308)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 107.0 (TID 308). 1705 bytes result sent to driver\n",
      "10-20 14:40:59.994 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 107.0 (TID 308) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:40:59.995 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool \n",
      "10-20 14:40:59.995 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 107 (parquet at OneHotEncoder.scala:418) finished in 0.018 s\n",
      "10-20 14:40:59.995 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:40:59.995 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 107: Stage finished\n",
      "10-20 14:40:59.996 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 87 finished: parquet at OneHotEncoder.scala:418, took 0.019040 s\n",
      "10-20 14:41:00.004 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:00.004 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:00.004 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:41:00.010 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_180 stored as values in memory (estimated size 177.4 KiB, free 432.4 MiB)\n",
      "10-20 14:41:00.019 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.3 MiB)\n",
      "10-20 14:41:00.020 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_180_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.021 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 180 from head at OneHotEncoder.scala:419\n",
      "10-20 14:41:00.021 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:00.026 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:41:00.027 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 88 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:41:00.027 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 108 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:41:00.027 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.027 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.028 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[308] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:41:00.030 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_181 stored as values in memory (estimated size 8.9 KiB, free 432.3 MiB)\n",
      "10-20 14:41:00.054 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.3 MiB)\n",
      "10-20 14:41:00.054 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_181_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.055 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_177_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.055 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.055 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[308] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:00.055 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 108.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:00.056 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 108.0 (TID 309) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.056 172.17.0.2:54321      6000    (TID 309)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 108.0 (TID 309)\n",
      "10-20 14:41:00.059 172.17.0.2:54321      6000    (TID 309)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/data/part-00000-9af656e9-9db7-48f1-94c4-7a2178967e64-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:41:00.060 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_178_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.061 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_173_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.063 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_170_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.064 172.17.0.2:54321      6000    (TID 309)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:00.064 172.17.0.2:54321      6000    (TID 309)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:00.065 172.17.0.2:54321      6000    (TID 309)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:41:00.065 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_171_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.066 172.17.0.2:54321      6000    (TID 309)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 108.0 (TID 309). 1633 bytes result sent to driver\n",
      "10-20 14:41:00.066 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 108.0 (TID 309) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:00.066 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 108 (head at OneHotEncoder.scala:419) finished in 0.038 s\n",
      "10-20 14:41:00.067 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.067 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 108: Stage finished\n",
      "10-20 14:41:00.067 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 88 finished: head at OneHotEncoder.scala:419, took 0.040349 s\n",
      "10-20 14:41:00.070 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_179_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.071 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_182 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:41:00.072 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_169_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.074 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_172_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.075 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_168_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:00.076 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_174_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:00.077 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.2 MiB)\n",
      "10-20 14:41:00.077 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_182_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.078 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 182 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:00.079 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_175_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:00.080 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_176_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:00.098 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:00.098 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 89 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:00.098 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 109 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:00.098 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.098 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.098 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 109 (outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata MapPartitionsRDD[310] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:00.099 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_183 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:41:00.100 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:41:00.101 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_183_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:00.101 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.102 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata MapPartitionsRDD[310] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:00.102 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 109.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:00.102 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 109.0 (TID 310) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.103 172.17.0.2:54321      6000    (TID 310)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 109.0 (TID 310)\n",
      "10-20 14:41:00.104 172.17.0.2:54321      6000    (TID 310)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata/part-00000:0+336\n",
      "10-20 14:41:00.106 172.17.0.2:54321      6000    (TID 310)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 109.0 (TID 310). 1264 bytes result sent to driver\n",
      "10-20 14:41:00.106 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 109.0 (TID 310) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:00.106 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.107 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 109 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:41:00.107 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.107 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 109: Stage finished\n",
      "10-20 14:41:00.108 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 89 finished: first at ReadWrite.scala:587, took 0.010053 s\n",
      "10-20 14:41:00.109 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_184 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 14:41:00.115 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.2 MiB)\n",
      "10-20 14:41:00.116 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_184_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.117 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 184 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:00.141 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:00.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 90 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:00.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 110 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:00.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.143 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 110 (outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata MapPartitionsRDD[312] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:00.143 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_185 stored as values in memory (estimated size 4.2 KiB, free 433.2 MiB)\n",
      "10-20 14:41:00.144 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.2 MiB)\n",
      "10-20 14:41:00.144 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_185_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata MapPartitionsRDD[312] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:00.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:00.146 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 110.0 (TID 311) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.146 172.17.0.2:54321      6000    (TID 311)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 110.0 (TID 311)\n",
      "10-20 14:41:00.148 172.17.0.2:54321      6000    (TID 311)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata/part-00000:0+336\n",
      "10-20 14:41:00.149 172.17.0.2:54321      6000    (TID 311)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 110.0 (TID 311). 1264 bytes result sent to driver\n",
      "10-20 14:41:00.150 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 110.0 (TID 311) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:00.150 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.151 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 110 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:41:00.152 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.152 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 110: Stage finished\n",
      "10-20 14:41:00.152 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 90 finished: first at ReadWrite.scala:587, took 0.010504 s\n",
      "10-20 14:41:00.158 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:00.178 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:41:00.179 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 91 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:41:00.179 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 111 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:41:00.179 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.179 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.179 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[314] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:41:00.184 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_186 stored as values in memory (estimated size 84.5 KiB, free 433.1 MiB)\n",
      "10-20 14:41:00.185 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.1 MiB)\n",
      "10-20 14:41:00.186 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_186_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.186 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.187 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[314] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:00.187 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 111.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:00.187 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 111.0 (TID 312) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.188 172.17.0.2:54321      6000    (TID 312)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 111.0 (TID 312)\n",
      "10-20 14:41:00.195 172.17.0.2:54321      6000    (TID 312)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 111.0 (TID 312). 1705 bytes result sent to driver\n",
      "10-20 14:41:00.196 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 111.0 (TID 312) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:00.196 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.196 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 111 (parquet at OneHotEncoder.scala:418) finished in 0.016 s\n",
      "10-20 14:41:00.196 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.196 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished\n",
      "10-20 14:41:00.197 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 91 finished: parquet at OneHotEncoder.scala:418, took 0.018220 s\n",
      "10-20 14:41:00.203 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:00.204 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:00.204 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:41:00.209 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_187 stored as values in memory (estimated size 177.4 KiB, free 432.9 MiB)\n",
      "10-20 14:41:00.215 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.9 MiB)\n",
      "10-20 14:41:00.215 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_187_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.216 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 187 from head at OneHotEncoder.scala:419\n",
      "10-20 14:41:00.217 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:00.224 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:41:00.226 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 92 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:41:00.226 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 112 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:41:00.226 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.226 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.226 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[317] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:41:00.230 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_188 stored as values in memory (estimated size 8.9 KiB, free 432.9 MiB)\n",
      "10-20 14:41:00.231 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.9 MiB)\n",
      "10-20 14:41:00.232 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_188_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.233 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.233 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[317] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:00.233 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 112.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:00.234 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 112.0 (TID 313) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.234 172.17.0.2:54321      6000    (TID 313)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 112.0 (TID 313)\n",
      "10-20 14:41:00.238 172.17.0.2:54321      6000    (TID 313)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/data/part-00000-8110f113-1580-4784-b3c6-55f059a5695f-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:41:00.241 172.17.0.2:54321      6000    (TID 313)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:00.242 172.17.0.2:54321      6000    (TID 313)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:00.242 172.17.0.2:54321      6000    (TID 313)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:00.244 172.17.0.2:54321      6000    (TID 313)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 112.0 (TID 313). 1633 bytes result sent to driver\n",
      "10-20 14:41:00.244 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 112.0 (TID 313) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:00.245 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.245 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 112 (head at OneHotEncoder.scala:419) finished in 0.017 s\n",
      "10-20 14:41:00.245 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.245 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 112: Stage finished\n",
      "10-20 14:41:00.246 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 92 finished: head at OneHotEncoder.scala:419, took 0.020690 s\n",
      "10-20 14:41:00.249 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_189 stored as values in memory (estimated size 176.1 KiB, free 432.7 MiB)\n",
      "10-20 14:41:00.258 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:41:00.258 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_189_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.259 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 189 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:00.313 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:00.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 93 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:00.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 113 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:00.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.315 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 113 (outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata MapPartitionsRDD[319] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:00.317 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_190 stored as values in memory (estimated size 4.2 KiB, free 432.6 MiB)\n",
      "10-20 14:41:00.318 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.6 MiB)\n",
      "10-20 14:41:00.319 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_190_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.319 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.319 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata MapPartitionsRDD[319] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:00.320 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 113.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:00.320 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 113.0 (TID 314) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4579 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.321 172.17.0.2:54321      6000    (TID 314)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 113.0 (TID 314)\n",
      "10-20 14:41:00.322 172.17.0.2:54321      6000    (TID 314)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata/part-00000:0+520\n",
      "10-20 14:41:00.324 172.17.0.2:54321      6000    (TID 314)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 113.0 (TID 314). 1448 bytes result sent to driver\n",
      "10-20 14:41:00.325 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 113.0 (TID 314) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:00.325 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.326 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 113 (first at ReadWrite.scala:587) finished in 0.010 s\n",
      "10-20 14:41:00.327 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.327 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished\n",
      "10-20 14:41:00.328 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 93 finished: first at ReadWrite.scala:587, took 0.013863 s\n",
      "10-20 14:41:00.337 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_191 stored as values in memory (estimated size 176.1 KiB, free 432.5 MiB)\n",
      "10-20 14:41:00.345 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.4 MiB)\n",
      "10-20 14:41:00.346 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_191_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.347 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 191 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:00.371 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:00.372 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 94 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:00.372 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 114 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:00.372 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.372 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.372 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 114 (outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata MapPartitionsRDD[321] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:00.374 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_192 stored as values in memory (estimated size 4.2 KiB, free 432.4 MiB)\n",
      "10-20 14:41:00.375 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.4 MiB)\n",
      "10-20 14:41:00.375 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_192_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.376 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.376 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata MapPartitionsRDD[321] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:00.376 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 114.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:00.377 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 114.0 (TID 315) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4579 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.378 172.17.0.2:54321      6000    (TID 315)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 114.0 (TID 315)\n",
      "10-20 14:41:00.379 172.17.0.2:54321      6000    (TID 315)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata/part-00000:0+520\n",
      "10-20 14:41:00.381 172.17.0.2:54321      6000    (TID 315)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 114.0 (TID 315). 1448 bytes result sent to driver\n",
      "10-20 14:41:00.383 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 114.0 (TID 315) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:00.383 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.384 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 114 (first at ReadWrite.scala:587) finished in 0.011 s\n",
      "10-20 14:41:00.384 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.384 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 114: Stage finished\n",
      "10-20 14:41:00.385 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 94 finished: first at ReadWrite.scala:587, took 0.014029 s\n",
      "10-20 14:41:00.388 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_193 stored as values in memory (estimated size 176.1 KiB, free 432.3 MiB)\n",
      "10-20 14:41:00.398 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.2 MiB)\n",
      "10-20 14:41:00.399 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_193_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.400 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 193 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:00.433 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:00.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 95 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:00.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 115 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:00.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.434 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 115 (outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata MapPartitionsRDD[323] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:00.436 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_194 stored as values in memory (estimated size 4.2 KiB, free 432.2 MiB)\n",
      "10-20 14:41:00.437 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.2 MiB)\n",
      "10-20 14:41:00.437 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_194_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.437 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.438 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata MapPartitionsRDD[323] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:00.438 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 115.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:00.439 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 115.0 (TID 316) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4586 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.439 172.17.0.2:54321      6000    (TID 316)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 115.0 (TID 316)\n",
      "10-20 14:41:00.442 172.17.0.2:54321      6000    (TID 316)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata/part-00000:0+742\n",
      "10-20 14:41:00.444 172.17.0.2:54321      6000    (TID 316)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 115.0 (TID 316). 1670 bytes result sent to driver\n",
      "10-20 14:41:00.445 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 115.0 (TID 316) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:00.445 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.446 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 115 (first at ReadWrite.scala:587) finished in 0.011 s\n",
      "10-20 14:41:00.446 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 95 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.446 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 115: Stage finished\n",
      "10-20 14:41:00.447 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 95 finished: first at ReadWrite.scala:587, took 0.013177 s\n",
      "10-20 14:41:00.455 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_195 stored as values in memory (estimated size 176.1 KiB, free 432.1 MiB)\n",
      "10-20 14:41:00.462 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.0 MiB)\n",
      "10-20 14:41:00.462 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_195_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.462 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 195 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:00.493 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:00.493 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 96 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:00.494 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 116 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:00.494 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.494 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.494 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 116 (outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata MapPartitionsRDD[325] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:00.497 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_196 stored as values in memory (estimated size 4.2 KiB, free 432.0 MiB)\n",
      "10-20 14:41:00.499 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.0 MiB)\n",
      "10-20 14:41:00.500 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_196_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.501 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.501 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata MapPartitionsRDD[325] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:00.501 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 116.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:00.502 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 116.0 (TID 317) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4586 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.503 172.17.0.2:54321      6000    (TID 317)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 116.0 (TID 317)\n",
      "10-20 14:41:00.505 172.17.0.2:54321      6000    (TID 317)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata/part-00000:0+742\n",
      "10-20 14:41:00.508 172.17.0.2:54321      6000    (TID 317)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 116.0 (TID 317). 1670 bytes result sent to driver\n",
      "10-20 14:41:00.508 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 116.0 (TID 317) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:00.508 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.509 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 116 (first at ReadWrite.scala:587) finished in 0.015 s\n",
      "10-20 14:41:00.509 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.509 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 116: Stage finished\n",
      "10-20 14:41:00.510 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 96 finished: first at ReadWrite.scala:587, took 0.016996 s\n",
      "10-20 14:41:00.518 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:00.542 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at treeModels.scala:507\n",
      "10-20 14:41:00.543 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 97 (parquet at treeModels.scala:507) with 1 output partitions\n",
      "10-20 14:41:00.543 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 117 (parquet at treeModels.scala:507)\n",
      "10-20 14:41:00.543 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.543 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.544 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[327] at parquet at treeModels.scala:507), which has no missing parents\n",
      "10-20 14:41:00.549 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_197 stored as values in memory (estimated size 84.5 KiB, free 431.9 MiB)\n",
      "10-20 14:41:00.568 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 431.9 MiB)\n",
      "10-20 14:41:00.568 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_184_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.568 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_197_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.0 MiB)\n",
      "10-20 14:41:00.569 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.569 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[327] at parquet at treeModels.scala:507) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:00.569 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:00.570 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_188_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.570 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 117.0 (TID 318) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4755 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.571 172.17.0.2:54321      6000    (TID 318)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 117.0 (TID 318)\n",
      "10-20 14:41:00.571 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_195_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.573 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_190_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.574 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_180_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.577 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_193_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.579 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_183_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.582 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_192_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.584 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_181_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:00.585 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_182_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.586 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_187_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.587 172.17.0.2:54321      6000    (TID 318)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 117.0 (TID 318). 1787 bytes result sent to driver\n",
      "10-20 14:41:00.588 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 117.0 (TID 318) in 18 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:00.588 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.589 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 117 (parquet at treeModels.scala:507) finished in 0.045 s\n",
      "10-20 14:41:00.589 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.589 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished\n",
      "10-20 14:41:00.589 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 97 finished: parquet at treeModels.scala:507, took 0.047313 s\n",
      "10-20 14:41:00.590 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_185_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.599 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_194_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.600 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_186_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.603 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_191_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:00.604 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_189_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:00.605 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_196_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:00.624 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:00.624 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:00.624 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<treeID: int, metadata: string, weights: double ... 1 more fields>\n",
      "10-20 14:41:00.644 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 10.610591 ms\n",
      "10-20 14:41:00.646 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_198 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:41:00.651 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:41:00.652 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_198_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:00.652 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 198 from rdd at treeModels.scala:509\n",
      "10-20 14:41:00.653 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4198400 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:00.677 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: sortByKey at treeModels.scala:514\n",
      "10-20 14:41:00.678 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 98 (sortByKey at treeModels.scala:514) with 4 output partitions\n",
      "10-20 14:41:00.678 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 118 (sortByKey at treeModels.scala:514)\n",
      "10-20 14:41:00.678 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.678 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.678 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[336] at sortByKey at treeModels.scala:514), which has no missing parents\n",
      "10-20 14:41:00.679 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_199 stored as values in memory (estimated size 20.0 KiB, free 433.5 MiB)\n",
      "10-20 14:41:00.680 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.5 MiB)\n",
      "10-20 14:41:00.680 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_199_piece0 in memory on 95675304fa2d:39707 (size: 9.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:00.681 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.681 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 118 (MapPartitionsRDD[336] at sortByKey at treeModels.scala:514) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:00.681 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 118.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:00.681 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 118.0 (TID 319) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.681 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 118.0 (TID 320) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.682 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 118.0 (TID 321) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.682 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 118.0 (TID 322) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.682 172.17.0.2:54321      6000    (TID 319)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 118.0 (TID 319)\n",
      "10-20 14:41:00.682 172.17.0.2:54321      6000    (TID 320)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 118.0 (TID 320)\n",
      "10-20 14:41:00.682 172.17.0.2:54321      6000    (TID 322)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 118.0 (TID 322)\n",
      "10-20 14:41:00.682 172.17.0.2:54321      6000    (TID 321)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 118.0 (TID 321)\n",
      "10-20 14:41:00.726 172.17.0.2:54321      6000    (TID 319)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 8.537715 ms\n",
      "10-20 14:41:00.729 172.17.0.2:54321      6000    (TID 320)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00001-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4113, partition values: [empty row]\n",
      "10-20 14:41:00.729 172.17.0.2:54321      6000    (TID 319)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00002-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4114, partition values: [empty row]\n",
      "10-20 14:41:00.730 172.17.0.2:54321      6000    (TID 321)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00000-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4083, partition values: [empty row]\n",
      "10-20 14:41:00.734 172.17.0.2:54321      6000    (TID 322)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00003-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4077, partition values: [empty row]\n",
      "10-20 14:41:00.773 172.17.0.2:54321      6000    (TID 319)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 118.0 (TID 319). 1953 bytes result sent to driver\n",
      "10-20 14:41:00.774 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 118.0 (TID 319) in 93 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:00.776 172.17.0.2:54321      6000    (TID 320)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 118.0 (TID 320). 1953 bytes result sent to driver\n",
      "10-20 14:41:00.778 172.17.0.2:54321      6000    (TID 322)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 118.0 (TID 322). 1953 bytes result sent to driver\n",
      "10-20 14:41:00.782 172.17.0.2:54321      6000    (TID 321)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 118.0 (TID 321). 1953 bytes result sent to driver\n",
      "10-20 14:41:00.782 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 118.0 (TID 322) in 100 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:00.783 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 118.0 (TID 320) in 102 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:00.784 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 118.0 (TID 321) in 103 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:00.784 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.784 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 118 (sortByKey at treeModels.scala:514) finished in 0.106 s\n",
      "10-20 14:41:00.784 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 98 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.784 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 118: Stage finished\n",
      "10-20 14:41:00.786 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 98 finished: sortByKey at treeModels.scala:514, took 0.108424 s\n",
      "10-20 14:41:00.804 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at treeModels.scala:514\n",
      "10-20 14:41:00.804 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 334 (map at treeModels.scala:510) as input to shuffle 20\n",
      "10-20 14:41:00.805 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 99 (collect at treeModels.scala:514) with 4 output partitions\n",
      "10-20 14:41:00.805 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 120 (collect at treeModels.scala:514)\n",
      "10-20 14:41:00.805 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 119)\n",
      "10-20 14:41:00.805 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 119)\n",
      "10-20 14:41:00.805 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[334] at map at treeModels.scala:510), which has no missing parents\n",
      "10-20 14:41:00.806 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_200 stored as values in memory (estimated size 20.7 KiB, free 433.4 MiB)\n",
      "10-20 14:41:00.807 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 433.4 MiB)\n",
      "10-20 14:41:00.807 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_200_piece0 in memory on 95675304fa2d:39707 (size: 9.5 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.807 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.807 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[334] at map at treeModels.scala:510) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:00.807 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 119.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:00.808 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 119.0 (TID 323) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4995 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.808 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 119.0 (TID 324) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4995 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.809 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 119.0 (TID 325) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4995 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.809 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 119.0 (TID 326) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4995 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.809 172.17.0.2:54321      6000    (TID 324)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 119.0 (TID 324)\n",
      "10-20 14:41:00.809 172.17.0.2:54321      6000    (TID 326)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 119.0 (TID 326)\n",
      "10-20 14:41:00.809 172.17.0.2:54321      6000    (TID 325)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 119.0 (TID 325)\n",
      "10-20 14:41:00.809 172.17.0.2:54321      6000    (TID 323)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 119.0 (TID 323)\n",
      "10-20 14:41:00.815 172.17.0.2:54321      6000    (TID 326)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00003-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4077, partition values: [empty row]\n",
      "10-20 14:41:00.824 172.17.0.2:54321      6000    (TID 324)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00001-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4113, partition values: [empty row]\n",
      "10-20 14:41:00.828 172.17.0.2:54321      6000    (TID 325)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00000-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4083, partition values: [empty row]\n",
      "10-20 14:41:00.831 172.17.0.2:54321      6000    (TID 323)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00002-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4114, partition values: [empty row]\n",
      "10-20 14:41:00.840 172.17.0.2:54321      6000    (TID 325)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 119.0 (TID 325). 1906 bytes result sent to driver\n",
      "10-20 14:41:00.840 172.17.0.2:54321      6000    (TID 324)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 119.0 (TID 324). 1906 bytes result sent to driver\n",
      "10-20 14:41:00.841 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 119.0 (TID 325) in 33 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:00.842 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 119.0 (TID 324) in 34 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:00.846 172.17.0.2:54321      6000    (TID 326)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 119.0 (TID 326). 1906 bytes result sent to driver\n",
      "10-20 14:41:00.847 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 119.0 (TID 326) in 38 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:00.850 172.17.0.2:54321      6000    (TID 323)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 119.0 (TID 323). 1906 bytes result sent to driver\n",
      "10-20 14:41:00.851 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 119.0 (TID 323) in 43 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:00.851 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.852 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 119 (map at treeModels.scala:510) finished in 0.046 s\n",
      "10-20 14:41:00.852 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:41:00.852 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:41:00.852 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 120)\n",
      "10-20 14:41:00.852 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:41:00.852 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[338] at values at treeModels.scala:514), which has no missing parents\n",
      "10-20 14:41:00.877 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_201 stored as values in memory (estimated size 4.6 KiB, free 433.4 MiB)\n",
      "10-20 14:41:00.878 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 433.4 MiB)\n",
      "10-20 14:41:00.878 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_201_piece0 in memory on 95675304fa2d:39707 (size: 2.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.879 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 201 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.879 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 120 (MapPartitionsRDD[338] at values at treeModels.scala:514) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:00.879 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 120.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:00.880 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 120.0 (TID 327) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.880 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 120.0 (TID 328) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.880 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 120.0 (TID 329) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.880 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 120.0 (TID 330) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.881 172.17.0.2:54321      6000    (TID 328)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 120.0 (TID 328)\n",
      "10-20 14:41:00.881 172.17.0.2:54321      6000    (TID 329)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 120.0 (TID 329)\n",
      "10-20 14:41:00.881 172.17.0.2:54321      6000    (TID 330)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 120.0 (TID 330)\n",
      "10-20 14:41:00.882 172.17.0.2:54321      6000    (TID 327)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 120.0 (TID 327)\n",
      "10-20 14:41:00.883 172.17.0.2:54321      6000    (TID 328)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:00.883 172.17.0.2:54321      6000    (TID 328)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:00.886 172.17.0.2:54321      6000    (TID 329)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:00.886 172.17.0.2:54321      6000    (TID 329)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:00.886 172.17.0.2:54321      6000    (TID 327)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:00.886 172.17.0.2:54321      6000    (TID 327)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:00.887 172.17.0.2:54321      6000    (TID 330)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:00.888 172.17.0.2:54321      6000    (TID 330)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:00.900 172.17.0.2:54321      6000    (TID 329)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 120.0 (TID 329). 10697 bytes result sent to driver\n",
      "10-20 14:41:00.901 172.17.0.2:54321      6000    (TID 330)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 120.0 (TID 330). 10697 bytes result sent to driver\n",
      "10-20 14:41:00.902 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 120.0 (TID 329) in 22 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:00.903 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 120.0 (TID 330) in 23 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:00.905 172.17.0.2:54321      6000    (TID 327)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 120.0 (TID 327). 10697 bytes result sent to driver\n",
      "10-20 14:41:00.906 172.17.0.2:54321      6000    (TID 328)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 120.0 (TID 328). 10697 bytes result sent to driver\n",
      "10-20 14:41:00.906 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 120.0 (TID 327) in 26 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:00.907 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 120.0 (TID 328) in 27 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:00.907 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.908 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 120 (collect at treeModels.scala:514) finished in 0.032 s\n",
      "10-20 14:41:00.909 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.909 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 120: Stage finished\n",
      "10-20 14:41:00.909 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 99 finished: collect at treeModels.scala:514, took 0.105011 s\n",
      "10-20 14:41:00.932 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:00.957 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at treeModels.scala:519\n",
      "10-20 14:41:00.959 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 100 (parquet at treeModels.scala:519) with 1 output partitions\n",
      "10-20 14:41:00.959 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 121 (parquet at treeModels.scala:519)\n",
      "10-20 14:41:00.959 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:00.959 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:00.959 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[340] at parquet at treeModels.scala:519), which has no missing parents\n",
      "10-20 14:41:00.965 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_202 stored as values in memory (estimated size 84.5 KiB, free 433.3 MiB)\n",
      "10-20 14:41:00.966 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.3 MiB)\n",
      "10-20 14:41:00.967 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_202_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:00.967 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:00.967 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[340] at parquet at treeModels.scala:519) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:00.967 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 121.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:00.968 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 121.0 (TID 331) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4746 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:00.969 172.17.0.2:54321      6000    (TID 331)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 121.0 (TID 331)\n",
      "10-20 14:41:00.977 172.17.0.2:54321      6000    (TID 331)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 121.0 (TID 331). 2376 bytes result sent to driver\n",
      "10-20 14:41:00.978 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 121.0 (TID 331) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:00.978 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:00.978 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 121 (parquet at treeModels.scala:519) finished in 0.018 s\n",
      "10-20 14:41:00.978 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:00.978 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 121: Stage finished\n",
      "10-20 14:41:00.978 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 100 finished: parquet at treeModels.scala:519, took 0.020125 s\n",
      "10-20 14:41:01.048 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:01.048 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:01.048 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<treeID: int, nodeData: struct<id: int, prediction: double, impurity: double, impurityStats: array<double>, rawCount: bigint ... 7 more fields>>\n",
      "10-20 14:41:01.051 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_203 stored as values in memory (estimated size 179.3 KiB, free 433.1 MiB)\n",
      "10-20 14:41:01.070 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_199_piece0 on 95675304fa2d:39707 in memory (size: 9.0 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:01.074 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:01.075 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_203_piece0 in memory on 95675304fa2d:39707 (size: 29.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:01.076 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 203 from rdd at treeModels.scala:530\n",
      "10-20 14:41:01.077 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4203994 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:01.078 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_200_piece0 on 95675304fa2d:39707 in memory (size: 9.5 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:01.081 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_201_piece0 on 95675304fa2d:39707 in memory (size: 2.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:01.082 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_197_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:01.083 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_202_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:01.123 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: sortByKey at treeModels.scala:536\n",
      "10-20 14:41:01.124 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 346 (map at treeModels.scala:531) as input to shuffle 21\n",
      "10-20 14:41:01.124 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 101 (sortByKey at treeModels.scala:536) with 4 output partitions\n",
      "10-20 14:41:01.124 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 123 (sortByKey at treeModels.scala:536)\n",
      "10-20 14:41:01.124 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)\n",
      "10-20 14:41:01.124 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 122)\n",
      "10-20 14:41:01.125 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 122 (MapPartitionsRDD[346] at map at treeModels.scala:531), which has no missing parents\n",
      "10-20 14:41:01.126 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_204 stored as values in memory (estimated size 25.2 KiB, free 433.4 MiB)\n",
      "10-20 14:41:01.127 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 433.4 MiB)\n",
      "10-20 14:41:01.128 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_204_piece0 in memory on 95675304fa2d:39707 (size: 9.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:01.128 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:01.128 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[346] at map at treeModels.scala:531) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:01.128 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 122.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:01.129 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 122.0 (TID 332) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4986 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.130 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 122.0 (TID 333) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4986 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.130 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 122.0 (TID 334) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4986 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.130 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 122.0 (TID 335) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4986 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.131 172.17.0.2:54321      6000    (TID 332)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 122.0 (TID 332)\n",
      "10-20 14:41:01.131 172.17.0.2:54321      6000    (TID 334)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 122.0 (TID 334)\n",
      "10-20 14:41:01.131 172.17.0.2:54321      6000    (TID 335)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 122.0 (TID 335)\n",
      "10-20 14:41:01.131 172.17.0.2:54321      6000    (TID 333)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 122.0 (TID 333)\n",
      "10-20 14:41:01.149 172.17.0.2:54321      6000    (TID 332)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.277175 ms\n",
      "10-20 14:41:01.197 172.17.0.2:54321      6000    (TID 333)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 40.96732 ms\n",
      "10-20 14:41:01.201 172.17.0.2:54321      6000    (TID 335)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/data/part-00001-4743f76e-eebf-4f06-b931-35f1863f01bb-c000.snappy.parquet, range: 0-9356, partition values: [empty row]\n",
      "10-20 14:41:01.206 172.17.0.2:54321      6000    (TID 335)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 161 records.\n",
      "10-20 14:41:01.209 172.17.0.2:54321      6000    (TID 332)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/data/part-00003-4743f76e-eebf-4f06-b931-35f1863f01bb-c000.snappy.parquet, range: 0-10207, partition values: [empty row]\n",
      "10-20 14:41:01.209 172.17.0.2:54321      6000    (TID 334)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/data/part-00002-4743f76e-eebf-4f06-b931-35f1863f01bb-c000.snappy.parquet, range: 0-9551, partition values: [empty row]\n",
      "10-20 14:41:01.214 172.17.0.2:54321      6000    (TID 332)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 189 records.\n",
      "10-20 14:41:01.214 172.17.0.2:54321      6000    (TID 334)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 169 records.\n",
      "10-20 14:41:01.216 172.17.0.2:54321      6000    (TID 332)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:01.216 172.17.0.2:54321      6000    (TID 335)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:01.222 172.17.0.2:54321      6000    (TID 334)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:01.225 172.17.0.2:54321      6000    (TID 333)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/data/part-00000-4743f76e-eebf-4f06-b931-35f1863f01bb-c000.snappy.parquet, range: 0-9647, partition values: [empty row]\n",
      "10-20 14:41:01.226 172.17.0.2:54321      6000    (TID 334)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 4 ms. row count = 169\n",
      "10-20 14:41:01.231 172.17.0.2:54321      6000    (TID 335)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 4 ms. row count = 161\n",
      "10-20 14:41:01.231 172.17.0.2:54321      6000    (TID 332)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 10 ms. row count = 189\n",
      "10-20 14:41:01.234 172.17.0.2:54321      6000    (TID 333)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 173 records.\n",
      "10-20 14:41:01.245 172.17.0.2:54321      6000    (TID 333)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:01.253 172.17.0.2:54321      6000    (TID 333)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 8 ms. row count = 173\n",
      "10-20 14:41:01.272 172.17.0.2:54321      6000    (TID 335)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 122.0 (TID 335). 1624 bytes result sent to driver\n",
      "10-20 14:41:01.273 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 122.0 (TID 335) in 143 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:01.277 172.17.0.2:54321      6000    (TID 332)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 122.0 (TID 332). 1624 bytes result sent to driver\n",
      "10-20 14:41:01.278 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 122.0 (TID 332) in 149 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:01.285 172.17.0.2:54321      6000    (TID 333)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 122.0 (TID 333). 1624 bytes result sent to driver\n",
      "10-20 14:41:01.285 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 122.0 (TID 333) in 155 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:01.291 172.17.0.2:54321      6000    (TID 334)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 122.0 (TID 334). 1624 bytes result sent to driver\n",
      "10-20 14:41:01.291 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 122.0 (TID 334) in 161 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:01.291 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:01.292 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 122 (map at treeModels.scala:531) finished in 0.166 s\n",
      "10-20 14:41:01.292 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:41:01.292 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:41:01.292 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 123)\n",
      "10-20 14:41:01.292 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:41:01.292 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[350] at sortByKey at treeModels.scala:536), which has no missing parents\n",
      "10-20 14:41:01.294 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_205 stored as values in memory (estimated size 27.4 KiB, free 433.3 MiB)\n",
      "10-20 14:41:01.295 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 10.5 KiB, free 433.3 MiB)\n",
      "10-20 14:41:01.295 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_205_piece0 in memory on 95675304fa2d:39707 (size: 10.5 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:01.296 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:01.296 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 123 (MapPartitionsRDD[350] at sortByKey at treeModels.scala:536) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:01.296 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 123.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:01.297 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 123.0 (TID 336) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.298 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 123.0 (TID 337) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.298 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 123.0 (TID 338) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.299 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 123.0 (TID 339) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.299 172.17.0.2:54321      6000    (TID 339)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 123.0 (TID 339)\n",
      "10-20 14:41:01.299 172.17.0.2:54321      6000    (TID 338)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 123.0 (TID 338)\n",
      "10-20 14:41:01.303 172.17.0.2:54321      6000    (TID 337)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 123.0 (TID 337)\n",
      "10-20 14:41:01.303 172.17.0.2:54321      6000    (TID 336)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 123.0 (TID 336)\n",
      "10-20 14:41:01.305 172.17.0.2:54321      6000    (TID 339)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (11.1 KiB) non-empty blocks including 4 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.305 172.17.0.2:54321      6000    (TID 339)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:01.305 172.17.0.2:54321      6000    (TID 338)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.0 KiB) non-empty blocks including 4 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.306 172.17.0.2:54321      6000    (TID 338)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:41:01.334 172.17.0.2:54321      6000    (TID 336)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.6 KiB) non-empty blocks including 4 (10.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.334 172.17.0.2:54321      6000    (TID 336)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:01.335 172.17.0.2:54321      6000    (TID 337)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (11.4 KiB) non-empty blocks including 4 (11.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.335 172.17.0.2:54321      6000    (TID 337)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:01.349 172.17.0.2:54321      6000    (TID 336)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 123.0 (TID 336). 2015 bytes result sent to driver\n",
      "10-20 14:41:01.350 172.17.0.2:54321      6000    (TID 339)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 123.0 (TID 339). 2015 bytes result sent to driver\n",
      "10-20 14:41:01.350 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 123.0 (TID 336) in 53 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:01.351 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 123.0 (TID 339) in 52 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:01.352 172.17.0.2:54321      6000    (TID 338)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 123.0 (TID 338). 2015 bytes result sent to driver\n",
      "10-20 14:41:01.353 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 123.0 (TID 338) in 55 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:01.353 172.17.0.2:54321      6000    (TID 337)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 123.0 (TID 337). 2015 bytes result sent to driver\n",
      "10-20 14:41:01.353 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 123.0 (TID 337) in 56 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:01.354 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:01.354 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 123 (sortByKey at treeModels.scala:536) finished in 0.061 s\n",
      "10-20 14:41:01.354 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 101 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:01.354 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 123: Stage finished\n",
      "10-20 14:41:01.355 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 101 finished: sortByKey at treeModels.scala:536, took 0.231143 s\n",
      "10-20 14:41:01.362 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at treeModels.scala:536\n",
      "10-20 14:41:01.363 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 348 (map at treeModels.scala:533) as input to shuffle 22\n",
      "10-20 14:41:01.363 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 102 (collect at treeModels.scala:536) with 4 output partitions\n",
      "10-20 14:41:01.363 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 126 (collect at treeModels.scala:536)\n",
      "10-20 14:41:01.363 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)\n",
      "10-20 14:41:01.363 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 125)\n",
      "10-20 14:41:01.364 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 125 (MapPartitionsRDD[348] at map at treeModels.scala:533), which has no missing parents\n",
      "10-20 14:41:01.370 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_206 stored as values in memory (estimated size 26.5 KiB, free 433.3 MiB)\n",
      "10-20 14:41:01.371 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 433.3 MiB)\n",
      "10-20 14:41:01.372 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_206_piece0 in memory on 95675304fa2d:39707 (size: 10.3 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:01.372 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:01.373 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 125 (MapPartitionsRDD[348] at map at treeModels.scala:533) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:01.373 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 125.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:01.374 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 125.0 (TID 340) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.374 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 125.0 (TID 341) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.374 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 125.0 (TID 342) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.375 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 125.0 (TID 343) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.375 172.17.0.2:54321      6000    (TID 341)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 125.0 (TID 341)\n",
      "10-20 14:41:01.375 172.17.0.2:54321      6000    (TID 343)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 125.0 (TID 343)\n",
      "10-20 14:41:01.375 172.17.0.2:54321      6000    (TID 342)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 125.0 (TID 342)\n",
      "10-20 14:41:01.377 172.17.0.2:54321      6000    (TID 340)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 125.0 (TID 340)\n",
      "10-20 14:41:01.380 172.17.0.2:54321      6000    (TID 341)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (11.4 KiB) non-empty blocks including 4 (11.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.380 172.17.0.2:54321      6000    (TID 341)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:41:01.380 172.17.0.2:54321      6000    (TID 343)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (11.1 KiB) non-empty blocks including 4 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.380 172.17.0.2:54321      6000    (TID 342)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.0 KiB) non-empty blocks including 4 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.380 172.17.0.2:54321      6000    (TID 342)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:01.381 172.17.0.2:54321      6000    (TID 343)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:01.384 172.17.0.2:54321      6000    (TID 340)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.6 KiB) non-empty blocks including 4 (10.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.384 172.17.0.2:54321      6000    (TID 340)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:01.389 172.17.0.2:54321      6000    (TID 342)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 125.0 (TID 342). 1968 bytes result sent to driver\n",
      "10-20 14:41:01.390 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 125.0 (TID 342) in 16 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:01.393 172.17.0.2:54321      6000    (TID 343)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 125.0 (TID 343). 1968 bytes result sent to driver\n",
      "10-20 14:41:01.396 172.17.0.2:54321      6000    (TID 340)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 125.0 (TID 340). 1968 bytes result sent to driver\n",
      "10-20 14:41:01.396 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 125.0 (TID 343) in 22 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:01.398 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 125.0 (TID 340) in 24 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:01.400 172.17.0.2:54321      6000    (TID 341)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 125.0 (TID 341). 1968 bytes result sent to driver\n",
      "10-20 14:41:01.401 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 125.0 (TID 341) in 27 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:01.401 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:01.401 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 125 (map at treeModels.scala:533) finished in 0.033 s\n",
      "10-20 14:41:01.401 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:41:01.402 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:41:01.402 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 126)\n",
      "10-20 14:41:01.402 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:41:01.402 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[352] at values at treeModels.scala:536), which has no missing parents\n",
      "10-20 14:41:01.404 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_207 stored as values in memory (estimated size 4.7 KiB, free 433.3 MiB)\n",
      "10-20 14:41:01.404 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 433.3 MiB)\n",
      "10-20 14:41:01.405 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_207_piece0 in memory on 95675304fa2d:39707 (size: 2.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:01.405 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 207 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:01.406 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 126 (MapPartitionsRDD[352] at values at treeModels.scala:536) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:01.406 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 126.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:01.407 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 126.0 (TID 344) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.407 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 126.0 (TID 345) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.407 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 126.0 (TID 346) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.407 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 126.0 (TID 347) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.407 172.17.0.2:54321      6000    (TID 347)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 126.0 (TID 347)\n",
      "10-20 14:41:01.407 172.17.0.2:54321      6000    (TID 346)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 126.0 (TID 346)\n",
      "10-20 14:41:01.408 172.17.0.2:54321      6000    (TID 345)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 126.0 (TID 345)\n",
      "10-20 14:41:01.409 172.17.0.2:54321      6000    (TID 347)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.9 KiB) non-empty blocks including 4 (10.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.409 172.17.0.2:54321      6000    (TID 347)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:01.409 172.17.0.2:54321      6000    (TID 345)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (9.8 KiB) non-empty blocks including 4 (9.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.410 172.17.0.2:54321      6000    (TID 345)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:01.412 172.17.0.2:54321      6000    (TID 347)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 126.0 (TID 347). 18698 bytes result sent to driver\n",
      "10-20 14:41:01.412 172.17.0.2:54321      6000    (TID 345)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 126.0 (TID 345). 16238 bytes result sent to driver\n",
      "10-20 14:41:01.413 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 126.0 (TID 347) in 6 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:01.415 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 126.0 (TID 345) in 8 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:01.419 172.17.0.2:54321      6000    (TID 346)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.2 KiB) non-empty blocks including 4 (10.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.419 172.17.0.2:54321      6000    (TID 346)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:01.422 172.17.0.2:54321      6000    (TID 346)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 126.0 (TID 346). 17088 bytes result sent to driver\n",
      "10-20 14:41:01.423 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 126.0 (TID 346) in 16 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:01.427 172.17.0.2:54321      6000    (TID 344)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 126.0 (TID 344)\n",
      "10-20 14:41:01.429 172.17.0.2:54321      6000    (TID 344)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.0 KiB) non-empty blocks including 4 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:01.429 172.17.0.2:54321      6000    (TID 344)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:01.435 172.17.0.2:54321      6000    (TID 344)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 126.0 (TID 344). 17283 bytes result sent to driver\n",
      "10-20 14:41:01.436 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 126.0 (TID 344) in 29 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:01.437 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:01.437 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 126 (collect at treeModels.scala:536) finished in 0.034 s\n",
      "10-20 14:41:01.437 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:01.437 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished\n",
      "10-20 14:41:01.437 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 102 finished: collect at treeModels.scala:536, took 0.075032 s\n",
      "10-20 14:41:01.454 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [8d8b3edb] training finished\n",
      "10-20 14:41:01.462 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [c953c7be] training finished\n",
      "10-20 14:41:01.821 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:01.821 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:01.821 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<fnlwgt: double, age: double, capital_gain: double, capital_loss: double, hours_per_week: double ... 3 more fields>\n",
      "10-20 14:41:01.832 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.38705 ms\n",
      "10-20 14:41:01.834 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_208 stored as values in memory (estimated size 177.8 KiB, free 433.1 MiB)\n",
      "10-20 14:41:01.859 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_204_piece0 on 95675304fa2d:39707 in memory (size: 9.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:01.862 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_203_piece0 on 95675304fa2d:39707 in memory (size: 29.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:01.863 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 28.7 KiB, free 433.3 MiB)\n",
      "10-20 14:41:01.864 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_198_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:01.864 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_208_piece0 in memory on 95675304fa2d:39707 (size: 28.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:01.865 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 208 from head at Imputer.scala:258\n",
      "10-20 14:41:01.866 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_206_piece0 on 95675304fa2d:39707 in memory (size: 10.3 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:01.866 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:01.867 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_205_piece0 on 95675304fa2d:39707 in memory (size: 10.5 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:01.869 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_207_piece0 on 95675304fa2d:39707 in memory (size: 2.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:01.872 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 14:41:01.873 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 103 (head at Imputer.scala:258) with 1 output partitions\n",
      "10-20 14:41:01.873 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 127 (head at Imputer.scala:258)\n",
      "10-20 14:41:01.873 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:01.873 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:01.873 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[356] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 14:41:01.880 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_209 stored as values in memory (estimated size 14.0 KiB, free 433.6 MiB)\n",
      "10-20 14:41:01.880 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 433.6 MiB)\n",
      "10-20 14:41:01.881 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_209_piece0 in memory on 95675304fa2d:39707 (size: 5.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:01.881 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:01.881 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[356] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:01.881 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 127.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:01.882 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 127.0 (TID 348) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:01.882 172.17.0.2:54321      6000    (TID 348)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 127.0 (TID 348)\n",
      "10-20 14:41:01.887 172.17.0.2:54321      6000    (TID 348)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/data/part-00000-a97a8010-555e-44ad-bd78-6ec0db1bb5ae-c000.snappy.parquet, range: 0-1479, partition values: [empty row]\n",
      "10-20 14:41:01.895 172.17.0.2:54321      6000    (TID 348)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 127.0 (TID 348). 1700 bytes result sent to driver\n",
      "10-20 14:41:01.896 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 127.0 (TID 348) in 14 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:01.897 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:01.897 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 127 (head at Imputer.scala:258) finished in 0.022 s\n",
      "10-20 14:41:01.897 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:01.897 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 127: Stage finished\n",
      "10-20 14:41:01.897 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 103 finished: head at Imputer.scala:258, took 0.024883 s\n",
      "10-20 14:41:02.109 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_68_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "Metric name: areaUnderROC\n",
      "10-20 14:41:02.957 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:02.957 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:02.958 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 12 more fields>\n",
      "10-20 14:41:03.029 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_208_piece0 on 95675304fa2d:39707 in memory (size: 28.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:03.031 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_209_piece0 on 95675304fa2d:39707 in memory (size: 5.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:03.041 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 59.761046 ms\n",
      "10-20 14:41:03.043 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_210 stored as values in memory (estimated size 176.1 KiB, free 433.8 MiB)\n",
      "10-20 14:41:03.059 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.8 MiB)\n",
      "10-20 14:41:03.059 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_210_piece0 in memory on 95675304fa2d:39707 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:03.060 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 210 from rdd at BinaryClassificationEvaluator.scala:133\n",
      "10-20 14:41:03.060 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:03.116 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: count at BinaryClassificationMetrics.scala:197\n",
      "10-20 14:41:03.117 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 364 (map at BinaryClassificationMetrics.scala:48) as input to shuffle 24\n",
      "10-20 14:41:03.118 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 365 (combineByKey at BinaryClassificationMetrics.scala:188) as input to shuffle 23\n",
      "10-20 14:41:03.118 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 104 (count at BinaryClassificationMetrics.scala:197) with 1 output partitions\n",
      "10-20 14:41:03.118 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 130 (count at BinaryClassificationMetrics.scala:197)\n",
      "10-20 14:41:03.118 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 129)\n",
      "10-20 14:41:03.118 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 129)\n",
      "10-20 14:41:03.119 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 128 (MapPartitionsRDD[364] at map at BinaryClassificationMetrics.scala:48), which has no missing parents\n",
      "10-20 14:41:03.131 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_211 stored as values in memory (estimated size 242.7 KiB, free 433.6 MiB)\n",
      "10-20 14:41:03.133 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 85.7 KiB, free 433.5 MiB)\n",
      "10-20 14:41:03.133 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_211_piece0 in memory on 95675304fa2d:39707 (size: 85.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:03.134 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:03.134 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 128 (MapPartitionsRDD[364] at map at BinaryClassificationMetrics.scala:48) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:03.134 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 128.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:03.136 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 128.0 (TID 349) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4855 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:03.136 172.17.0.2:54321      6000    (TID 349)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 128.0 (TID 349)\n",
      "10-20 14:41:03.189 172.17.0.2:54321      6000    (TID 349)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.452456 ms\n",
      "10-20 14:41:03.190 172.17.0.2:54321      6000    (TID 349)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-train.csv, range: 0-3974305, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 128:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:41:03.962 172.17.0.2:54321      6000    (TID 349)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 128.0 (TID 349). 2133 bytes result sent to driver\n",
      "10-20 14:41:03.963 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 128.0 (TID 349) in 827 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:03.963 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:03.964 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 128 (map at BinaryClassificationMetrics.scala:48) finished in 0.844 s\n",
      "10-20 14:41:03.964 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:41:03.964 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:41:03.964 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 129, ResultStage 130)\n",
      "10-20 14:41:03.964 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:41:03.964 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 129 (ShuffledRDD[365] at combineByKey at BinaryClassificationMetrics.scala:188), which has no missing parents\n",
      "10-20 14:41:03.967 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_212 stored as values in memory (estimated size 5.1 KiB, free 433.5 MiB)\n",
      "10-20 14:41:03.985 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.5 MiB)\n",
      "10-20 14:41:03.985 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_212_piece0 in memory on 95675304fa2d:39707 (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:03.986 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:03.986 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 129 (ShuffledRDD[365] at combineByKey at BinaryClassificationMetrics.scala:188) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:03.986 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:03.987 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 129.0 (TID 350) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:03.995 172.17.0.2:54321      6000    (TID 350)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 129.0 (TID 350)\n",
      "10-20 14:41:03.999 172.17.0.2:54321      6000    (TID 350)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:03.999 172.17.0.2:54321      6000    (TID 350)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:04.020 172.17.0.2:54321      6000    (TID 350)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 129.0 (TID 350). 1462 bytes result sent to driver\n",
      "10-20 14:41:04.021 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 129.0 (TID 350) in 34 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:04.021 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:04.021 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 129 (combineByKey at BinaryClassificationMetrics.scala:188) finished in 0.056 s\n",
      "10-20 14:41:04.021 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:41:04.021 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:41:04.021 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 130)\n",
      "10-20 14:41:04.021 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:41:04.022 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 130 (ShuffledRDD[366] at sortByKey at BinaryClassificationMetrics.scala:189), which has no missing parents\n",
      "10-20 14:41:04.022 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_213 stored as values in memory (estimated size 3.9 KiB, free 433.5 MiB)\n",
      "10-20 14:41:04.023 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 433.5 MiB)\n",
      "10-20 14:41:04.023 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_213_piece0 in memory on 95675304fa2d:39707 (size: 2.3 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:04.024 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 213 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:04.024 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (ShuffledRDD[366] at sortByKey at BinaryClassificationMetrics.scala:189) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:04.024 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:04.025 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 130.0 (TID 351) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:04.026 172.17.0.2:54321      6000    (TID 351)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 130.0 (TID 351)\n",
      "10-20 14:41:04.028 172.17.0.2:54321      6000    (TID 351)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:04.028 172.17.0.2:54321      6000    (TID 351)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:04.054 172.17.0.2:54321      6000    (TID 351)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 130.0 (TID 351). 1305 bytes result sent to driver\n",
      "10-20 14:41:04.055 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 130.0 (TID 351) in 30 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:04.055 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:04.055 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 130 (count at BinaryClassificationMetrics.scala:197) finished in 0.033 s\n",
      "10-20 14:41:04.055 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 104 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:04.056 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 130: Stage finished\n",
      "10-20 14:41:04.056 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 104 finished: count at BinaryClassificationMetrics.scala:197, took 0.939223 s\n",
      "10-20 14:41:04.057 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Curve is too small (1755) for 1000 bins to be useful\n",
      "10-20 14:41:04.065 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:237\n",
      "10-20 14:41:04.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 105 (collect at BinaryClassificationMetrics.scala:237) with 1 output partitions\n",
      "10-20 14:41:04.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 133 (collect at BinaryClassificationMetrics.scala:237)\n",
      "10-20 14:41:04.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 132)\n",
      "10-20 14:41:04.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:04.068 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[368] at mapPartitions at BinaryClassificationMetrics.scala:237), which has no missing parents\n",
      "10-20 14:41:04.069 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_214 stored as values in memory (estimated size 5.3 KiB, free 433.5 MiB)\n",
      "10-20 14:41:04.070 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 433.5 MiB)\n",
      "10-20 14:41:04.070 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_214_piece0 in memory on 95675304fa2d:39707 (size: 2.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:04.071 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:04.071 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[368] at mapPartitions at BinaryClassificationMetrics.scala:237) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:04.071 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:04.072 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 133.0 (TID 352) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:04.072 172.17.0.2:54321      6000    (TID 352)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 133.0 (TID 352)\n",
      "10-20 14:41:04.076 172.17.0.2:54321      6000    (TID 352)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:04.076 172.17.0.2:54321      6000    (TID 352)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:04.102 172.17.0.2:54321      6000    (TID 352)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 133.0 (TID 352). 1448 bytes result sent to driver\n",
      "10-20 14:41:04.103 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 133.0 (TID 352) in 31 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:04.103 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:04.104 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 133 (collect at BinaryClassificationMetrics.scala:237) finished in 0.036 s\n",
      "10-20 14:41:04.104 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:04.104 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished\n",
      "10-20 14:41:04.105 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 105 finished: collect at BinaryClassificationMetrics.scala:237, took 0.039899 s\n",
      "10-20 14:41:04.107 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.mllib.evaluation.BinaryClassificationMetrics: Total counts: {numPos: 1552.0, numNeg: 4933.0}\n",
      "10-20 14:41:04.121 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at AreaUnderCurve.scala:44\n",
      "10-20 14:41:04.122 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 106 (collect at AreaUnderCurve.scala:44) with 1 output partitions\n",
      "10-20 14:41:04.122 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 136 (collect at AreaUnderCurve.scala:44)\n",
      "10-20 14:41:04.122 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 135)\n",
      "10-20 14:41:04.123 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:04.124 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[373] at mapPartitions at AreaUnderCurve.scala:44), which has no missing parents\n",
      "10-20 14:41:04.126 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_215 stored as values in memory (estimated size 6.9 KiB, free 433.5 MiB)\n",
      "10-20 14:41:04.126 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 433.4 MiB)\n",
      "10-20 14:41:04.127 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_215_piece0 in memory on 95675304fa2d:39707 (size: 3.3 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:04.127 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:04.127 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[373] at mapPartitions at AreaUnderCurve.scala:44) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:04.128 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:04.129 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 136.0 (TID 353) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:04.129 172.17.0.2:54321      6000    (TID 353)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 136.0 (TID 353)\n",
      "10-20 14:41:04.134 172.17.0.2:54321      6000    (TID 353)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:04.134 172.17.0.2:54321      6000    (TID 353)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:04.170 172.17.0.2:54321      6000    (TID 353)  INFO org.apache.spark.storage.memory.MemoryStore: Block rdd_369_0 stored as values in memory (estimated size 139.7 KiB, free 433.3 MiB)\n",
      "10-20 14:41:04.171 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added rdd_369_0 in memory on 95675304fa2d:39707 (size: 139.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:04.209 172.17.0.2:54321      6000    (TID 353)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 136.0 (TID 353). 1524 bytes result sent to driver\n",
      "10-20 14:41:04.210 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 136.0 (TID 353) in 82 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:04.210 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:04.210 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 136 (collect at AreaUnderCurve.scala:44) finished in 0.085 s\n",
      "10-20 14:41:04.210 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:04.210 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished\n",
      "10-20 14:41:04.211 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 106 finished: collect at AreaUnderCurve.scala:44, took 0.089600 s\n",
      "10-20 14:41:04.212 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.rdd.MapPartitionsRDD: Removing RDD 369 from persistence list\n",
      "Metric value: 0.8775613190986046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:41:04.213 172.17.0.2:54321      6000   ad-pool-15  INFO org.apache.spark.storage.BlockManager: Removing RDD 369\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import (\n",
    "    PipelineModel\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "pipeline_model = PipelineModel.load(model_path)\n",
    "train_df_pred = pipeline_model.transform(train_df)\n",
    "val_df_pred = pipeline_model.transform(val_df)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print(f'Metric name: {evaluator.getMetricName()}')\n",
    "print(f'Metric value: {evaluator.evaluate(val_df_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d13b86d-a514-46a4-85e7-8ebb294b1907",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "383adb92-37cc-4f0c-ab17-6046655bb29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:                                     score\n",
      "name                                     \n",
      "workclass_vec_ Private           0.000400\n",
      "workclass_vec_ Self-emp-not-inc  0.000021\n",
      "workclass_vec_ Local-gov         0.000000\n",
      "workclass_vec_NA                 0.000000\n",
      "workclass_vec_ State-gov         0.000000\n",
      "...                                   ...\n",
      "fnlwgt_IMPUTED                   0.000876\n",
      "age_IMPUTED                      0.013504\n",
      "capital_gain_IMPUTED             0.172791\n",
      "capital_loss_IMPUTED             0.032275\n",
      "hours_per_week_IMPUTED           0.031168\n",
      "\n",
      "[106 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fitted_model = pipeline_model.stages[-1]\n",
    "binary_features = train_df_pred.schema['features'].metadata['ml_attr']['attrs']['binary']\n",
    "numerical_features = train_df_pred.schema['features'].metadata['ml_attr']['attrs']['numeric']\n",
    "features_map = pd.DataFrame(binary_features + numerical_features)\n",
    "feature_importances = fitted_model.featureImportances\n",
    "features_map['score'] = features_map.idx.apply(lambda x: feature_importances[x])\n",
    "features_map = features_map.set_index('name')['score']\n",
    "features_map = pd.DataFrame(features_map)\n",
    "print(f'Feature importance: {features_map}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13502a6-0691-4aae-8c29-52b80a5e6ca1",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27c08dc4-f8f9-40ca-89e6-4b7e8f935c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:41:37.758 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:37.845 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_216 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:41:37.862 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_211_piece0 on 95675304fa2d:39707 in memory (size: 85.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:37.863 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.6 MiB)\n",
      "10-20 14:41:37.864 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_216_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:37.866 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_213_piece0 on 95675304fa2d:39707 in memory (size: 2.3 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:37.871 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_212_piece0 on 95675304fa2d:39707 in memory (size: 2.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:37.872 172.17.0.2:54321      6000   ad-pool-29  INFO org.apache.spark.storage.BlockManager: Removing RDD 369\n",
      "10-20 14:41:37.874 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_215_piece0 on 95675304fa2d:39707 in memory (size: 3.3 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:37.874 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 216 from textFile at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:41:37.875 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_210_piece0 on 95675304fa2d:39707 in memory (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:37.876 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_214_piece0 on 95675304fa2d:39707 in memory (size: 2.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:37.928 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: runJob at PythonRDD.scala:166\n",
      "10-20 14:41:37.931 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 107 (runJob at PythonRDD.scala:166) with 1 output partitions\n",
      "10-20 14:41:37.931 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 137 (runJob at PythonRDD.scala:166)\n",
      "10-20 14:41:37.931 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:37.931 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:37.931 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 137 (PythonRDD[376] at RDD at PythonRDD.scala:53), which has no missing parents\n",
      "10-20 14:41:37.933 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_217 stored as values in memory (estimated size 6.7 KiB, free 433.8 MiB)\n",
      "10-20 14:41:37.934 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 433.8 MiB)\n",
      "10-20 14:41:37.934 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_217_piece0 in memory on 95675304fa2d:39707 (size: 4.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:37.936 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 217 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:37.936 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 137 (PythonRDD[376] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:37.936 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 137.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:37.937 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 137.0 (TID 354) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4540 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:37.938 172.17.0.2:54321      6000    (TID 354)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 137.0 (TID 354)\n",
      "10-20 14:41:37.941 172.17.0.2:54321      6000    (TID 354)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/metadata/part-00000:0+734\n",
      "10-20 14:41:37.959 172.17.0.2:54321      6000    (TID 354)  INFO org.apache.spark.api.python.PythonRunner: Times: total = 17, boot = 6, init = 11, finish = 0\n",
      "10-20 14:41:37.965 172.17.0.2:54321      6000    (TID 354)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 137.0 (TID 354). 2137 bytes result sent to driver\n",
      "10-20 14:41:37.967 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 137.0 (TID 354) in 30 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:37.967 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:37.970 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 137 (runJob at PythonRDD.scala:166) finished in 0.038 s\n",
      "10-20 14:41:37.970 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:37.970 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished\n",
      "10-20 14:41:37.970 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 107 finished: runJob at PythonRDD.scala:166, took 0.041655 s\n",
      "10-20 14:41:37.989 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_218 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 14:41:38.002 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.6 MiB)\n",
      "10-20 14:41:38.004 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_218_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.005 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 218 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.086 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.087 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 108 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.087 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 138 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.087 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.087 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.087 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 138 (outputs/income_rf_spark/metadata MapPartitionsRDD[378] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.088 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_219 stored as values in memory (estimated size 4.1 KiB, free 433.6 MiB)\n",
      "10-20 14:41:38.089 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:41:38.089 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_219_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.090 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 219 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.090 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 138 (outputs/income_rf_spark/metadata MapPartitionsRDD[378] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.090 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 138.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.091 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 138.0 (TID 355) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4540 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.091 172.17.0.2:54321      6000    (TID 355)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 138.0 (TID 355)\n",
      "10-20 14:41:38.094 172.17.0.2:54321      6000    (TID 355)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/metadata/part-00000:0+734\n",
      "10-20 14:41:38.096 172.17.0.2:54321      6000    (TID 355)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 138.0 (TID 355). 1662 bytes result sent to driver\n",
      "10-20 14:41:38.097 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 138.0 (TID 355) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.097 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.098 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 138 (first at ReadWrite.scala:587) finished in 0.010 s\n",
      "10-20 14:41:38.098 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.098 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 138: Stage finished\n",
      "10-20 14:41:38.098 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 108 finished: first at ReadWrite.scala:587, took 0.011977 s\n",
      "10-20 14:41:38.101 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_220 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 14:41:38.107 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.4 MiB)\n",
      "10-20 14:41:38.108 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_220_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.108 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 220 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.128 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.129 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 109 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.129 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 139 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.129 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.129 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.129 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 139 (outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata MapPartitionsRDD[380] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.130 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_221 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:41:38.131 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:41:38.131 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_221_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.132 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.132 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata MapPartitionsRDD[380] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.132 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 139.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.133 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 139.0 (TID 356) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4571 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.133 172.17.0.2:54321      6000    (TID 356)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 139.0 (TID 356)\n",
      "10-20 14:41:38.135 172.17.0.2:54321      6000    (TID 356)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata/part-00000:0+479\n",
      "10-20 14:41:38.136 172.17.0.2:54321      6000    (TID 356)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 139.0 (TID 356). 1407 bytes result sent to driver\n",
      "10-20 14:41:38.137 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 139.0 (TID 356) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.137 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.138 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 139 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:41:38.138 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.138 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 139: Stage finished\n",
      "10-20 14:41:38.139 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 109 finished: first at ReadWrite.scala:587, took 0.010037 s\n",
      "10-20 14:41:38.140 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_222 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 14:41:38.145 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.2 MiB)\n",
      "10-20 14:41:38.146 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_222_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.146 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 222 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.165 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.166 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 110 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.166 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 140 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.166 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.166 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.166 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 140 (outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata MapPartitionsRDD[382] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.168 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_223 stored as values in memory (estimated size 4.2 KiB, free 433.2 MiB)\n",
      "10-20 14:41:38.169 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.2 MiB)\n",
      "10-20 14:41:38.169 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_223_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.171 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 223 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.171 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 140 (outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata MapPartitionsRDD[382] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.171 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 140.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.172 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 140.0 (TID 357) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4571 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.172 172.17.0.2:54321      6000    (TID 357)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 140.0 (TID 357)\n",
      "10-20 14:41:38.174 172.17.0.2:54321      6000    (TID 357)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/metadata/part-00000:0+479\n",
      "10-20 14:41:38.175 172.17.0.2:54321      6000    (TID 357)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 140.0 (TID 357). 1407 bytes result sent to driver\n",
      "10-20 14:41:38.176 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 140.0 (TID 357) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.176 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.177 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 140 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:41:38.177 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 110 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.177 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 140: Stage finished\n",
      "10-20 14:41:38.178 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 110 finished: first at ReadWrite.scala:587, took 0.012594 s\n",
      "10-20 14:41:38.220 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:38.239 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at Imputer.scala:320\n",
      "10-20 14:41:38.240 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 111 (parquet at Imputer.scala:320) with 1 output partitions\n",
      "10-20 14:41:38.240 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 141 (parquet at Imputer.scala:320)\n",
      "10-20 14:41:38.240 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.240 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.240 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[384] at parquet at Imputer.scala:320), which has no missing parents\n",
      "10-20 14:41:38.245 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_224 stored as values in memory (estimated size 84.5 KiB, free 433.1 MiB)\n",
      "10-20 14:41:38.246 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.1 MiB)\n",
      "10-20 14:41:38.246 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_224_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.246 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.247 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[384] at parquet at Imputer.scala:320) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.247 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 141.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.248 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 141.0 (TID 358) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4731 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.248 172.17.0.2:54321      6000    (TID 358)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 141.0 (TID 358)\n",
      "10-20 14:41:38.254 172.17.0.2:54321      6000    (TID 358)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 141.0 (TID 358). 1774 bytes result sent to driver\n",
      "10-20 14:41:38.255 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 141.0 (TID 358) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.255 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.256 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 141 (parquet at Imputer.scala:320) finished in 0.016 s\n",
      "10-20 14:41:38.256 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 111 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.256 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 141: Stage finished\n",
      "10-20 14:41:38.256 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 111 finished: parquet at Imputer.scala:320, took 0.016482 s\n",
      "10-20 14:41:38.264 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_225 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:41:38.270 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:41:38.271 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_225_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.271 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 225 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.289 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.289 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 112 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.289 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 142 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.289 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.289 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.290 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 142 (outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata MapPartitionsRDD[386] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.291 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_226 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:41:38.291 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:41:38.292 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_226_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.292 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.293 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 142 (outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata MapPartitionsRDD[386] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.293 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 142.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.293 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 142.0 (TID 359) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.294 172.17.0.2:54321      6000    (TID 359)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 142.0 (TID 359)\n",
      "10-20 14:41:38.295 172.17.0.2:54321      6000    (TID 359)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata/part-00000:0+357\n",
      "10-20 14:41:38.296 172.17.0.2:54321      6000    (TID 359)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 142.0 (TID 359). 1242 bytes result sent to driver\n",
      "10-20 14:41:38.297 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 142.0 (TID 359) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.297 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.297 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 142 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:38.298 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.298 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 142: Stage finished\n",
      "10-20 14:41:38.298 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 112 finished: first at ReadWrite.scala:587, took 0.009662 s\n",
      "10-20 14:41:38.300 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_227 stored as values in memory (estimated size 176.1 KiB, free 432.7 MiB)\n",
      "10-20 14:41:38.304 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:41:38.305 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_227_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.305 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 227 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.321 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.321 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 113 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.322 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 143 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.322 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.322 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.322 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 143 (outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata MapPartitionsRDD[388] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.322 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_228 stored as values in memory (estimated size 4.2 KiB, free 432.7 MiB)\n",
      "10-20 14:41:38.323 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.7 MiB)\n",
      "10-20 14:41:38.324 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_228_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.325 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.325 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 143 (outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata MapPartitionsRDD[388] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.325 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 143.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.326 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 143.0 (TID 360) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.327 172.17.0.2:54321      6000    (TID 360)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 143.0 (TID 360)\n",
      "10-20 14:41:38.328 172.17.0.2:54321      6000    (TID 360)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/metadata/part-00000:0+357\n",
      "10-20 14:41:38.329 172.17.0.2:54321      6000    (TID 360)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 143.0 (TID 360). 1242 bytes result sent to driver\n",
      "10-20 14:41:38.330 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 143.0 (TID 360) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.330 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.330 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 143 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:41:38.330 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 113 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.330 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 143: Stage finished\n",
      "10-20 14:41:38.331 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 113 finished: first at ReadWrite.scala:587, took 0.009750 s\n",
      "10-20 14:41:38.335 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:38.353 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:41:38.353 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 114 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:41:38.353 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 144 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:41:38.353 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.353 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.353 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[390] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:41:38.357 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_229 stored as values in memory (estimated size 84.5 KiB, free 432.6 MiB)\n",
      "10-20 14:41:38.370 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.7 MiB)\n",
      "10-20 14:41:38.370 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_225_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.370 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_229_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.371 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 229 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.371 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[390] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.371 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 144.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.371 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_224_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.372 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 144.0 (TID 361) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.372 172.17.0.2:54321      6000    (TID 361)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 144.0 (TID 361)\n",
      "10-20 14:41:38.379 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_226_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.380 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_227_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.381 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_228_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.382 172.17.0.2:54321      6000    (TID 361)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 144.0 (TID 361). 1709 bytes result sent to driver\n",
      "10-20 14:41:38.383 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 144.0 (TID 361) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.383 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.383 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 144 (parquet at StringIndexer.scala:523) finished in 0.029 s\n",
      "10-20 14:41:38.383 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 114 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.383 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 144: Stage finished\n",
      "10-20 14:41:38.383 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 114 finished: parquet at StringIndexer.scala:523, took 0.030384 s\n",
      "10-20 14:41:38.384 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_221_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.384 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_217_piece0 on 95675304fa2d:39707 in memory (size: 4.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.385 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_220_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.391 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:38.391 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:38.392 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:41:38.392 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_223_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.393 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_219_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.393 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_218_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.394 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_222_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.397 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_230 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:41:38.402 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:41:38.402 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_230_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.403 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 230 from head at StringIndexer.scala:524\n",
      "10-20 14:41:38.403 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:38.407 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:41:38.407 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 115 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:41:38.407 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 145 (head at StringIndexer.scala:524)\n",
      "10-20 14:41:38.407 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.407 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.407 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[393] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:41:38.409 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_231 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:41:38.410 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:41:38.410 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_231_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.410 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 231 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.410 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[393] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.410 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 145.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.411 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 145.0 (TID 362) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.412 172.17.0.2:54321      6000    (TID 362)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 145.0 (TID 362)\n",
      "10-20 14:41:38.414 172.17.0.2:54321      6000    (TID 362)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/01_StringIndexer_da764b56dc42/data/part-00000-d14895eb-d962-484e-b0f1-6314a71ecfea-c000.snappy.parquet, range: 0-750, partition values: [empty row]\n",
      "10-20 14:41:38.416 172.17.0.2:54321      6000    (TID 362)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:38.417 172.17.0.2:54321      6000    (TID 362)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:38.417 172.17.0.2:54321      6000    (TID 362)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:38.419 172.17.0.2:54321      6000    (TID 362)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 145.0 (TID 362). 1804 bytes result sent to driver\n",
      "10-20 14:41:38.419 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 145.0 (TID 362) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.419 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.419 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 145 (head at StringIndexer.scala:524) finished in 0.011 s\n",
      "10-20 14:41:38.419 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.420 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 145: Stage finished\n",
      "10-20 14:41:38.420 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 115 finished: head at StringIndexer.scala:524, took 0.012986 s\n",
      "10-20 14:41:38.424 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_232 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:41:38.428 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:41:38.429 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_232_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.430 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 232 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.445 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.445 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 116 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.445 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 146 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.445 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.445 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.446 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 146 (outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata MapPartitionsRDD[395] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.446 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_233 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:41:38.447 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:41:38.447 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_233_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.448 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.448 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 146 (outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata MapPartitionsRDD[395] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.448 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 146.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.449 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 146.0 (TID 363) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.449 172.17.0.2:54321      6000    (TID 363)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 146.0 (TID 363)\n",
      "10-20 14:41:38.450 172.17.0.2:54321      6000    (TID 363)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata/part-00000:0+357\n",
      "10-20 14:41:38.452 172.17.0.2:54321      6000    (TID 363)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 146.0 (TID 363). 1285 bytes result sent to driver\n",
      "10-20 14:41:38.452 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 146.0 (TID 363) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.453 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.454 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 146 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:38.454 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 116 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.454 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 146: Stage finished\n",
      "10-20 14:41:38.454 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 116 finished: first at ReadWrite.scala:587, took 0.008934 s\n",
      "10-20 14:41:38.455 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_234 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:41:38.460 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:38.460 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_234_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.461 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 234 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.476 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.476 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 117 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.476 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 147 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.476 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.476 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.477 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 147 (outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata MapPartitionsRDD[397] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.477 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_235 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:38.478 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:41:38.478 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_235_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.478 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.478 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata MapPartitionsRDD[397] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.478 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 147.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.479 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 147.0 (TID 364) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.479 172.17.0.2:54321      6000    (TID 364)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 147.0 (TID 364)\n",
      "10-20 14:41:38.481 172.17.0.2:54321      6000    (TID 364)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/metadata/part-00000:0+357\n",
      "10-20 14:41:38.482 172.17.0.2:54321      6000    (TID 364)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 147.0 (TID 364). 1285 bytes result sent to driver\n",
      "10-20 14:41:38.483 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 147.0 (TID 364) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.483 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.484 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 147 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:41:38.484 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 117 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.484 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 147: Stage finished\n",
      "10-20 14:41:38.484 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 117 finished: first at ReadWrite.scala:587, took 0.008355 s\n",
      "10-20 14:41:38.489 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:38.506 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:41:38.507 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 118 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:41:38.507 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 148 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:41:38.507 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.507 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.507 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[399] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:41:38.512 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_236 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:41:38.513 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.0 MiB)\n",
      "10-20 14:41:38.513 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_236_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.514 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.514 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[399] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.514 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 148.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.515 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 148.0 (TID 365) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.515 172.17.0.2:54321      6000    (TID 365)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 148.0 (TID 365)\n",
      "10-20 14:41:38.548 172.17.0.2:54321      6000    (TID 365)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 148.0 (TID 365). 1709 bytes result sent to driver\n",
      "10-20 14:41:38.549 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 148.0 (TID 365) in 35 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.549 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.549 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 148 (parquet at StringIndexer.scala:523) finished in 0.042 s\n",
      "10-20 14:41:38.549 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 118 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.549 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 148: Stage finished\n",
      "10-20 14:41:38.549 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 118 finished: parquet at StringIndexer.scala:523, took 0.043103 s\n",
      "10-20 14:41:38.556 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:38.556 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:38.556 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:41:38.562 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_237 stored as values in memory (estimated size 177.5 KiB, free 432.8 MiB)\n",
      "10-20 14:41:38.567 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.8 MiB)\n",
      "10-20 14:41:38.568 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_237_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.568 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 237 from head at StringIndexer.scala:524\n",
      "10-20 14:41:38.569 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:38.572 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:41:38.573 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 119 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:41:38.573 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 149 (head at StringIndexer.scala:524)\n",
      "10-20 14:41:38.573 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.573 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.573 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[402] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:41:38.576 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_238 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:41:38.577 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:41:38.577 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_238_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 238 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[402] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 149.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.578 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 149.0 (TID 366) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.579 172.17.0.2:54321      6000    (TID 366)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 149.0 (TID 366)\n",
      "10-20 14:41:38.581 172.17.0.2:54321      6000    (TID 366)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/02_StringIndexer_713fbf312582/data/part-00000-be9cdc38-257f-4bf0-93c8-c37b6939d3b6-c000.snappy.parquet, range: 0-813, partition values: [empty row]\n",
      "10-20 14:41:38.583 172.17.0.2:54321      6000    (TID 366)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:38.585 172.17.0.2:54321      6000    (TID 366)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:38.585 172.17.0.2:54321      6000    (TID 366)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:38.587 172.17.0.2:54321      6000    (TID 366)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 149.0 (TID 366). 1888 bytes result sent to driver\n",
      "10-20 14:41:38.588 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 149.0 (TID 366) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.588 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.588 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 149 (head at StringIndexer.scala:524) finished in 0.015 s\n",
      "10-20 14:41:38.588 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 119 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.588 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 149: Stage finished\n",
      "10-20 14:41:38.589 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 119 finished: head at StringIndexer.scala:524, took 0.016454 s\n",
      "10-20 14:41:38.594 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_239 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:41:38.599 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:38.599 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_239_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.600 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 239 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.618 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.618 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 120 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.618 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 150 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.618 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.618 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.618 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 150 (outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata MapPartitionsRDD[404] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.619 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_240 stored as values in memory (estimated size 4.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:38.620 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.5 MiB)\n",
      "10-20 14:41:38.620 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_240_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.620 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 240 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.620 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 150 (outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata MapPartitionsRDD[404] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.620 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 150.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.621 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 150.0 (TID 367) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.621 172.17.0.2:54321      6000    (TID 367)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 150.0 (TID 367)\n",
      "10-20 14:41:38.622 172.17.0.2:54321      6000    (TID 367)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata/part-00000:0+367\n",
      "10-20 14:41:38.623 172.17.0.2:54321      6000    (TID 367)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 150.0 (TID 367). 1252 bytes result sent to driver\n",
      "10-20 14:41:38.624 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 150.0 (TID 367) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.624 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.625 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 150 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:41:38.625 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 120 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.625 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 150: Stage finished\n",
      "10-20 14:41:38.626 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 120 finished: first at ReadWrite.scala:587, took 0.008065 s\n",
      "10-20 14:41:38.628 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_241 stored as values in memory (estimated size 176.1 KiB, free 432.4 MiB)\n",
      "10-20 14:41:38.632 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.3 MiB)\n",
      "10-20 14:41:38.633 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_241_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.633 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 241 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.652 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.653 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 121 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.653 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 151 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.653 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.653 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.653 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 151 (outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata MapPartitionsRDD[406] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.654 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_242 stored as values in memory (estimated size 4.2 KiB, free 432.3 MiB)\n",
      "10-20 14:41:38.655 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.3 MiB)\n",
      "10-20 14:41:38.655 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_242_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.655 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 242 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.655 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 151 (outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata MapPartitionsRDD[406] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.655 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 151.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.656 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 151.0 (TID 368) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.657 172.17.0.2:54321      6000    (TID 368)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 151.0 (TID 368)\n",
      "10-20 14:41:38.658 172.17.0.2:54321      6000    (TID 368)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/metadata/part-00000:0+367\n",
      "10-20 14:41:38.661 172.17.0.2:54321      6000    (TID 368)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 151.0 (TID 368). 1252 bytes result sent to driver\n",
      "10-20 14:41:38.662 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 151.0 (TID 368) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.663 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.663 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 151 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:41:38.663 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.663 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 151: Stage finished\n",
      "10-20 14:41:38.663 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 121 finished: first at ReadWrite.scala:587, took 0.010615 s\n",
      "10-20 14:41:38.677 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:38.693 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:41:38.694 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 122 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:41:38.694 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 152 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:41:38.694 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.694 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.694 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[408] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:41:38.698 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_243 stored as values in memory (estimated size 84.5 KiB, free 432.2 MiB)\n",
      "10-20 14:41:38.726 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.2 MiB)\n",
      "10-20 14:41:38.726 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_243_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.0 MiB)\n",
      "10-20 14:41:38.726 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_237_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.727 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 243 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.727 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[408] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.727 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 152.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.728 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 152.0 (TID 369) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.728 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_242_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.729 172.17.0.2:54321      6000    (TID 369)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 152.0 (TID 369)\n",
      "10-20 14:41:38.730 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_233_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.732 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_230_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.733 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_231_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.734 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_236_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.735 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_238_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.736 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_235_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.737 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_234_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.737 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_232_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.738 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_229_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.739 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_240_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.740 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_241_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.741 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_239_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.755 172.17.0.2:54321      6000    (TID 369)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 152.0 (TID 369). 1709 bytes result sent to driver\n",
      "10-20 14:41:38.756 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 152.0 (TID 369) in 28 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.756 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.756 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 152 (parquet at StringIndexer.scala:523) finished in 0.062 s\n",
      "10-20 14:41:38.756 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 122 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.756 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 152: Stage finished\n",
      "10-20 14:41:38.756 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 122 finished: parquet at StringIndexer.scala:523, took 0.062907 s\n",
      "10-20 14:41:38.763 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:38.763 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:38.763 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:41:38.767 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_244 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:41:38.772 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:41:38.772 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_244_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.773 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 244 from head at StringIndexer.scala:524\n",
      "10-20 14:41:38.773 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:38.777 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:41:38.777 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 123 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:41:38.777 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 153 (head at StringIndexer.scala:524)\n",
      "10-20 14:41:38.777 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.777 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.777 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 153 (MapPartitionsRDD[411] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:41:38.779 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_245 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:41:38.780 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:41:38.780 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_245_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:38.781 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 245 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.781 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 153 (MapPartitionsRDD[411] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.781 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 153.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.782 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 153.0 (TID 370) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.783 172.17.0.2:54321      6000    (TID 370)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 153.0 (TID 370)\n",
      "10-20 14:41:38.786 172.17.0.2:54321      6000    (TID 370)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/03_StringIndexer_24131ba85ffa/data/part-00000-c883591b-5ee3-46b0-a91b-2b149f54261f-c000.snappy.parquet, range: 0-743, partition values: [empty row]\n",
      "10-20 14:41:38.789 172.17.0.2:54321      6000    (TID 370)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:38.790 172.17.0.2:54321      6000    (TID 370)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:38.791 172.17.0.2:54321      6000    (TID 370)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:41:38.792 172.17.0.2:54321      6000    (TID 370)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 153.0 (TID 370). 1786 bytes result sent to driver\n",
      "10-20 14:41:38.793 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 153.0 (TID 370) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.793 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.793 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 153 (head at StringIndexer.scala:524) finished in 0.015 s\n",
      "10-20 14:41:38.794 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 123 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.794 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 153: Stage finished\n",
      "10-20 14:41:38.794 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 123 finished: head at StringIndexer.scala:524, took 0.017331 s\n",
      "10-20 14:41:38.799 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_246 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:41:38.804 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:41:38.804 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_246_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.805 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 246 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.821 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.822 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 124 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.822 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 154 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.822 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.822 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.822 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 154 (outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata MapPartitionsRDD[413] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.823 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_247 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:41:38.823 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:41:38.824 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_247_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.824 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 247 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.824 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata MapPartitionsRDD[413] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.824 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 154.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.825 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 154.0 (TID 371) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.826 172.17.0.2:54321      6000    (TID 371)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 154.0 (TID 371)\n",
      "10-20 14:41:38.827 172.17.0.2:54321      6000    (TID 371)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata/part-00000:0+359\n",
      "10-20 14:41:38.828 172.17.0.2:54321      6000    (TID 371)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 154.0 (TID 371). 1244 bytes result sent to driver\n",
      "10-20 14:41:38.829 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 154.0 (TID 371) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.829 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.829 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 154 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:38.830 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 124 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.830 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 154: Stage finished\n",
      "10-20 14:41:38.830 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 124 finished: first at ReadWrite.scala:587, took 0.008322 s\n",
      "10-20 14:41:38.832 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_248 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:41:38.836 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:38.836 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_248_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.837 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 248 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.854 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.854 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 125 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.854 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 155 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.854 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.855 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.855 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 155 (outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata MapPartitionsRDD[415] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.855 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_249 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:38.856 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:41:38.857 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_249_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.857 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 249 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.857 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 155 (outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata MapPartitionsRDD[415] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.857 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 155.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.858 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 155.0 (TID 372) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.859 172.17.0.2:54321      6000    (TID 372)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 155.0 (TID 372)\n",
      "10-20 14:41:38.860 172.17.0.2:54321      6000    (TID 372)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/metadata/part-00000:0+359\n",
      "10-20 14:41:38.861 172.17.0.2:54321      6000    (TID 372)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 155.0 (TID 372). 1244 bytes result sent to driver\n",
      "10-20 14:41:38.861 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 155.0 (TID 372) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.861 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.862 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 155 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:38.862 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 125 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.862 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 155: Stage finished\n",
      "10-20 14:41:38.863 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 125 finished: first at ReadWrite.scala:587, took 0.008656 s\n",
      "10-20 14:41:38.868 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:38.885 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:41:38.885 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 126 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:41:38.885 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 156 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:41:38.885 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.885 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.886 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 156 (MapPartitionsRDD[417] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:41:38.890 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_250 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:41:38.892 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.0 MiB)\n",
      "10-20 14:41:38.892 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_250_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:38.893 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 250 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.894 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 156 (MapPartitionsRDD[417] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.894 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 156.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.894 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 156.0 (TID 373) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.895 172.17.0.2:54321      6000    (TID 373)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 156.0 (TID 373)\n",
      "10-20 14:41:38.900 172.17.0.2:54321      6000    (TID 373)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 156.0 (TID 373). 1709 bytes result sent to driver\n",
      "10-20 14:41:38.900 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 156.0 (TID 373) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.900 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.901 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 156 (parquet at StringIndexer.scala:523) finished in 0.015 s\n",
      "10-20 14:41:38.901 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 126 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.901 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 156: Stage finished\n",
      "10-20 14:41:38.902 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 126 finished: parquet at StringIndexer.scala:523, took 0.016938 s\n",
      "10-20 14:41:38.908 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:38.908 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:38.908 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:41:38.934 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_251 stored as values in memory (estimated size 177.5 KiB, free 432.8 MiB)\n",
      "10-20 14:41:38.940 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.8 MiB)\n",
      "10-20 14:41:38.941 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_251_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.942 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 251 from head at StringIndexer.scala:524\n",
      "10-20 14:41:38.942 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:38.946 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:41:38.947 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 127 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:41:38.947 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 157 (head at StringIndexer.scala:524)\n",
      "10-20 14:41:38.947 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.947 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.947 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[420] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:41:38.949 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_252 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:41:38.950 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:41:38.950 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_252_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.951 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 252 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.951 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 157 (MapPartitionsRDD[420] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.951 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 157.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.951 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 157.0 (TID 374) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.952 172.17.0.2:54321      6000    (TID 374)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 157.0 (TID 374)\n",
      "10-20 14:41:38.954 172.17.0.2:54321      6000    (TID 374)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/04_StringIndexer_1e6b076f0cec/data/part-00000-3d2f0af4-4c70-4d74-8ebf-19433b143995-c000.snappy.parquet, range: 0-873, partition values: [empty row]\n",
      "10-20 14:41:38.956 172.17.0.2:54321      6000    (TID 374)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:38.957 172.17.0.2:54321      6000    (TID 374)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:38.957 172.17.0.2:54321      6000    (TID 374)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:38.958 172.17.0.2:54321      6000    (TID 374)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 157.0 (TID 374). 1969 bytes result sent to driver\n",
      "10-20 14:41:38.958 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 157.0 (TID 374) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.959 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.959 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 157 (head at StringIndexer.scala:524) finished in 0.011 s\n",
      "10-20 14:41:38.959 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 127 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.959 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 157: Stage finished\n",
      "10-20 14:41:38.960 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 127 finished: head at StringIndexer.scala:524, took 0.013157 s\n",
      "10-20 14:41:38.963 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_253 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:41:38.967 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:38.967 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_253_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.970 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 253 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:38.986 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:38.986 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 128 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:38.986 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 158 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:38.986 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:38.987 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:38.987 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 158 (outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata MapPartitionsRDD[422] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:38.988 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_254 stored as values in memory (estimated size 4.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:38.989 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.5 MiB)\n",
      "10-20 14:41:38.990 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_254_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:38.991 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 254 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:38.991 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata MapPartitionsRDD[422] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:38.991 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 158.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:38.991 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 158.0 (TID 375) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:38.992 172.17.0.2:54321      6000    (TID 375)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 158.0 (TID 375)\n",
      "10-20 14:41:38.994 172.17.0.2:54321      6000    (TID 375)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata/part-00000:0+363\n",
      "10-20 14:41:38.995 172.17.0.2:54321      6000    (TID 375)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 158.0 (TID 375). 1291 bytes result sent to driver\n",
      "10-20 14:41:38.995 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 158.0 (TID 375) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:38.995 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:38.996 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 158 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:41:38.996 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 128 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:38.996 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 158: Stage finished\n",
      "10-20 14:41:38.996 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 128 finished: first at ReadWrite.scala:587, took 0.010177 s\n",
      "10-20 14:41:39.000 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_255 stored as values in memory (estimated size 176.1 KiB, free 432.4 MiB)\n",
      "10-20 14:41:39.007 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_255_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.3 MiB)\n",
      "10-20 14:41:39.007 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_255_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.008 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 255 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:39.036 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:39.036 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 129 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:39.036 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 159 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:39.036 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.036 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.037 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 159 (outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata MapPartitionsRDD[424] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:39.037 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_256 stored as values in memory (estimated size 4.2 KiB, free 432.3 MiB)\n",
      "10-20 14:41:39.038 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_256_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.3 MiB)\n",
      "10-20 14:41:39.038 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_256_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.038 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 256 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.038 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 159 (outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata MapPartitionsRDD[424] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.038 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 159.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.039 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 159.0 (TID 376) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.039 172.17.0.2:54321      6000    (TID 376)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 159.0 (TID 376)\n",
      "10-20 14:41:39.041 172.17.0.2:54321      6000    (TID 376)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/metadata/part-00000:0+363\n",
      "10-20 14:41:39.042 172.17.0.2:54321      6000    (TID 376)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 159.0 (TID 376). 1248 bytes result sent to driver\n",
      "10-20 14:41:39.042 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 159.0 (TID 376) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.042 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.043 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 159 (first at ReadWrite.scala:587) finished in 0.005 s\n",
      "10-20 14:41:39.043 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 129 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.043 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 159: Stage finished\n",
      "10-20 14:41:39.043 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 129 finished: first at ReadWrite.scala:587, took 0.007469 s\n",
      "10-20 14:41:39.048 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:39.066 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:41:39.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 130 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:41:39.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 160 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:41:39.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 160 (MapPartitionsRDD[426] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:41:39.070 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_257 stored as values in memory (estimated size 84.5 KiB, free 432.2 MiB)\n",
      "10-20 14:41:39.090 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_257_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.2 MiB)\n",
      "10-20 14:41:39.091 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_257_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.0 MiB)\n",
      "10-20 14:41:39.091 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_251_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.092 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_247_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.093 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_254_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.094 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_249_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.095 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 257 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.095 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 160 (MapPartitionsRDD[426] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.095 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 160.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.095 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_245_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.096 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 160.0 (TID 377) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.096 172.17.0.2:54321      6000    (TID 377)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 160.0 (TID 377)\n",
      "10-20 14:41:39.097 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_243_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.101 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_256_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.104 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_246_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.105 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_244_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.107 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_253_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.108 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_252_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.110 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_250_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.112 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_255_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.113 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_248_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.120 172.17.0.2:54321      6000    (TID 377)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 160.0 (TID 377). 1709 bytes result sent to driver\n",
      "10-20 14:41:39.121 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 160.0 (TID 377) in 26 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.121 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.121 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 160 (parquet at StringIndexer.scala:523) finished in 0.055 s\n",
      "10-20 14:41:39.121 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 130 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.121 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 160: Stage finished\n",
      "10-20 14:41:39.121 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 130 finished: parquet at StringIndexer.scala:523, took 0.055583 s\n",
      "10-20 14:41:39.127 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:39.127 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:39.127 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:41:39.132 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_258 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.136 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_258_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.137 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_258_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.137 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 258 from head at StringIndexer.scala:524\n",
      "10-20 14:41:39.138 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:39.141 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:41:39.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 131 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:41:39.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 161 (head at StringIndexer.scala:524)\n",
      "10-20 14:41:39.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.142 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[429] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:41:39.144 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_259 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_259_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.145 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_259_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 259 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.146 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (MapPartitionsRDD[429] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.146 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 161.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.146 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 161.0 (TID 378) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.147 172.17.0.2:54321      6000    (TID 378)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 161.0 (TID 378)\n",
      "10-20 14:41:39.149 172.17.0.2:54321      6000    (TID 378)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/05_StringIndexer_7ad58bda48b0/data/part-00000-5967b13e-7ecf-4cf2-9ef8-b8ca3676c1ca-c000.snappy.parquet, range: 0-712, partition values: [empty row]\n",
      "10-20 14:41:39.151 172.17.0.2:54321      6000    (TID 378)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:39.152 172.17.0.2:54321      6000    (TID 378)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:39.152 172.17.0.2:54321      6000    (TID 378)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:39.154 172.17.0.2:54321      6000    (TID 378)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 161.0 (TID 378). 1758 bytes result sent to driver\n",
      "10-20 14:41:39.154 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 161.0 (TID 378) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.154 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.155 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 161 (head at StringIndexer.scala:524) finished in 0.013 s\n",
      "10-20 14:41:39.155 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 131 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.155 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 161: Stage finished\n",
      "10-20 14:41:39.155 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 131 finished: head at StringIndexer.scala:524, took 0.013322 s\n",
      "10-20 14:41:39.158 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_260 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.163 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_260_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.163 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_260_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.164 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 260 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:39.180 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:39.180 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 132 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:39.180 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 162 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:39.180 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.180 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.181 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 162 (outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata MapPartitionsRDD[431] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:39.181 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_261 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.182 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_261_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.182 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_261_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.182 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 261 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.183 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 162 (outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata MapPartitionsRDD[431] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.183 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 162.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.183 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 162.0 (TID 379) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.184 172.17.0.2:54321      6000    (TID 379)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 162.0 (TID 379)\n",
      "10-20 14:41:39.185 172.17.0.2:54321      6000    (TID 379)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata/part-00000:0+347\n",
      "10-20 14:41:39.186 172.17.0.2:54321      6000    (TID 379)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 162.0 (TID 379). 1232 bytes result sent to driver\n",
      "10-20 14:41:39.186 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 162.0 (TID 379) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.187 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.187 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 162 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:41:39.187 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 132 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.187 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 162: Stage finished\n",
      "10-20 14:41:39.187 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 132 finished: first at ReadWrite.scala:587, took 0.007271 s\n",
      "10-20 14:41:39.189 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_262 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.194 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_262_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.194 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_262_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.195 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 262 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:39.216 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:39.216 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 133 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:39.216 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 163 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:39.216 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.216 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.217 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 163 (outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata MapPartitionsRDD[433] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:39.219 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_263 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.220 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_263_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.220 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_263_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.221 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 263 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.221 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 163 (outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata MapPartitionsRDD[433] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.221 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 163.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.222 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 163.0 (TID 380) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.223 172.17.0.2:54321      6000    (TID 380)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 163.0 (TID 380)\n",
      "10-20 14:41:39.224 172.17.0.2:54321      6000    (TID 380)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/metadata/part-00000:0+347\n",
      "10-20 14:41:39.226 172.17.0.2:54321      6000    (TID 380)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 163.0 (TID 380). 1275 bytes result sent to driver\n",
      "10-20 14:41:39.226 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 163.0 (TID 380) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.226 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.227 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 163 (first at ReadWrite.scala:587) finished in 0.010 s\n",
      "10-20 14:41:39.227 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 133 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.227 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 163: Stage finished\n",
      "10-20 14:41:39.227 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 133 finished: first at ReadWrite.scala:587, took 0.010948 s\n",
      "10-20 14:41:39.232 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:39.251 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:41:39.251 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 134 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:41:39.251 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 164 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:41:39.251 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.251 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.251 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 164 (MapPartitionsRDD[435] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:41:39.256 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_264 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:41:39.256 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_264_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.0 MiB)\n",
      "10-20 14:41:39.257 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_264_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.257 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 264 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.257 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 164 (MapPartitionsRDD[435] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.258 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 164.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.258 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 164.0 (TID 381) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.258 172.17.0.2:54321      6000    (TID 381)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 164.0 (TID 381)\n",
      "10-20 14:41:39.265 172.17.0.2:54321      6000    (TID 381)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 164.0 (TID 381). 1709 bytes result sent to driver\n",
      "10-20 14:41:39.289 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 164.0 (TID 381) in 31 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.289 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.290 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 164 (parquet at StringIndexer.scala:523) finished in 0.039 s\n",
      "10-20 14:41:39.290 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 134 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.290 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 164: Stage finished\n",
      "10-20 14:41:39.290 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 134 finished: parquet at StringIndexer.scala:523, took 0.039344 s\n",
      "10-20 14:41:39.298 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:39.299 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:39.299 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:41:39.305 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_265 stored as values in memory (estimated size 177.5 KiB, free 432.8 MiB)\n",
      "10-20 14:41:39.311 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_265_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.8 MiB)\n",
      "10-20 14:41:39.311 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_265_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.312 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 265 from head at StringIndexer.scala:524\n",
      "10-20 14:41:39.313 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:39.316 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:41:39.317 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 135 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:41:39.317 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 165 (head at StringIndexer.scala:524)\n",
      "10-20 14:41:39.317 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.317 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.317 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 165 (MapPartitionsRDD[438] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:41:39.318 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_266 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:41:39.319 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_266_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:41:39.319 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_266_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.319 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 266 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.320 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 165 (MapPartitionsRDD[438] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.320 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 165.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.320 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 165.0 (TID 382) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.320 172.17.0.2:54321      6000    (TID 382)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 165.0 (TID 382)\n",
      "10-20 14:41:39.323 172.17.0.2:54321      6000    (TID 382)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/06_StringIndexer_50f1bdbc0726/data/part-00000-1f0502b8-35e5-40b2-bf46-70559e28e4de-c000.snappy.parquet, range: 0-725, partition values: [empty row]\n",
      "10-20 14:41:39.325 172.17.0.2:54321      6000    (TID 382)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:39.326 172.17.0.2:54321      6000    (TID 382)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:39.327 172.17.0.2:54321      6000    (TID 382)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:41:39.328 172.17.0.2:54321      6000    (TID 382)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 165.0 (TID 382). 1735 bytes result sent to driver\n",
      "10-20 14:41:39.328 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 165.0 (TID 382) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.328 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.329 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 165 (head at StringIndexer.scala:524) finished in 0.012 s\n",
      "10-20 14:41:39.329 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 135 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.329 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 165: Stage finished\n",
      "10-20 14:41:39.329 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 135 finished: head at StringIndexer.scala:524, took 0.013026 s\n",
      "10-20 14:41:39.333 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_267 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:41:39.339 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_267_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:39.340 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_267_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.340 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 267 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:39.359 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:39.359 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 136 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:39.359 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 166 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:39.359 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.359 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.359 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 166 (outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata MapPartitionsRDD[440] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:39.360 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_268 stored as values in memory (estimated size 4.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:39.361 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_268_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.5 MiB)\n",
      "10-20 14:41:39.362 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_268_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.362 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 268 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.362 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 166 (outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata MapPartitionsRDD[440] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.362 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 166.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.363 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 166.0 (TID 383) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.363 172.17.0.2:54321      6000    (TID 383)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 166.0 (TID 383)\n",
      "10-20 14:41:39.365 172.17.0.2:54321      6000    (TID 383)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata/part-00000:0+345\n",
      "10-20 14:41:39.366 172.17.0.2:54321      6000    (TID 383)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 166.0 (TID 383). 1273 bytes result sent to driver\n",
      "10-20 14:41:39.366 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 166.0 (TID 383) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.366 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.367 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 166 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:41:39.367 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 136 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.367 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 166: Stage finished\n",
      "10-20 14:41:39.368 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 136 finished: first at ReadWrite.scala:587, took 0.008843 s\n",
      "10-20 14:41:39.369 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_269 stored as values in memory (estimated size 176.1 KiB, free 432.4 MiB)\n",
      "10-20 14:41:39.374 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_269_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.3 MiB)\n",
      "10-20 14:41:39.375 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_269_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.376 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 269 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:39.393 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:39.394 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 137 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:39.394 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 167 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:39.394 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.394 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.394 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 167 (outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata MapPartitionsRDD[442] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:39.395 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_270 stored as values in memory (estimated size 4.2 KiB, free 432.3 MiB)\n",
      "10-20 14:41:39.396 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_270_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.3 MiB)\n",
      "10-20 14:41:39.396 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_270_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.397 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 270 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.397 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 167 (outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata MapPartitionsRDD[442] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.397 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 167.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.398 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 167.0 (TID 384) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.398 172.17.0.2:54321      6000    (TID 384)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 167.0 (TID 384)\n",
      "10-20 14:41:39.400 172.17.0.2:54321      6000    (TID 384)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/metadata/part-00000:0+345\n",
      "10-20 14:41:39.401 172.17.0.2:54321      6000    (TID 384)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 167.0 (TID 384). 1273 bytes result sent to driver\n",
      "10-20 14:41:39.402 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 167.0 (TID 384) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.402 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.403 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 167 (first at ReadWrite.scala:587) finished in 0.009 s\n",
      "10-20 14:41:39.403 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 137 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.403 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 167: Stage finished\n",
      "10-20 14:41:39.404 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 137 finished: first at ReadWrite.scala:587, took 0.011009 s\n",
      "10-20 14:41:39.410 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:39.436 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:41:39.439 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 138 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:41:39.439 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 168 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:41:39.439 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.440 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.440 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 168 (MapPartitionsRDD[444] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:41:39.447 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_271 stored as values in memory (estimated size 84.5 KiB, free 432.2 MiB)\n",
      "10-20 14:41:39.472 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_271_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.2 MiB)\n",
      "10-20 14:41:39.473 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_271_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.0 MiB)\n",
      "10-20 14:41:39.475 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_269_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 271 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 168 (MapPartitionsRDD[444] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 168.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.476 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 168.0 (TID 385) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.476 172.17.0.2:54321      6000    (TID 385)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 168.0 (TID 385)\n",
      "10-20 14:41:39.481 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_257_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.482 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_265_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.483 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_264_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.484 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_262_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.485 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_263_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.487 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_260_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.488 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_267_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.488 172.17.0.2:54321      6000    (TID 385)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 168.0 (TID 385). 1709 bytes result sent to driver\n",
      "10-20 14:41:39.489 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 168.0 (TID 385) in 13 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.489 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.490 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_268_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.490 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 168 (parquet at StringIndexer.scala:523) finished in 0.050 s\n",
      "10-20 14:41:39.490 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 138 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.490 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 168: Stage finished\n",
      "10-20 14:41:39.490 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 138 finished: parquet at StringIndexer.scala:523, took 0.054536 s\n",
      "10-20 14:41:39.491 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_258_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.492 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_270_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.494 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_261_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.495 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_266_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.496 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_259_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.499 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:39.500 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:39.500 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:41:39.506 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_272 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.512 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_272_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.512 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_272_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.514 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 272 from head at StringIndexer.scala:524\n",
      "10-20 14:41:39.515 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:39.519 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:41:39.519 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 139 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:41:39.520 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 169 (head at StringIndexer.scala:524)\n",
      "10-20 14:41:39.520 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.520 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.520 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 169 (MapPartitionsRDD[447] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:41:39.522 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_273 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.523 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_273_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.523 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_273_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.524 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 273 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.524 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 169 (MapPartitionsRDD[447] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.524 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 169.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.525 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 169.0 (TID 386) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.526 172.17.0.2:54321      6000    (TID 386)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 169.0 (TID 386)\n",
      "10-20 14:41:39.529 172.17.0.2:54321      6000    (TID 386)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/07_StringIndexer_1edcea527209/data/part-00000-2dd328c5-8e60-4092-ba23-2d656e8d740d-c000.snappy.parquet, range: 0-648, partition values: [empty row]\n",
      "10-20 14:41:39.531 172.17.0.2:54321      6000    (TID 386)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:39.532 172.17.0.2:54321      6000    (TID 386)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:39.533 172.17.0.2:54321      6000    (TID 386)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:39.533 172.17.0.2:54321      6000    (TID 386)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 169.0 (TID 386). 1670 bytes result sent to driver\n",
      "10-20 14:41:39.534 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 169.0 (TID 386) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.534 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.535 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 169 (head at StringIndexer.scala:524) finished in 0.014 s\n",
      "10-20 14:41:39.535 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 139 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.535 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 169: Stage finished\n",
      "10-20 14:41:39.535 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 139 finished: head at StringIndexer.scala:524, took 0.015996 s\n",
      "10-20 14:41:39.538 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_274 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.543 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_274_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.543 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_274_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.544 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 274 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:39.560 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:39.561 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 140 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:39.561 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 170 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:39.561 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.561 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.561 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 170 (outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata MapPartitionsRDD[449] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:39.562 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_275 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.562 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_275_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.562 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_275_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.563 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 275 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.563 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 170 (outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata MapPartitionsRDD[449] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.563 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 170.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.564 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 170.0 (TID 387) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.564 172.17.0.2:54321      6000    (TID 387)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 170.0 (TID 387)\n",
      "10-20 14:41:39.566 172.17.0.2:54321      6000    (TID 387)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata/part-00000:0+367\n",
      "10-20 14:41:39.567 172.17.0.2:54321      6000    (TID 387)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 170.0 (TID 387). 1295 bytes result sent to driver\n",
      "10-20 14:41:39.568 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 170.0 (TID 387) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.568 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.569 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 170 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:41:39.569 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 140 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.569 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 170: Stage finished\n",
      "10-20 14:41:39.570 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 140 finished: first at ReadWrite.scala:587, took 0.009767 s\n",
      "10-20 14:41:39.572 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_276 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.576 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_276_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.577 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_276_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.577 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 276 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:39.593 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:39.593 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 141 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:39.593 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 171 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:39.593 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.593 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.594 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 171 (outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata MapPartitionsRDD[451] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:39.596 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_277 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.597 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_277_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.598 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_277_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.598 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 277 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.599 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 171 (outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata MapPartitionsRDD[451] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.599 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 171.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.599 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 171.0 (TID 388) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.600 172.17.0.2:54321      6000    (TID 388)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 171.0 (TID 388)\n",
      "10-20 14:41:39.602 172.17.0.2:54321      6000    (TID 388)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/metadata/part-00000:0+367\n",
      "10-20 14:41:39.604 172.17.0.2:54321      6000    (TID 388)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 171.0 (TID 388). 1295 bytes result sent to driver\n",
      "10-20 14:41:39.605 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 171.0 (TID 388) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.605 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.606 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 171 (first at ReadWrite.scala:587) finished in 0.011 s\n",
      "10-20 14:41:39.606 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 141 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.606 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 171: Stage finished\n",
      "10-20 14:41:39.606 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 141 finished: first at ReadWrite.scala:587, took 0.013239 s\n",
      "10-20 14:41:39.614 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:39.634 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at StringIndexer.scala:523\n",
      "10-20 14:41:39.634 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 142 (parquet at StringIndexer.scala:523) with 1 output partitions\n",
      "10-20 14:41:39.634 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 172 (parquet at StringIndexer.scala:523)\n",
      "10-20 14:41:39.634 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.634 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.635 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 172 (MapPartitionsRDD[453] at parquet at StringIndexer.scala:523), which has no missing parents\n",
      "10-20 14:41:39.640 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_278 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:41:39.641 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_278_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.0 MiB)\n",
      "10-20 14:41:39.641 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_278_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.641 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 278 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.642 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 172 (MapPartitionsRDD[453] at parquet at StringIndexer.scala:523) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.642 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 172.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.643 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 172.0 (TID 389) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.644 172.17.0.2:54321      6000    (TID 389)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 172.0 (TID 389)\n",
      "10-20 14:41:39.654 172.17.0.2:54321      6000    (TID 389)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 172.0 (TID 389). 1709 bytes result sent to driver\n",
      "10-20 14:41:39.655 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 172.0 (TID 389) in 12 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.655 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.655 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 172 (parquet at StringIndexer.scala:523) finished in 0.020 s\n",
      "10-20 14:41:39.656 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 142 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.656 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 172: Stage finished\n",
      "10-20 14:41:39.656 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 142 finished: parquet at StringIndexer.scala:523, took 0.022446 s\n",
      "10-20 14:41:39.663 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:39.664 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:39.664 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<labelsArray: array<array<string>>>\n",
      "10-20 14:41:39.669 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_279 stored as values in memory (estimated size 177.5 KiB, free 432.8 MiB)\n",
      "10-20 14:41:39.695 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_279_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.8 MiB)\n",
      "10-20 14:41:39.695 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_279_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.696 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 279 from head at StringIndexer.scala:524\n",
      "10-20 14:41:39.697 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:39.701 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at StringIndexer.scala:524\n",
      "10-20 14:41:39.702 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 143 (head at StringIndexer.scala:524) with 1 output partitions\n",
      "10-20 14:41:39.702 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 173 (head at StringIndexer.scala:524)\n",
      "10-20 14:41:39.702 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.702 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.702 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 173 (MapPartitionsRDD[456] at head at StringIndexer.scala:524), which has no missing parents\n",
      "10-20 14:41:39.704 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_280 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:41:39.705 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_280_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:41:39.705 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_280_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.706 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 280 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.706 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 173 (MapPartitionsRDD[456] at head at StringIndexer.scala:524) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.706 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 173.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.707 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 173.0 (TID 390) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.707 172.17.0.2:54321      6000    (TID 390)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 173.0 (TID 390)\n",
      "10-20 14:41:39.710 172.17.0.2:54321      6000    (TID 390)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/08_StringIndexer_c13d2f2607e8/data/part-00000-28ad6a8a-320b-413b-8c55-09b9f2ef9bf3-c000.snappy.parquet, range: 0-1080, partition values: [empty row]\n",
      "10-20 14:41:39.712 172.17.0.2:54321      6000    (TID 390)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:39.713 172.17.0.2:54321      6000    (TID 390)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:39.713 172.17.0.2:54321      6000    (TID 390)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:39.714 172.17.0.2:54321      6000    (TID 390)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 173.0 (TID 390). 2291 bytes result sent to driver\n",
      "10-20 14:41:39.715 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 173.0 (TID 390) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.715 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.715 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 173 (head at StringIndexer.scala:524) finished in 0.012 s\n",
      "10-20 14:41:39.715 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 143 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.715 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 173: Stage finished\n",
      "10-20 14:41:39.716 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 143 finished: head at StringIndexer.scala:524, took 0.014666 s\n",
      "10-20 14:41:39.719 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_281 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:41:39.726 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_281_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:39.726 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_281_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.727 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 281 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:39.750 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:39.758 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 144 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:39.758 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 174 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:39.758 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.758 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.759 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 174 (outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata MapPartitionsRDD[458] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:39.760 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_282 stored as values in memory (estimated size 4.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:39.760 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_282_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.5 MiB)\n",
      "10-20 14:41:39.761 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_282_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.762 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 282 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.762 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 174 (outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata MapPartitionsRDD[458] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.762 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 174.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.763 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 174.0 (TID 391) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.765 172.17.0.2:54321      6000    (TID 391)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 174.0 (TID 391)\n",
      "10-20 14:41:39.772 172.17.0.2:54321      6000    (TID 391)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata/part-00000:0+326\n",
      "10-20 14:41:39.773 172.17.0.2:54321      6000    (TID 391)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 174.0 (TID 391). 1254 bytes result sent to driver\n",
      "10-20 14:41:39.774 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 174.0 (TID 391) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.774 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.774 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 174 (first at ReadWrite.scala:587) finished in 0.015 s\n",
      "10-20 14:41:39.774 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 144 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.774 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 174: Stage finished\n",
      "10-20 14:41:39.774 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 144 finished: first at ReadWrite.scala:587, took 0.023787 s\n",
      "10-20 14:41:39.776 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_283 stored as values in memory (estimated size 176.1 KiB, free 432.4 MiB)\n",
      "10-20 14:41:39.781 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_283_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.3 MiB)\n",
      "10-20 14:41:39.781 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_283_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.782 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 283 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:39.806 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:39.807 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 145 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:39.807 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 175 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:39.807 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.807 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.807 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 175 (outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata MapPartitionsRDD[460] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:39.808 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_284 stored as values in memory (estimated size 4.2 KiB, free 432.3 MiB)\n",
      "10-20 14:41:39.808 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_284_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.3 MiB)\n",
      "10-20 14:41:39.808 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_284_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.809 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 284 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.809 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata MapPartitionsRDD[460] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.809 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 175.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.810 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 175.0 (TID 392) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.810 172.17.0.2:54321      6000    (TID 392)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 175.0 (TID 392)\n",
      "10-20 14:41:39.812 172.17.0.2:54321      6000    (TID 392)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/metadata/part-00000:0+326\n",
      "10-20 14:41:39.813 172.17.0.2:54321      6000    (TID 392)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 175.0 (TID 392). 1254 bytes result sent to driver\n",
      "10-20 14:41:39.815 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 175.0 (TID 392) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.815 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.815 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 175 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:41:39.816 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 145 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.816 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 175: Stage finished\n",
      "10-20 14:41:39.817 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 145 finished: first at ReadWrite.scala:587, took 0.010099 s\n",
      "10-20 14:41:39.822 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:39.838 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:41:39.839 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 146 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:41:39.839 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 176 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:41:39.839 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.839 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.839 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 176 (MapPartitionsRDD[462] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:41:39.844 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_285 stored as values in memory (estimated size 84.5 KiB, free 432.2 MiB)\n",
      "10-20 14:41:39.863 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_285_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.2 MiB)\n",
      "10-20 14:41:39.863 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_285_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.0 MiB)\n",
      "10-20 14:41:39.864 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 285 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.864 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 176 (MapPartitionsRDD[462] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.864 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 176.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.864 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_278_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.865 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_284_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.865 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 176.0 (TID 393) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.865 172.17.0.2:54321      6000    (TID 393)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 176.0 (TID 393)\n",
      "10-20 14:41:39.866 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_280_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.867 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_283_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.867 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_277_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.868 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_272_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:39.871 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_271_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.873 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_282_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.875 172.17.0.2:54321      6000    (TID 393)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 176.0 (TID 393). 1705 bytes result sent to driver\n",
      "10-20 14:41:39.876 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 176.0 (TID 393) in 11 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.876 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.876 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 176 (parquet at OneHotEncoder.scala:418) finished in 0.037 s\n",
      "10-20 14:41:39.877 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 146 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.877 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 176: Stage finished\n",
      "10-20 14:41:39.877 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 146 finished: parquet at OneHotEncoder.scala:418, took 0.038534 s\n",
      "10-20 14:41:39.879 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_275_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.880 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_274_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.882 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_273_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.883 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_276_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.885 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:39.885 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:39.885 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_281_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.885 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:41:39.886 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_279_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.890 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_286 stored as values in memory (estimated size 177.4 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.895 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_286_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.896 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_286_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.897 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 286 from head at OneHotEncoder.scala:419\n",
      "10-20 14:41:39.897 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:39.901 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:41:39.901 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 147 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:41:39.901 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 177 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:41:39.901 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.901 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.901 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 177 (MapPartitionsRDD[465] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:41:39.903 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_287 stored as values in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.904 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_287_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 433.5 MiB)\n",
      "10-20 14:41:39.905 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_287_piece0 in memory on 95675304fa2d:39707 (size: 4.8 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:39.905 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 287 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.906 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 177 (MapPartitionsRDD[465] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.906 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 177.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.906 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 177.0 (TID 394) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.907 172.17.0.2:54321      6000    (TID 394)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 177.0 (TID 394)\n",
      "10-20 14:41:39.908 172.17.0.2:54321      6000    (TID 394)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/09_OneHotEncoder_cea0c712efbc/data/part-00000-78b0edea-bc88-4f86-bd46-df3110cd1cc8-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:41:39.911 172.17.0.2:54321      6000    (TID 394)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:39.912 172.17.0.2:54321      6000    (TID 394)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:39.912 172.17.0.2:54321      6000    (TID 394)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:39.913 172.17.0.2:54321      6000    (TID 394)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 177.0 (TID 394). 1633 bytes result sent to driver\n",
      "10-20 14:41:39.914 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 177.0 (TID 394) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.914 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.915 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 177 (head at OneHotEncoder.scala:419) finished in 0.013 s\n",
      "10-20 14:41:39.915 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 147 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.915 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 177: Stage finished\n",
      "10-20 14:41:39.915 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 147 finished: head at OneHotEncoder.scala:419, took 0.014404 s\n",
      "10-20 14:41:39.918 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_288 stored as values in memory (estimated size 176.1 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.923 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_288_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.923 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_288_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.923 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 288 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:39.938 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:39.939 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 148 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:39.939 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 178 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:39.939 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.939 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.939 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 178 (outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata MapPartitionsRDD[467] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:39.939 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_289 stored as values in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.940 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_289_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.3 MiB)\n",
      "10-20 14:41:39.940 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_289_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.940 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 289 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.941 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 178 (outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata MapPartitionsRDD[467] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.941 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 178.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.941 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 178.0 (TID 395) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.941 172.17.0.2:54321      6000    (TID 395)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 178.0 (TID 395)\n",
      "10-20 14:41:39.943 172.17.0.2:54321      6000    (TID 395)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata/part-00000:0+326\n",
      "10-20 14:41:39.945 172.17.0.2:54321      6000    (TID 395)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 178.0 (TID 395). 1211 bytes result sent to driver\n",
      "10-20 14:41:39.945 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 178.0 (TID 395) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.945 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.946 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 178 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:39.946 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 148 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.946 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 178: Stage finished\n",
      "10-20 14:41:39.946 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 148 finished: first at ReadWrite.scala:587, took 0.008284 s\n",
      "10-20 14:41:39.948 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_290 stored as values in memory (estimated size 176.1 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.952 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_290_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.952 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_290_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.952 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 290 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:39.975 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:39.976 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 149 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:39.976 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 179 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:39.976 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:39.976 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:39.976 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 179 (outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata MapPartitionsRDD[469] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:39.977 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_291 stored as values in memory (estimated size 4.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.977 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_291_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.1 MiB)\n",
      "10-20 14:41:39.977 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_291_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:39.978 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 291 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:39.978 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 179 (outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata MapPartitionsRDD[469] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:39.978 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 179.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:39.979 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 179.0 (TID 396) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:39.979 172.17.0.2:54321      6000    (TID 396)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 179.0 (TID 396)\n",
      "10-20 14:41:39.980 172.17.0.2:54321      6000    (TID 396)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/metadata/part-00000:0+326\n",
      "10-20 14:41:39.982 172.17.0.2:54321      6000    (TID 396)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 179.0 (TID 396). 1254 bytes result sent to driver\n",
      "10-20 14:41:39.982 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 179.0 (TID 396) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:39.982 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:39.983 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 179 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:39.983 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 149 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:39.983 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 179: Stage finished\n",
      "10-20 14:41:39.984 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 149 finished: first at ReadWrite.scala:587, took 0.009064 s\n",
      "10-20 14:41:39.989 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:40.005 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:41:40.006 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 150 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:41:40.006 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 180 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:41:40.006 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.006 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.006 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 180 (MapPartitionsRDD[471] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:41:40.011 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_292 stored as values in memory (estimated size 84.5 KiB, free 433.0 MiB)\n",
      "10-20 14:41:40.012 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_292_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.0 MiB)\n",
      "10-20 14:41:40.012 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_292_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.013 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 292 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.013 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 180 (MapPartitionsRDD[471] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.013 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 180.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.014 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 180.0 (TID 397) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.014 172.17.0.2:54321      6000    (TID 397)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 180.0 (TID 397)\n",
      "10-20 14:41:40.021 172.17.0.2:54321      6000    (TID 397)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 180.0 (TID 397). 1705 bytes result sent to driver\n",
      "10-20 14:41:40.021 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 180.0 (TID 397) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.021 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.022 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 180 (parquet at OneHotEncoder.scala:418) finished in 0.015 s\n",
      "10-20 14:41:40.022 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 150 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.022 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 180: Stage finished\n",
      "10-20 14:41:40.022 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 150 finished: parquet at OneHotEncoder.scala:418, took 0.016844 s\n",
      "10-20 14:41:40.029 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:40.030 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:40.030 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:41:40.038 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_293 stored as values in memory (estimated size 177.4 KiB, free 432.8 MiB)\n",
      "10-20 14:41:40.044 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_293_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.8 MiB)\n",
      "10-20 14:41:40.045 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_293_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.046 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 293 from head at OneHotEncoder.scala:419\n",
      "10-20 14:41:40.046 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:40.075 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:41:40.075 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 151 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:41:40.076 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 181 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:41:40.076 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.076 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.076 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[474] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:41:40.078 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_294 stored as values in memory (estimated size 8.9 KiB, free 432.7 MiB)\n",
      "10-20 14:41:40.079 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_294_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.7 MiB)\n",
      "10-20 14:41:40.079 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_294_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.079 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 294 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.080 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 181 (MapPartitionsRDD[474] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.080 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 181.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.081 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 181.0 (TID 398) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.082 172.17.0.2:54321      6000    (TID 398)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 181.0 (TID 398)\n",
      "10-20 14:41:40.085 172.17.0.2:54321      6000    (TID 398)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/10_OneHotEncoder_49a66e99e263/data/part-00000-9e6216b3-41a9-4b4e-a2ff-f6b5c0484611-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:41:40.087 172.17.0.2:54321      6000    (TID 398)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:40.087 172.17.0.2:54321      6000    (TID 398)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:40.088 172.17.0.2:54321      6000    (TID 398)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1\n",
      "10-20 14:41:40.089 172.17.0.2:54321      6000    (TID 398)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 181.0 (TID 398). 1633 bytes result sent to driver\n",
      "10-20 14:41:40.089 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 181.0 (TID 398) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.089 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.090 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 181 (head at OneHotEncoder.scala:419) finished in 0.014 s\n",
      "10-20 14:41:40.090 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 151 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.090 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 181: Stage finished\n",
      "10-20 14:41:40.091 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 151 finished: head at OneHotEncoder.scala:419, took 0.015921 s\n",
      "10-20 14:41:40.094 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_295 stored as values in memory (estimated size 176.1 KiB, free 432.6 MiB)\n",
      "10-20 14:41:40.098 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_295_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:40.099 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_295_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.099 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 295 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:40.114 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:40.115 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 152 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:40.115 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 182 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:40.115 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.115 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.115 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 182 (outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata MapPartitionsRDD[476] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:40.115 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_296 stored as values in memory (estimated size 4.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:40.116 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_296_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.5 MiB)\n",
      "10-20 14:41:40.116 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_296_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.116 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 296 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.117 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 182 (outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata MapPartitionsRDD[476] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.117 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 182.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.117 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 182.0 (TID 399) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.118 172.17.0.2:54321      6000    (TID 399)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 182.0 (TID 399)\n",
      "10-20 14:41:40.119 172.17.0.2:54321      6000    (TID 399)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata/part-00000:0+336\n",
      "10-20 14:41:40.120 172.17.0.2:54321      6000    (TID 399)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 182.0 (TID 399). 1178 bytes result sent to driver\n",
      "10-20 14:41:40.121 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 182.0 (TID 399) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.121 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.121 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 182 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:41:40.121 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 152 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.121 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 182: Stage finished\n",
      "10-20 14:41:40.121 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 152 finished: first at ReadWrite.scala:587, took 0.007184 s\n",
      "10-20 14:41:40.123 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_297 stored as values in memory (estimated size 176.1 KiB, free 432.4 MiB)\n",
      "10-20 14:41:40.129 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_297_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.3 MiB)\n",
      "10-20 14:41:40.129 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_297_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.129 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 297 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:40.144 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:40.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 153 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:40.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 183 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:40.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.145 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 183 (outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata MapPartitionsRDD[478] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:40.146 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_298 stored as values in memory (estimated size 4.2 KiB, free 432.3 MiB)\n",
      "10-20 14:41:40.146 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_298_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.3 MiB)\n",
      "10-20 14:41:40.147 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_298_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.147 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 298 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.148 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 183 (outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata MapPartitionsRDD[478] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.148 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 183.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.148 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 183.0 (TID 400) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.149 172.17.0.2:54321      6000    (TID 400)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 183.0 (TID 400)\n",
      "10-20 14:41:40.150 172.17.0.2:54321      6000    (TID 400)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/metadata/part-00000:0+336\n",
      "10-20 14:41:40.151 172.17.0.2:54321      6000    (TID 400)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 183.0 (TID 400). 1178 bytes result sent to driver\n",
      "10-20 14:41:40.151 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 183.0 (TID 400) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.151 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.152 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 183 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:40.152 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 153 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.152 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 183: Stage finished\n",
      "10-20 14:41:40.153 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 153 finished: first at ReadWrite.scala:587, took 0.008432 s\n",
      "10-20 14:41:40.157 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:40.173 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:41:40.174 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 154 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:41:40.174 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 184 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:41:40.174 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.174 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.174 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 184 (MapPartitionsRDD[480] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:41:40.179 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_299 stored as values in memory (estimated size 84.5 KiB, free 432.2 MiB)\n",
      "10-20 14:41:40.180 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_299_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.2 MiB)\n",
      "10-20 14:41:40.180 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_299_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.0 MiB)\n",
      "10-20 14:41:40.181 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 299 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.181 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 184 (MapPartitionsRDD[480] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.181 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 184.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.182 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 184.0 (TID 401) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.182 172.17.0.2:54321      6000    (TID 401)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 184.0 (TID 401)\n",
      "10-20 14:41:40.190 172.17.0.2:54321      6000    (TID 401)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 184.0 (TID 401). 1705 bytes result sent to driver\n",
      "10-20 14:41:40.190 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 184.0 (TID 401) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.191 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 184.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.191 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 184 (parquet at OneHotEncoder.scala:418) finished in 0.016 s\n",
      "10-20 14:41:40.191 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 154 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.192 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 184: Stage finished\n",
      "10-20 14:41:40.192 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 154 finished: parquet at OneHotEncoder.scala:418, took 0.018294 s\n",
      "10-20 14:41:40.199 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:40.199 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:40.200 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:41:40.204 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_300 stored as values in memory (estimated size 177.4 KiB, free 432.0 MiB)\n",
      "10-20 14:41:40.227 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_296_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.229 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_287_piece0 on 95675304fa2d:39707 in memory (size: 4.8 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.234 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_298_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.235 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_297_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.236 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_294_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.238 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_288_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.239 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_300_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.5 MiB)\n",
      "10-20 14:41:40.240 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_292_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.248 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_300_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.249 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 300 from head at OneHotEncoder.scala:419\n",
      "10-20 14:41:40.249 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:40.250 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_286_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.251 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_285_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.254 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:41:40.254 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 155 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:41:40.254 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 185 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:41:40.254 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.255 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.255 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 185 (MapPartitionsRDD[483] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:41:40.256 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_299_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.257 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_301 stored as values in memory (estimated size 8.9 KiB, free 432.9 MiB)\n",
      "10-20 14:41:40.258 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_301_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.0 MiB)\n",
      "10-20 14:41:40.259 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_301_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.259 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_290_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.260 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 301 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.260 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 185 (MapPartitionsRDD[483] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.260 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 185.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.261 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 185.0 (TID 402) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.261 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_293_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:40.262 172.17.0.2:54321      6000    (TID 402)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 185.0 (TID 402)\n",
      "10-20 14:41:40.263 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_291_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:40.264 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_295_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:40.265 172.17.0.2:54321      6000    (TID 402)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/11_OneHotEncoder_244b95b54c8f/data/part-00000-4eac8902-db0d-4f97-9a53-b0ec6f2f61d6-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:41:40.265 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_289_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:40.267 172.17.0.2:54321      6000    (TID 402)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:40.268 172.17.0.2:54321      6000    (TID 402)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:40.268 172.17.0.2:54321      6000    (TID 402)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:40.269 172.17.0.2:54321      6000    (TID 402)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 185.0 (TID 402). 1633 bytes result sent to driver\n",
      "10-20 14:41:40.270 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 185.0 (TID 402) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.270 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.270 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 185 (head at OneHotEncoder.scala:419) finished in 0.015 s\n",
      "10-20 14:41:40.271 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 155 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.271 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 185: Stage finished\n",
      "10-20 14:41:40.271 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 155 finished: head at OneHotEncoder.scala:419, took 0.017531 s\n",
      "10-20 14:41:40.275 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_302 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 14:41:40.281 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_302_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.4 MiB)\n",
      "10-20 14:41:40.282 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_302_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:40.282 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 302 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:40.302 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:40.302 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 156 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:40.302 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 186 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:40.302 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.302 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.303 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 186 (outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata MapPartitionsRDD[485] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:40.304 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_303 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:41:40.305 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_303_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:41:40.305 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_303_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:40.306 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 303 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.306 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 186 (outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata MapPartitionsRDD[485] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.306 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 186.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.307 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 186.0 (TID 403) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.307 172.17.0.2:54321      6000    (TID 403)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 186.0 (TID 403)\n",
      "10-20 14:41:40.309 172.17.0.2:54321      6000    (TID 403)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata/part-00000:0+328\n",
      "10-20 14:41:40.310 172.17.0.2:54321      6000    (TID 403)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 186.0 (TID 403). 1256 bytes result sent to driver\n",
      "10-20 14:41:40.311 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 186.0 (TID 403) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.311 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.311 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 186 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:41:40.311 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 156 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.312 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 186: Stage finished\n",
      "10-20 14:41:40.312 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 156 finished: first at ReadWrite.scala:587, took 0.009888 s\n",
      "10-20 14:41:40.314 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_304 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 14:41:40.321 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_304_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.2 MiB)\n",
      "10-20 14:41:40.321 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_304_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.321 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 304 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:40.345 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:40.346 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 157 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:40.346 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 187 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:40.346 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.346 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.346 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 187 (outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata MapPartitionsRDD[487] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:40.347 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_305 stored as values in memory (estimated size 4.2 KiB, free 433.2 MiB)\n",
      "10-20 14:41:40.348 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_305_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.2 MiB)\n",
      "10-20 14:41:40.348 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_305_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.349 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 305 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.349 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 187 (outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata MapPartitionsRDD[487] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.349 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 187.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.350 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 187.0 (TID 404) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.351 172.17.0.2:54321      6000    (TID 404)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 187.0 (TID 404)\n",
      "10-20 14:41:40.353 172.17.0.2:54321      6000    (TID 404)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/metadata/part-00000:0+328\n",
      "10-20 14:41:40.355 172.17.0.2:54321      6000    (TID 404)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 187.0 (TID 404). 1256 bytes result sent to driver\n",
      "10-20 14:41:40.356 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 187.0 (TID 404) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.356 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 187.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.357 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 187 (first at ReadWrite.scala:587) finished in 0.010 s\n",
      "10-20 14:41:40.357 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 157 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.357 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 187: Stage finished\n",
      "10-20 14:41:40.357 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 157 finished: first at ReadWrite.scala:587, took 0.012130 s\n",
      "10-20 14:41:40.364 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:40.390 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:41:40.390 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 158 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:41:40.390 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 188 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:41:40.390 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.390 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.391 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 188 (MapPartitionsRDD[489] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:41:40.398 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_306 stored as values in memory (estimated size 84.5 KiB, free 433.1 MiB)\n",
      "10-20 14:41:40.399 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_306_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.1 MiB)\n",
      "10-20 14:41:40.399 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_306_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.400 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 306 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.400 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 188 (MapPartitionsRDD[489] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.400 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 188.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.401 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 188.0 (TID 405) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.401 172.17.0.2:54321      6000    (TID 405)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 188.0 (TID 405)\n",
      "10-20 14:41:40.410 172.17.0.2:54321      6000    (TID 405)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 188.0 (TID 405). 1705 bytes result sent to driver\n",
      "10-20 14:41:40.411 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 188.0 (TID 405) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.411 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.412 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 188 (parquet at OneHotEncoder.scala:418) finished in 0.021 s\n",
      "10-20 14:41:40.412 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 158 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.412 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 188: Stage finished\n",
      "10-20 14:41:40.413 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 158 finished: parquet at OneHotEncoder.scala:418, took 0.022865 s\n",
      "10-20 14:41:40.423 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:40.423 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:40.423 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:41:40.432 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_307 stored as values in memory (estimated size 177.4 KiB, free 432.9 MiB)\n",
      "10-20 14:41:40.439 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_307_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.9 MiB)\n",
      "10-20 14:41:40.440 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_307_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.441 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 307 from head at OneHotEncoder.scala:419\n",
      "10-20 14:41:40.441 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:40.446 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:41:40.446 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 159 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:41:40.447 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 189 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:41:40.447 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.447 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.447 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 189 (MapPartitionsRDD[492] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:41:40.449 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_308 stored as values in memory (estimated size 8.9 KiB, free 432.9 MiB)\n",
      "10-20 14:41:40.451 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_308_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.9 MiB)\n",
      "10-20 14:41:40.451 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_308_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.451 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 308 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.452 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 189 (MapPartitionsRDD[492] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.452 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 189.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.453 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 189.0 (TID 406) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.453 172.17.0.2:54321      6000    (TID 406)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 189.0 (TID 406)\n",
      "10-20 14:41:40.457 172.17.0.2:54321      6000    (TID 406)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/12_OneHotEncoder_817fc8ee27d1/data/part-00000-ef2a2ef5-f2b1-4c06-b402-6c6b518f0107-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:41:40.460 172.17.0.2:54321      6000    (TID 406)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:40.461 172.17.0.2:54321      6000    (TID 406)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:40.461 172.17.0.2:54321      6000    (TID 406)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:40.462 172.17.0.2:54321      6000    (TID 406)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 189.0 (TID 406). 1629 bytes result sent to driver\n",
      "10-20 14:41:40.463 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 189.0 (TID 406) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.463 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 189.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.464 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 189 (head at OneHotEncoder.scala:419) finished in 0.017 s\n",
      "10-20 14:41:40.464 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 159 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.464 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 189: Stage finished\n",
      "10-20 14:41:40.464 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 159 finished: head at OneHotEncoder.scala:419, took 0.018268 s\n",
      "10-20 14:41:40.468 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_309 stored as values in memory (estimated size 176.1 KiB, free 432.7 MiB)\n",
      "10-20 14:41:40.474 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_309_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:41:40.531 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_309_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.532 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 309 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:40.549 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:40.550 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 160 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:40.550 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 190 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:40.550 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.550 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.550 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 190 (outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata MapPartitionsRDD[494] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:40.551 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_310 stored as values in memory (estimated size 4.2 KiB, free 432.6 MiB)\n",
      "10-20 14:41:40.552 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_310_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.6 MiB)\n",
      "10-20 14:41:40.552 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_310_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.552 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 310 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.552 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 190 (outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata MapPartitionsRDD[494] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.552 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 190.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.553 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 190.0 (TID 407) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.554 172.17.0.2:54321      6000    (TID 407)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 190.0 (TID 407)\n",
      "10-20 14:41:40.555 172.17.0.2:54321      6000    (TID 407)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata/part-00000:0+332\n",
      "10-20 14:41:40.556 172.17.0.2:54321      6000    (TID 407)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 190.0 (TID 407). 1217 bytes result sent to driver\n",
      "10-20 14:41:40.556 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 190.0 (TID 407) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.556 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.557 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 190 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:40.557 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 160 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.557 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 190: Stage finished\n",
      "10-20 14:41:40.557 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 160 finished: first at ReadWrite.scala:587, took 0.007954 s\n",
      "10-20 14:41:40.558 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_311 stored as values in memory (estimated size 176.1 KiB, free 432.5 MiB)\n",
      "10-20 14:41:40.563 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_311_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.4 MiB)\n",
      "10-20 14:41:40.563 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_311_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.563 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 311 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:40.578 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:40.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 161 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:40.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 191 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:40.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.578 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 191 (outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata MapPartitionsRDD[496] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:40.579 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_312 stored as values in memory (estimated size 4.2 KiB, free 432.4 MiB)\n",
      "10-20 14:41:40.582 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_312_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.4 MiB)\n",
      "10-20 14:41:40.582 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_312_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.583 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 312 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.583 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 191 (outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata MapPartitionsRDD[496] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.583 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 191.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.583 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 191.0 (TID 408) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.584 172.17.0.2:54321      6000    (TID 408)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 191.0 (TID 408)\n",
      "10-20 14:41:40.585 172.17.0.2:54321      6000    (TID 408)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/metadata/part-00000:0+332\n",
      "10-20 14:41:40.586 172.17.0.2:54321      6000    (TID 408)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 191.0 (TID 408). 1217 bytes result sent to driver\n",
      "10-20 14:41:40.586 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 191.0 (TID 408) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.587 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.587 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 191 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:41:40.587 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 161 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.587 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 191: Stage finished\n",
      "10-20 14:41:40.588 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 161 finished: first at ReadWrite.scala:587, took 0.009570 s\n",
      "10-20 14:41:40.593 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:40.609 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:41:40.610 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 162 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:41:40.610 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 192 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:41:40.610 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.610 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.610 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 192 (MapPartitionsRDD[498] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:41:40.614 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_313 stored as values in memory (estimated size 84.5 KiB, free 432.4 MiB)\n",
      "10-20 14:41:40.615 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_313_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.3 MiB)\n",
      "10-20 14:41:40.615 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_313_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.615 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 313 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.616 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 192 (MapPartitionsRDD[498] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.616 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 192.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.616 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 192.0 (TID 409) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.616 172.17.0.2:54321      6000    (TID 409)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 192.0 (TID 409)\n",
      "10-20 14:41:40.622 172.17.0.2:54321      6000    (TID 409)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 192.0 (TID 409). 1705 bytes result sent to driver\n",
      "10-20 14:41:40.622 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 192.0 (TID 409) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.622 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 192.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.623 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 192 (parquet at OneHotEncoder.scala:418) finished in 0.013 s\n",
      "10-20 14:41:40.623 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 162 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.623 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 192: Stage finished\n",
      "10-20 14:41:40.623 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 162 finished: parquet at OneHotEncoder.scala:418, took 0.013454 s\n",
      "10-20 14:41:40.630 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:40.630 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:40.631 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:41:40.637 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_314 stored as values in memory (estimated size 177.4 KiB, free 432.2 MiB)\n",
      "10-20 14:41:40.643 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_314_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.1 MiB)\n",
      "10-20 14:41:40.644 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_314_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.647 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 314 from head at OneHotEncoder.scala:419\n",
      "10-20 14:41:40.648 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:40.652 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:41:40.653 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 163 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:41:40.653 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 193 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:41:40.653 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.653 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.653 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 193 (MapPartitionsRDD[501] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:41:40.655 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_315 stored as values in memory (estimated size 8.9 KiB, free 432.1 MiB)\n",
      "10-20 14:41:40.669 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_315_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.1 MiB)\n",
      "10-20 14:41:40.670 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_315_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.0 MiB)\n",
      "10-20 14:41:40.670 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 315 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.670 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 193 (MapPartitionsRDD[501] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.670 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 193.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.670 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_310_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.0 MiB)\n",
      "10-20 14:41:40.670 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 193.0 (TID 410) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.672 172.17.0.2:54321      6000    (TID 410)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 193.0 (TID 410)\n",
      "10-20 14:41:40.673 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_300_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.674 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_308_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.674 172.17.0.2:54321      6000    (TID 410)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/13_OneHotEncoder_57530b711254/data/part-00000-e76ba9d1-8323-4b58-8a2d-73b24a0df199-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:41:40.675 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_309_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.676 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_313_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.677 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_303_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.677 172.17.0.2:54321      6000    (TID 410)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:40.678 172.17.0.2:54321      6000    (TID 410)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:40.678 172.17.0.2:54321      6000    (TID 410)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:40.679 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_301_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.679 172.17.0.2:54321      6000    (TID 410)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 193.0 (TID 410). 1633 bytes result sent to driver\n",
      "10-20 14:41:40.680 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_311_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.680 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 193.0 (TID 410) in 10 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.680 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 193.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.681 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_305_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.681 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 193 (head at OneHotEncoder.scala:419) finished in 0.028 s\n",
      "10-20 14:41:40.681 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 163 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.681 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 193: Stage finished\n",
      "10-20 14:41:40.681 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 163 finished: head at OneHotEncoder.scala:419, took 0.028782 s\n",
      "10-20 14:41:40.682 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_302_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.683 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_307_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.684 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_306_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:40.684 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_316 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 14:41:40.685 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_304_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:40.685 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_312_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:40.690 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_316_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.4 MiB)\n",
      "10-20 14:41:40.690 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_316_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:40.690 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 316 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:40.707 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:40.709 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 164 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:40.709 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 194 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:40.709 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.709 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.709 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 194 (outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata MapPartitionsRDD[503] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:40.709 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_317 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:41:40.710 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_317_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:41:40.710 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_317_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:40.710 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 317 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.710 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 194 (outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata MapPartitionsRDD[503] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.710 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 194.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.711 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 194.0 (TID 411) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.711 172.17.0.2:54321      6000    (TID 411)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 194.0 (TID 411)\n",
      "10-20 14:41:40.713 172.17.0.2:54321      6000    (TID 411)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata/part-00000:0+316\n",
      "10-20 14:41:40.714 172.17.0.2:54321      6000    (TID 411)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 194.0 (TID 411). 1244 bytes result sent to driver\n",
      "10-20 14:41:40.714 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 194.0 (TID 411) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.714 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.715 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 194 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:41:40.715 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 164 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.716 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 194: Stage finished\n",
      "10-20 14:41:40.716 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 164 finished: first at ReadWrite.scala:587, took 0.008506 s\n",
      "10-20 14:41:40.717 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_318 stored as values in memory (estimated size 176.1 KiB, free 433.2 MiB)\n",
      "10-20 14:41:40.722 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_318_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.2 MiB)\n",
      "10-20 14:41:40.722 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_318_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.723 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 318 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:40.739 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:40.739 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 165 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:40.739 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 195 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:40.739 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.739 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.739 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 195 (outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata MapPartitionsRDD[505] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:40.740 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_319 stored as values in memory (estimated size 4.2 KiB, free 433.2 MiB)\n",
      "10-20 14:41:40.740 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_319_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.2 MiB)\n",
      "10-20 14:41:40.741 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_319_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.741 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 319 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.742 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 195 (outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata MapPartitionsRDD[505] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.742 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 195.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.743 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 195.0 (TID 412) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.743 172.17.0.2:54321      6000    (TID 412)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 195.0 (TID 412)\n",
      "10-20 14:41:40.745 172.17.0.2:54321      6000    (TID 412)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/metadata/part-00000:0+316\n",
      "10-20 14:41:40.746 172.17.0.2:54321      6000    (TID 412)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 195.0 (TID 412). 1244 bytes result sent to driver\n",
      "10-20 14:41:40.746 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 195.0 (TID 412) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.746 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.747 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 195 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:40.747 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 165 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.747 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 195: Stage finished\n",
      "10-20 14:41:40.747 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 165 finished: first at ReadWrite.scala:587, took 0.008801 s\n",
      "10-20 14:41:40.752 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:40.769 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:41:40.769 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 166 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:41:40.769 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 196 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:41:40.769 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.769 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.769 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 196 (MapPartitionsRDD[507] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:41:40.774 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_320 stored as values in memory (estimated size 84.5 KiB, free 433.1 MiB)\n",
      "10-20 14:41:40.775 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_320_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.1 MiB)\n",
      "10-20 14:41:40.775 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_320_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.775 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 320 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.776 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 196 (MapPartitionsRDD[507] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.776 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 196.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.777 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 196.0 (TID 413) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.777 172.17.0.2:54321      6000    (TID 413)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 196.0 (TID 413)\n",
      "10-20 14:41:40.782 172.17.0.2:54321      6000    (TID 413)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 196.0 (TID 413). 1705 bytes result sent to driver\n",
      "10-20 14:41:40.783 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 196.0 (TID 413) in 6 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.783 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.789 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 196 (parquet at OneHotEncoder.scala:418) finished in 0.019 s\n",
      "10-20 14:41:40.789 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 166 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.789 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 196: Stage finished\n",
      "10-20 14:41:40.790 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 166 finished: parquet at OneHotEncoder.scala:418, took 0.021125 s\n",
      "10-20 14:41:40.799 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:40.799 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:40.799 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:41:40.804 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_321 stored as values in memory (estimated size 177.4 KiB, free 432.9 MiB)\n",
      "10-20 14:41:40.809 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_321_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.9 MiB)\n",
      "10-20 14:41:40.809 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_321_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.810 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 321 from head at OneHotEncoder.scala:419\n",
      "10-20 14:41:40.810 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:40.815 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:41:40.816 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 167 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:41:40.816 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 197 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:41:40.816 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.816 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.817 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 197 (MapPartitionsRDD[510] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:41:40.819 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_322 stored as values in memory (estimated size 8.9 KiB, free 432.9 MiB)\n",
      "10-20 14:41:40.820 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_322_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 432.9 MiB)\n",
      "10-20 14:41:40.820 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_322_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:40.820 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 322 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.821 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 197 (MapPartitionsRDD[510] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.821 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 197.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.821 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 197.0 (TID 414) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.822 172.17.0.2:54321      6000    (TID 414)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 197.0 (TID 414)\n",
      "10-20 14:41:40.824 172.17.0.2:54321      6000    (TID 414)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/14_OneHotEncoder_bfe933d13538/data/part-00000-0f750067-deed-48fb-936b-5d79e4b4a5da-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:41:40.827 172.17.0.2:54321      6000    (TID 414)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:40.827 172.17.0.2:54321      6000    (TID 414)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:40.828 172.17.0.2:54321      6000    (TID 414)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:40.828 172.17.0.2:54321      6000    (TID 414)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 197.0 (TID 414). 1633 bytes result sent to driver\n",
      "10-20 14:41:40.829 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 197.0 (TID 414) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.829 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.830 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 197 (head at OneHotEncoder.scala:419) finished in 0.013 s\n",
      "10-20 14:41:40.830 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 167 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.830 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 197: Stage finished\n",
      "10-20 14:41:40.830 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 167 finished: head at OneHotEncoder.scala:419, took 0.014162 s\n",
      "10-20 14:41:40.832 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_323 stored as values in memory (estimated size 176.1 KiB, free 432.7 MiB)\n",
      "10-20 14:41:40.836 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_323_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:41:40.837 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_323_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.837 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 323 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:40.854 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:40.855 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 168 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:40.855 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 198 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:40.855 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.855 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.855 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 198 (outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata MapPartitionsRDD[512] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:40.856 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_324 stored as values in memory (estimated size 4.2 KiB, free 432.6 MiB)\n",
      "10-20 14:41:40.856 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_324_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.6 MiB)\n",
      "10-20 14:41:40.856 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_324_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.857 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 324 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.857 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 198 (outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata MapPartitionsRDD[512] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.857 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 198.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.858 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 198.0 (TID 415) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.894 172.17.0.2:54321      6000    (TID 415)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 198.0 (TID 415)\n",
      "10-20 14:41:40.895 172.17.0.2:54321      6000    (TID 415)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata/part-00000:0+314\n",
      "10-20 14:41:40.897 172.17.0.2:54321      6000    (TID 415)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 198.0 (TID 415). 1242 bytes result sent to driver\n",
      "10-20 14:41:40.897 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 198.0 (TID 415) in 39 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.898 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.899 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 198 (first at ReadWrite.scala:587) finished in 0.044 s\n",
      "10-20 14:41:40.899 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 168 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.899 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 198: Stage finished\n",
      "10-20 14:41:40.899 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 168 finished: first at ReadWrite.scala:587, took 0.044774 s\n",
      "10-20 14:41:40.907 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_325 stored as values in memory (estimated size 176.1 KiB, free 432.5 MiB)\n",
      "10-20 14:41:40.913 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_325_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.4 MiB)\n",
      "10-20 14:41:40.913 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_325_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.914 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 325 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:40.935 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:40.935 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 169 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:40.935 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 199 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:40.935 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.935 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.936 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 199 (outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata MapPartitionsRDD[514] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:40.937 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_326 stored as values in memory (estimated size 4.2 KiB, free 432.4 MiB)\n",
      "10-20 14:41:40.937 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_326_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.4 MiB)\n",
      "10-20 14:41:40.937 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_326_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.938 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 326 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.938 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 199 (outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata MapPartitionsRDD[514] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.938 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 199.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.938 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 199.0 (TID 416) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.939 172.17.0.2:54321      6000    (TID 416)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 199.0 (TID 416)\n",
      "10-20 14:41:40.940 172.17.0.2:54321      6000    (TID 416)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/metadata/part-00000:0+314\n",
      "10-20 14:41:40.941 172.17.0.2:54321      6000    (TID 416)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 199.0 (TID 416). 1199 bytes result sent to driver\n",
      "10-20 14:41:40.941 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 199.0 (TID 416) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.941 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.942 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 199 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:41:40.942 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 169 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.943 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 199: Stage finished\n",
      "10-20 14:41:40.943 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 169 finished: first at ReadWrite.scala:587, took 0.008009 s\n",
      "10-20 14:41:40.948 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:40.965 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:41:40.966 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 170 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:41:40.966 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 200 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:41:40.966 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:40.966 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:40.966 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 200 (MapPartitionsRDD[516] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:41:40.970 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_327 stored as values in memory (estimated size 84.5 KiB, free 432.4 MiB)\n",
      "10-20 14:41:40.971 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_327_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.3 MiB)\n",
      "10-20 14:41:40.971 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_327_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:40.972 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 327 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:40.972 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 200 (MapPartitionsRDD[516] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:40.972 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 200.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:40.973 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 200.0 (TID 417) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:40.973 172.17.0.2:54321      6000    (TID 417)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 200.0 (TID 417)\n",
      "10-20 14:41:40.980 172.17.0.2:54321      6000    (TID 417)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 200.0 (TID 417). 1705 bytes result sent to driver\n",
      "10-20 14:41:40.981 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 200.0 (TID 417) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:40.981 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:40.981 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 200 (parquet at OneHotEncoder.scala:418) finished in 0.015 s\n",
      "10-20 14:41:40.982 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 170 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:40.982 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 200: Stage finished\n",
      "10-20 14:41:40.982 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 170 finished: parquet at OneHotEncoder.scala:418, took 0.016526 s\n",
      "10-20 14:41:40.993 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:40.993 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:40.993 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:41:40.999 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_328 stored as values in memory (estimated size 177.4 KiB, free 432.2 MiB)\n",
      "10-20 14:41:41.004 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_328_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 432.1 MiB)\n",
      "10-20 14:41:41.004 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_328_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.005 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 328 from head at OneHotEncoder.scala:419\n",
      "10-20 14:41:41.005 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:41.008 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:41:41.009 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 171 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:41:41.009 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 201 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:41:41.009 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.009 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.009 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 201 (MapPartitionsRDD[519] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:41:41.011 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_329 stored as values in memory (estimated size 8.9 KiB, free 432.1 MiB)\n",
      "10-20 14:41:41.011 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_329_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 432.1 MiB)\n",
      "10-20 14:41:41.011 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_329_piece0 in memory on 95675304fa2d:39707 (size: 4.8 KiB, free: 434.0 MiB)\n",
      "10-20 14:41:41.012 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 329 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.012 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 201 (MapPartitionsRDD[519] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:41.012 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 201.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:41.013 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 201.0 (TID 418) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.013 172.17.0.2:54321      6000    (TID 418)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 201.0 (TID 418)\n",
      "10-20 14:41:41.015 172.17.0.2:54321      6000    (TID 418)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/15_OneHotEncoder_9419dce295d1/data/part-00000-9af656e9-9db7-48f1-94c4-7a2178967e64-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:41:41.018 172.17.0.2:54321      6000    (TID 418)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:41.019 172.17.0.2:54321      6000    (TID 418)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:41.019 172.17.0.2:54321      6000    (TID 418)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:41.021 172.17.0.2:54321      6000    (TID 418)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 201.0 (TID 418). 1633 bytes result sent to driver\n",
      "10-20 14:41:41.022 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 201.0 (TID 418) in 9 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:41.022 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.022 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 201 (head at OneHotEncoder.scala:419) finished in 0.013 s\n",
      "10-20 14:41:41.022 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 171 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.022 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 201: Stage finished\n",
      "10-20 14:41:41.023 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 171 finished: head at OneHotEncoder.scala:419, took 0.014555 s\n",
      "10-20 14:41:41.025 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_330 stored as values in memory (estimated size 176.1 KiB, free 431.9 MiB)\n",
      "10-20 14:41:41.041 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_329_piece0 on 95675304fa2d:39707 in memory (size: 4.8 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.042 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_322_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.043 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_325_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.043 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_330_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.1 MiB)\n",
      "10-20 14:41:41.044 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_330_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.044 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_317_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.044 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 330 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:41.045 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_316_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.046 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_323_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.047 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_328_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.048 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_326_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.049 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_315_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.050 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_314_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.051 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_321_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.052 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_320_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.052 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_327_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:41.053 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_319_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:41.054 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_318_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:41.056 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_324_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:41.063 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:41.063 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 172 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:41.063 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 202 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:41.063 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.063 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.064 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 202 (outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata MapPartitionsRDD[521] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:41.064 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_331 stored as values in memory (estimated size 4.2 KiB, free 433.6 MiB)\n",
      "10-20 14:41:41.065 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_331_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.6 MiB)\n",
      "10-20 14:41:41.065 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_331_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:41.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 331 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 202 (outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata MapPartitionsRDD[521] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:41.066 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 202.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:41.067 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 202.0 (TID 419) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.067 172.17.0.2:54321      6000    (TID 419)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 202.0 (TID 419)\n",
      "10-20 14:41:41.068 172.17.0.2:54321      6000    (TID 419)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata/part-00000:0+336\n",
      "10-20 14:41:41.070 172.17.0.2:54321      6000    (TID 419)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 202.0 (TID 419). 1221 bytes result sent to driver\n",
      "10-20 14:41:41.071 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 202.0 (TID 419) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:41.071 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 202.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.071 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 202 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:41.071 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 172 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.071 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 202: Stage finished\n",
      "10-20 14:41:41.072 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 172 finished: first at ReadWrite.scala:587, took 0.008743 s\n",
      "10-20 14:41:41.073 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_332 stored as values in memory (estimated size 176.1 KiB, free 433.4 MiB)\n",
      "10-20 14:41:41.078 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_332_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.4 MiB)\n",
      "10-20 14:41:41.079 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_332_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:41.079 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 332 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:41.096 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:41.097 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 173 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:41.097 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 203 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:41.097 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.097 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.097 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 203 (outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata MapPartitionsRDD[523] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:41.098 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_333 stored as values in memory (estimated size 4.2 KiB, free 433.4 MiB)\n",
      "10-20 14:41:41.098 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_333_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 433.4 MiB)\n",
      "10-20 14:41:41.098 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_333_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:41.099 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 333 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.099 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 203 (outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata MapPartitionsRDD[523] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:41.099 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 203.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:41.100 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 203.0 (TID 420) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.100 172.17.0.2:54321      6000    (TID 420)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 203.0 (TID 420)\n",
      "10-20 14:41:41.102 172.17.0.2:54321      6000    (TID 420)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/metadata/part-00000:0+336\n",
      "10-20 14:41:41.104 172.17.0.2:54321      6000    (TID 420)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 203.0 (TID 420). 1264 bytes result sent to driver\n",
      "10-20 14:41:41.105 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 203.0 (TID 420) in 5 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:41.105 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 203.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.105 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 203 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:41:41.105 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 173 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.105 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 203: Stage finished\n",
      "10-20 14:41:41.106 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 173 finished: first at ReadWrite.scala:587, took 0.009988 s\n",
      "10-20 14:41:41.111 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:41.129 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:418\n",
      "10-20 14:41:41.130 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 174 (parquet at OneHotEncoder.scala:418) with 1 output partitions\n",
      "10-20 14:41:41.130 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 204 (parquet at OneHotEncoder.scala:418)\n",
      "10-20 14:41:41.130 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.130 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.130 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 204 (MapPartitionsRDD[525] at parquet at OneHotEncoder.scala:418), which has no missing parents\n",
      "10-20 14:41:41.134 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_334 stored as values in memory (estimated size 84.5 KiB, free 433.3 MiB)\n",
      "10-20 14:41:41.136 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_334_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.3 MiB)\n",
      "10-20 14:41:41.136 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_334_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.137 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 334 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.137 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 204 (MapPartitionsRDD[525] at parquet at OneHotEncoder.scala:418) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:41.138 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 204.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:41.138 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 204.0 (TID 421) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4737 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.139 172.17.0.2:54321      6000    (TID 421)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 204.0 (TID 421)\n",
      "10-20 14:41:41.146 172.17.0.2:54321      6000    (TID 421)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 204.0 (TID 421). 1705 bytes result sent to driver\n",
      "10-20 14:41:41.146 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 204.0 (TID 421) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:41.147 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 204.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.147 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 204 (parquet at OneHotEncoder.scala:418) finished in 0.017 s\n",
      "10-20 14:41:41.148 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 174 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.148 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 204: Stage finished\n",
      "10-20 14:41:41.148 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 174 finished: parquet at OneHotEncoder.scala:418, took 0.018500 s\n",
      "10-20 14:41:41.155 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:41.155 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:41.155 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<categorySizes: array<int>>\n",
      "10-20 14:41:41.159 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_335 stored as values in memory (estimated size 177.4 KiB, free 433.1 MiB)\n",
      "10-20 14:41:41.164 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_335_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.1 MiB)\n",
      "10-20 14:41:41.165 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_335_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.165 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 335 from head at OneHotEncoder.scala:419\n",
      "10-20 14:41:41.165 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:41.169 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at OneHotEncoder.scala:419\n",
      "10-20 14:41:41.169 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 175 (head at OneHotEncoder.scala:419) with 1 output partitions\n",
      "10-20 14:41:41.170 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 205 (head at OneHotEncoder.scala:419)\n",
      "10-20 14:41:41.170 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.170 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.170 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 205 (MapPartitionsRDD[528] at head at OneHotEncoder.scala:419), which has no missing parents\n",
      "10-20 14:41:41.171 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_336 stored as values in memory (estimated size 8.9 KiB, free 433.1 MiB)\n",
      "10-20 14:41:41.172 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_336_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.1 MiB)\n",
      "10-20 14:41:41.172 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_336_piece0 in memory on 95675304fa2d:39707 (size: 4.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.172 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 336 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.172 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 205 (MapPartitionsRDD[528] at head at OneHotEncoder.scala:419) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:41.172 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 205.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:41.173 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 205.0 (TID 422) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4988 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.173 172.17.0.2:54321      6000    (TID 422)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 205.0 (TID 422)\n",
      "10-20 14:41:41.175 172.17.0.2:54321      6000    (TID 422)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/16_OneHotEncoder_77d01d806245/data/part-00000-8110f113-1580-4784-b3c6-55f059a5695f-c000.snappy.parquet, range: 0-560, partition values: [empty row]\n",
      "10-20 14:41:41.178 172.17.0.2:54321      6000    (TID 422)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.\n",
      "10-20 14:41:41.179 172.17.0.2:54321      6000    (TID 422)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:41.179 172.17.0.2:54321      6000    (TID 422)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 1\n",
      "10-20 14:41:41.180 172.17.0.2:54321      6000    (TID 422)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 205.0 (TID 422). 1633 bytes result sent to driver\n",
      "10-20 14:41:41.180 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 205.0 (TID 422) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:41.180 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.181 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 205 (head at OneHotEncoder.scala:419) finished in 0.011 s\n",
      "10-20 14:41:41.181 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 175 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.182 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 205: Stage finished\n",
      "10-20 14:41:41.182 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 175 finished: head at OneHotEncoder.scala:419, took 0.012897 s\n",
      "10-20 14:41:41.185 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_337 stored as values in memory (estimated size 176.1 KiB, free 432.9 MiB)\n",
      "10-20 14:41:41.190 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_337_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)\n",
      "10-20 14:41:41.190 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_337_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.190 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 337 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:41.206 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:41.206 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 176 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:41.206 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 206 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:41.206 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.206 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.207 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 206 (outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata MapPartitionsRDD[530] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:41.207 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_338 stored as values in memory (estimated size 4.2 KiB, free 432.9 MiB)\n",
      "10-20 14:41:41.208 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_338_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.9 MiB)\n",
      "10-20 14:41:41.208 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_338_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.209 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 338 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.209 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 206 (outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata MapPartitionsRDD[530] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:41.209 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 206.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:41.210 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 206.0 (TID 423) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4579 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.210 172.17.0.2:54321      6000    (TID 423)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 206.0 (TID 423)\n",
      "10-20 14:41:41.211 172.17.0.2:54321      6000    (TID 423)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata/part-00000:0+520\n",
      "10-20 14:41:41.212 172.17.0.2:54321      6000    (TID 423)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 206.0 (TID 423). 1362 bytes result sent to driver\n",
      "10-20 14:41:41.212 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 206.0 (TID 423) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:41.212 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.213 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 206 (first at ReadWrite.scala:587) finished in 0.006 s\n",
      "10-20 14:41:41.213 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 176 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.213 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 206: Stage finished\n",
      "10-20 14:41:41.213 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 176 finished: first at ReadWrite.scala:587, took 0.007535 s\n",
      "10-20 14:41:41.215 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_339 stored as values in memory (estimated size 176.1 KiB, free 432.7 MiB)\n",
      "10-20 14:41:41.243 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_339_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.7 MiB)\n",
      "10-20 14:41:41.243 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_339_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.244 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 339 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:41.268 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:41.268 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 177 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:41.268 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 207 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:41.268 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.269 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.269 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 207 (outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata MapPartitionsRDD[532] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:41.271 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_340 stored as values in memory (estimated size 4.2 KiB, free 432.7 MiB)\n",
      "10-20 14:41:41.272 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_340_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.7 MiB)\n",
      "10-20 14:41:41.272 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_340_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.272 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 340 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.273 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 207 (outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata MapPartitionsRDD[532] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:41.273 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 207.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:41.274 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 207.0 (TID 424) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4579 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.274 172.17.0.2:54321      6000    (TID 424)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 207.0 (TID 424)\n",
      "10-20 14:41:41.275 172.17.0.2:54321      6000    (TID 424)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/17_VectorAssembler_92d293711184/metadata/part-00000:0+520\n",
      "10-20 14:41:41.276 172.17.0.2:54321      6000    (TID 424)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 207.0 (TID 424). 1448 bytes result sent to driver\n",
      "10-20 14:41:41.277 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 207.0 (TID 424) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:41.277 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.278 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 207 (first at ReadWrite.scala:587) finished in 0.008 s\n",
      "10-20 14:41:41.278 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 177 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.278 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 207: Stage finished\n",
      "10-20 14:41:41.279 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 177 finished: first at ReadWrite.scala:587, took 0.010850 s\n",
      "10-20 14:41:41.280 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_341 stored as values in memory (estimated size 176.1 KiB, free 432.5 MiB)\n",
      "10-20 14:41:41.287 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_341_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:41.288 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_341_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.288 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 341 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:41.319 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:41.320 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 178 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:41.320 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 208 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:41.320 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.320 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.320 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 208 (outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata MapPartitionsRDD[534] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:41.322 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_342 stored as values in memory (estimated size 4.2 KiB, free 432.5 MiB)\n",
      "10-20 14:41:41.322 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_342_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.5 MiB)\n",
      "10-20 14:41:41.323 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_342_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.324 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 342 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.324 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 208 (outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata MapPartitionsRDD[534] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:41.324 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 208.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:41.324 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 208.0 (TID 425) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4586 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.325 172.17.0.2:54321      6000    (TID 425)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 208.0 (TID 425)\n",
      "10-20 14:41:41.326 172.17.0.2:54321      6000    (TID 425)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata/part-00000:0+742\n",
      "10-20 14:41:41.328 172.17.0.2:54321      6000    (TID 425)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 208.0 (TID 425). 1670 bytes result sent to driver\n",
      "10-20 14:41:41.328 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 208.0 (TID 425) in 4 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:41.328 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.328 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 208 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:41.329 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 178 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.329 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 208: Stage finished\n",
      "10-20 14:41:41.330 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 178 finished: first at ReadWrite.scala:587, took 0.010926 s\n",
      "10-20 14:41:41.333 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_343 stored as values in memory (estimated size 176.1 KiB, free 432.3 MiB)\n",
      "10-20 14:41:41.338 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_343_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.3 MiB)\n",
      "10-20 14:41:41.338 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_343_piece0 in memory on 95675304fa2d:39707 (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.339 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 343 from textFile at ReadWrite.scala:587\n",
      "10-20 14:41:41.356 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: first at ReadWrite.scala:587\n",
      "10-20 14:41:41.357 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 179 (first at ReadWrite.scala:587) with 1 output partitions\n",
      "10-20 14:41:41.357 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 209 (first at ReadWrite.scala:587)\n",
      "10-20 14:41:41.357 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.357 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.357 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 209 (outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata MapPartitionsRDD[536] at textFile at ReadWrite.scala:587), which has no missing parents\n",
      "10-20 14:41:41.358 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_344 stored as values in memory (estimated size 4.2 KiB, free 432.2 MiB)\n",
      "10-20 14:41:41.358 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_344_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 432.2 MiB)\n",
      "10-20 14:41:41.359 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_344_piece0 in memory on 95675304fa2d:39707 (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.359 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 344 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.359 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 209 (outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata MapPartitionsRDD[536] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:41.359 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 209.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:41.360 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 209.0 (TID 426) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4586 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.360 172.17.0.2:54321      6000    (TID 426)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 209.0 (TID 426)\n",
      "10-20 14:41:41.361 172.17.0.2:54321      6000    (TID 426)  INFO org.apache.spark.rdd.HadoopRDD: Input split: file:/home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/metadata/part-00000:0+742\n",
      "10-20 14:41:41.363 172.17.0.2:54321      6000    (TID 426)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 209.0 (TID 426). 1627 bytes result sent to driver\n",
      "10-20 14:41:41.363 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 209.0 (TID 426) in 3 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:41.363 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 209.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.364 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 209 (first at ReadWrite.scala:587) finished in 0.007 s\n",
      "10-20 14:41:41.365 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 179 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.365 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 209: Stage finished\n",
      "10-20 14:41:41.365 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 179 finished: first at ReadWrite.scala:587, took 0.008308 s\n",
      "10-20 14:41:41.371 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:41.390 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at treeModels.scala:507\n",
      "10-20 14:41:41.390 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 180 (parquet at treeModels.scala:507) with 1 output partitions\n",
      "10-20 14:41:41.390 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 210 (parquet at treeModels.scala:507)\n",
      "10-20 14:41:41.390 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.390 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.391 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 210 (MapPartitionsRDD[538] at parquet at treeModels.scala:507), which has no missing parents\n",
      "10-20 14:41:41.396 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_345 stored as values in memory (estimated size 84.5 KiB, free 432.2 MiB)\n",
      "10-20 14:41:41.410 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_345_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 432.1 MiB)\n",
      "10-20 14:41:41.411 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_345_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.411 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_338_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.412 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 345 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.412 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 210 (MapPartitionsRDD[538] at parquet at treeModels.scala:507) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:41.413 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 210.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:41.413 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 210.0 (TID 427) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4755 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.415 172.17.0.2:54321      6000    (TID 427)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 210.0 (TID 427)\n",
      "10-20 14:41:41.419 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_336_piece0 on 95675304fa2d:39707 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.421 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_341_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.422 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_340_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.423 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_342_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.424 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_344_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.425 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_334_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:41.425 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_343_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.426 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_335_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.427 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_332_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.428 172.17.0.2:54321      6000    (TID 427)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 210.0 (TID 427). 1787 bytes result sent to driver\n",
      "10-20 14:41:41.428 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 210.0 (TID 427) in 15 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:41.428 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 210.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.428 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_330_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.429 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 210 (parquet at treeModels.scala:507) finished in 0.038 s\n",
      "10-20 14:41:41.429 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 180 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.429 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 210: Stage finished\n",
      "10-20 14:41:41.430 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_331_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.432 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 180 finished: parquet at treeModels.scala:507, took 0.038953 s\n",
      "10-20 14:41:41.432 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_333_piece0 on 95675304fa2d:39707 in memory (size: 2.4 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.433 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_337_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:41.434 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_339_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:41.451 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:41.451 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:41.451 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<treeID: int, metadata: string, weights: double ... 1 more fields>\n",
      "10-20 14:41:41.455 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_346 stored as values in memory (estimated size 177.5 KiB, free 433.5 MiB)\n",
      "10-20 14:41:41.460 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_346_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 433.5 MiB)\n",
      "10-20 14:41:41.460 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_346_piece0 in memory on 95675304fa2d:39707 (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:41.460 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 346 from rdd at treeModels.scala:509\n",
      "10-20 14:41:41.461 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4198400 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:41.472 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: sortByKey at treeModels.scala:514\n",
      "10-20 14:41:41.473 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 181 (sortByKey at treeModels.scala:514) with 4 output partitions\n",
      "10-20 14:41:41.473 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 211 (sortByKey at treeModels.scala:514)\n",
      "10-20 14:41:41.473 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.473 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.473 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 211 (MapPartitionsRDD[547] at sortByKey at treeModels.scala:514), which has no missing parents\n",
      "10-20 14:41:41.474 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_347 stored as values in memory (estimated size 20.0 KiB, free 433.5 MiB)\n",
      "10-20 14:41:41.474 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_347_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 433.5 MiB)\n",
      "10-20 14:41:41.475 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_347_piece0 in memory on 95675304fa2d:39707 (size: 8.9 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:41.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 347 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 211 (MapPartitionsRDD[547] at sortByKey at treeModels.scala:514) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:41.475 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 211.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:41.476 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 211.0 (TID 428) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.477 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 211.0 (TID 429) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.477 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 211.0 (TID 430) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.477 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 211.0 (TID 431) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.477 172.17.0.2:54321      6000    (TID 430)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 211.0 (TID 430)\n",
      "10-20 14:41:41.477 172.17.0.2:54321      6000    (TID 428)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 211.0 (TID 428)\n",
      "10-20 14:41:41.478 172.17.0.2:54321      6000    (TID 429)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 211.0 (TID 429)\n",
      "10-20 14:41:41.482 172.17.0.2:54321      6000    (TID 428)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00002-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4114, partition values: [empty row]\n",
      "10-20 14:41:41.483 172.17.0.2:54321      6000    (TID 429)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00001-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4113, partition values: [empty row]\n",
      "10-20 14:41:41.487 172.17.0.2:54321      6000    (TID 431)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 211.0 (TID 431)\n",
      "10-20 14:41:41.490 172.17.0.2:54321      6000    (TID 430)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00000-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4083, partition values: [empty row]\n",
      "10-20 14:41:41.490 172.17.0.2:54321      6000    (TID 431)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00003-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4077, partition values: [empty row]\n",
      "10-20 14:41:41.492 172.17.0.2:54321      6000    (TID 429)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 211.0 (TID 429). 1953 bytes result sent to driver\n",
      "10-20 14:41:41.493 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 211.0 (TID 429) in 16 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:41.498 172.17.0.2:54321      6000    (TID 430)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 211.0 (TID 430). 1953 bytes result sent to driver\n",
      "10-20 14:41:41.499 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 211.0 (TID 430) in 22 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:41.500 172.17.0.2:54321      6000    (TID 431)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 211.0 (TID 431). 1953 bytes result sent to driver\n",
      "10-20 14:41:41.501 172.17.0.2:54321      6000    (TID 428)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 211.0 (TID 428). 1953 bytes result sent to driver\n",
      "10-20 14:41:41.501 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 211.0 (TID 428) in 25 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:41.502 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 211.0 (TID 431) in 25 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:41.502 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 211.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.502 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 211 (sortByKey at treeModels.scala:514) finished in 0.029 s\n",
      "10-20 14:41:41.502 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 181 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.502 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 211: Stage finished\n",
      "10-20 14:41:41.502 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 181 finished: sortByKey at treeModels.scala:514, took 0.030028 s\n",
      "10-20 14:41:41.509 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at treeModels.scala:514\n",
      "10-20 14:41:41.509 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 545 (map at treeModels.scala:510) as input to shuffle 25\n",
      "10-20 14:41:41.509 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 182 (collect at treeModels.scala:514) with 4 output partitions\n",
      "10-20 14:41:41.509 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 213 (collect at treeModels.scala:514)\n",
      "10-20 14:41:41.509 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 212)\n",
      "10-20 14:41:41.509 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 212)\n",
      "10-20 14:41:41.509 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 212 (MapPartitionsRDD[545] at map at treeModels.scala:510), which has no missing parents\n",
      "10-20 14:41:41.510 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_348 stored as values in memory (estimated size 20.7 KiB, free 433.4 MiB)\n",
      "10-20 14:41:41.511 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_348_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 433.4 MiB)\n",
      "10-20 14:41:41.511 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_348_piece0 in memory on 95675304fa2d:39707 (size: 9.5 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.511 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 348 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.512 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 212 (MapPartitionsRDD[545] at map at treeModels.scala:510) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:41.512 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 212.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:41.512 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 212.0 (TID 432) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4995 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.512 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 212.0 (TID 433) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4995 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.512 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 212.0 (TID 434) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4995 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.512 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 212.0 (TID 435) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4995 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.513 172.17.0.2:54321      6000    (TID 435)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 212.0 (TID 435)\n",
      "10-20 14:41:41.513 172.17.0.2:54321      6000    (TID 432)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 212.0 (TID 432)\n",
      "10-20 14:41:41.517 172.17.0.2:54321      6000    (TID 435)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00003-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4077, partition values: [empty row]\n",
      "10-20 14:41:41.517 172.17.0.2:54321      6000    (TID 432)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00002-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4114, partition values: [empty row]\n",
      "10-20 14:41:41.521 172.17.0.2:54321      6000    (TID 433)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 212.0 (TID 433)\n",
      "10-20 14:41:41.524 172.17.0.2:54321      6000    (TID 433)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00001-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4113, partition values: [empty row]\n",
      "10-20 14:41:41.525 172.17.0.2:54321      6000    (TID 435)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 212.0 (TID 435). 1906 bytes result sent to driver\n",
      "10-20 14:41:41.525 172.17.0.2:54321      6000    (TID 434)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 212.0 (TID 434)\n",
      "10-20 14:41:41.525 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 212.0 (TID 435) in 13 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:41.529 172.17.0.2:54321      6000    (TID 432)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 212.0 (TID 432). 1906 bytes result sent to driver\n",
      "10-20 14:41:41.529 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 212.0 (TID 432) in 17 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:41.531 172.17.0.2:54321      6000    (TID 433)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 212.0 (TID 433). 1906 bytes result sent to driver\n",
      "10-20 14:41:41.532 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 212.0 (TID 433) in 20 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:41.532 172.17.0.2:54321      6000    (TID 434)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/treesMetadata/part-00000-2423f70d-eced-4cd6-b739-a1a36fcc46be-c000.snappy.parquet, range: 0-4083, partition values: [empty row]\n",
      "10-20 14:41:41.540 172.17.0.2:54321      6000    (TID 434)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 212.0 (TID 434). 1906 bytes result sent to driver\n",
      "10-20 14:41:41.540 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 212.0 (TID 434) in 28 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:41.540 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 212.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.541 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 212 (map at treeModels.scala:510) finished in 0.031 s\n",
      "10-20 14:41:41.541 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:41:41.541 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:41:41.541 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 213)\n",
      "10-20 14:41:41.541 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:41:41.541 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 213 (MapPartitionsRDD[549] at values at treeModels.scala:514), which has no missing parents\n",
      "10-20 14:41:41.542 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_349 stored as values in memory (estimated size 4.6 KiB, free 433.4 MiB)\n",
      "10-20 14:41:41.543 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_349_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 433.4 MiB)\n",
      "10-20 14:41:41.543 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_349_piece0 in memory on 95675304fa2d:39707 (size: 2.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.544 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 349 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.544 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 213 (MapPartitionsRDD[549] at values at treeModels.scala:514) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:41.544 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 213.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:41.545 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 213.0 (TID 436) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.545 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 213.0 (TID 437) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.545 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 213.0 (TID 438) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.546 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 213.0 (TID 439) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.546 172.17.0.2:54321      6000    (TID 437)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 213.0 (TID 437)\n",
      "10-20 14:41:41.546 172.17.0.2:54321      6000    (TID 439)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 213.0 (TID 439)\n",
      "10-20 14:41:41.546 172.17.0.2:54321      6000    (TID 438)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 213.0 (TID 438)\n",
      "10-20 14:41:41.547 172.17.0.2:54321      6000    (TID 436)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 213.0 (TID 436)\n",
      "10-20 14:41:41.547 172.17.0.2:54321      6000    (TID 437)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.547 172.17.0.2:54321      6000    (TID 438)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.547 172.17.0.2:54321      6000    (TID 438)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.548 172.17.0.2:54321      6000    (TID 436)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.548 172.17.0.2:54321      6000    (TID 436)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.547 172.17.0.2:54321      6000    (TID 437)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.548 172.17.0.2:54321      6000    (TID 439)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.549 172.17.0.2:54321      6000    (TID 439)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.550 172.17.0.2:54321      6000    (TID 439)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 213.0 (TID 439). 10697 bytes result sent to driver\n",
      "10-20 14:41:41.550 172.17.0.2:54321      6000    (TID 438)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 213.0 (TID 438). 10697 bytes result sent to driver\n",
      "10-20 14:41:41.551 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 213.0 (TID 439) in 5 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:41.551 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 213.0 (TID 438) in 6 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:41.553 172.17.0.2:54321      6000    (TID 436)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 213.0 (TID 436). 10697 bytes result sent to driver\n",
      "10-20 14:41:41.553 172.17.0.2:54321      6000    (TID 437)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 213.0 (TID 437). 10654 bytes result sent to driver\n",
      "10-20 14:41:41.555 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 213.0 (TID 436) in 10 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:41.556 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 213.0 (TID 437) in 11 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:41.556 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 213.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.556 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 213 (collect at treeModels.scala:514) finished in 0.015 s\n",
      "10-20 14:41:41.557 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 182 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.557 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 213: Stage finished\n",
      "10-20 14:41:41.557 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 182 finished: collect at treeModels.scala:514, took 0.047960 s\n",
      "10-20 14:41:41.563 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "10-20 14:41:41.581 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at treeModels.scala:519\n",
      "10-20 14:41:41.582 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 183 (parquet at treeModels.scala:519) with 1 output partitions\n",
      "10-20 14:41:41.582 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 214 (parquet at treeModels.scala:519)\n",
      "10-20 14:41:41.582 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:41.582 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:41.582 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 214 (MapPartitionsRDD[551] at parquet at treeModels.scala:519), which has no missing parents\n",
      "10-20 14:41:41.587 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_350 stored as values in memory (estimated size 84.5 KiB, free 433.3 MiB)\n",
      "10-20 14:41:41.588 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_350_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.3 MiB)\n",
      "10-20 14:41:41.588 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_350_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.589 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 350 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.589 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 214 (MapPartitionsRDD[551] at parquet at treeModels.scala:519) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:41.589 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 214.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:41.590 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 214.0 (TID 440) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4746 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.590 172.17.0.2:54321      6000    (TID 440)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 214.0 (TID 440)\n",
      "10-20 14:41:41.596 172.17.0.2:54321      6000    (TID 440)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 214.0 (TID 440). 2376 bytes result sent to driver\n",
      "10-20 14:41:41.597 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 214.0 (TID 440) in 7 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:41.597 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.597 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 214 (parquet at treeModels.scala:519) finished in 0.015 s\n",
      "10-20 14:41:41.598 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 183 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.598 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 214: Stage finished\n",
      "10-20 14:41:41.598 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 183 finished: parquet at treeModels.scala:519, took 0.016670 s\n",
      "10-20 14:41:41.669 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:41.669 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:41.669 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<treeID: int, nodeData: struct<id: int, prediction: double, impurity: double, impurityStats: array<double>, rawCount: bigint ... 7 more fields>>\n",
      "10-20 14:41:41.671 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_351 stored as values in memory (estimated size 179.3 KiB, free 433.1 MiB)\n",
      "10-20 14:41:41.678 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_351_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:41.678 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_351_piece0 in memory on 95675304fa2d:39707 (size: 29.2 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.679 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 351 from rdd at treeModels.scala:530\n",
      "10-20 14:41:41.679 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4203994 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:41.697 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: sortByKey at treeModels.scala:536\n",
      "10-20 14:41:41.697 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 557 (map at treeModels.scala:531) as input to shuffle 26\n",
      "10-20 14:41:41.698 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 184 (sortByKey at treeModels.scala:536) with 4 output partitions\n",
      "10-20 14:41:41.698 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 216 (sortByKey at treeModels.scala:536)\n",
      "10-20 14:41:41.698 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 215)\n",
      "10-20 14:41:41.698 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 215)\n",
      "10-20 14:41:41.698 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 215 (MapPartitionsRDD[557] at map at treeModels.scala:531), which has no missing parents\n",
      "10-20 14:41:41.699 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_352 stored as values in memory (estimated size 25.2 KiB, free 433.1 MiB)\n",
      "10-20 14:41:41.700 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_352_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 433.1 MiB)\n",
      "10-20 14:41:41.700 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_352_piece0 in memory on 95675304fa2d:39707 (size: 9.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.701 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 352 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.701 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 215 (MapPartitionsRDD[557] at map at treeModels.scala:531) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:41.701 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 215.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:41.702 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 215.0 (TID 441) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4986 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.702 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 215.0 (TID 442) (95675304fa2d, executor driver, partition 1, PROCESS_LOCAL, 4986 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.702 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 215.0 (TID 443) (95675304fa2d, executor driver, partition 2, PROCESS_LOCAL, 4986 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.702 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 215.0 (TID 444) (95675304fa2d, executor driver, partition 3, PROCESS_LOCAL, 4986 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.703 172.17.0.2:54321      6000    (TID 441)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 215.0 (TID 441)\n",
      "10-20 14:41:41.703 172.17.0.2:54321      6000    (TID 443)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 215.0 (TID 443)\n",
      "10-20 14:41:41.703 172.17.0.2:54321      6000    (TID 442)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 215.0 (TID 442)\n",
      "10-20 14:41:41.705 172.17.0.2:54321      6000    (TID 444)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 215.0 (TID 444)\n",
      "10-20 14:41:41.715 172.17.0.2:54321      6000    (TID 443)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/data/part-00002-4743f76e-eebf-4f06-b931-35f1863f01bb-c000.snappy.parquet, range: 0-9551, partition values: [empty row]\n",
      "10-20 14:41:41.716 172.17.0.2:54321      6000    (TID 442)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/data/part-00000-4743f76e-eebf-4f06-b931-35f1863f01bb-c000.snappy.parquet, range: 0-9647, partition values: [empty row]\n",
      "10-20 14:41:41.723 172.17.0.2:54321      6000    (TID 443)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 169 records.\n",
      "10-20 14:41:41.726 172.17.0.2:54321      6000    (TID 441)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/data/part-00003-4743f76e-eebf-4f06-b931-35f1863f01bb-c000.snappy.parquet, range: 0-10207, partition values: [empty row]\n",
      "10-20 14:41:41.729 172.17.0.2:54321      6000    (TID 441)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 189 records.\n",
      "10-20 14:41:41.731 172.17.0.2:54321      6000    (TID 443)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:41.735 172.17.0.2:54321      6000    (TID 443)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 3 ms. row count = 169\n",
      "10-20 14:41:41.737 172.17.0.2:54321      6000    (TID 444)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/18_RandomForestClassifier_b22e8c938b22/data/part-00001-4743f76e-eebf-4f06-b931-35f1863f01bb-c000.snappy.parquet, range: 0-9356, partition values: [empty row]\n",
      "10-20 14:41:41.740 172.17.0.2:54321      6000    (TID 442)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 173 records.\n",
      "10-20 14:41:41.743 172.17.0.2:54321      6000    (TID 444)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 161 records.\n",
      "10-20 14:41:41.743 172.17.0.2:54321      6000    (TID 441)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:41.753 172.17.0.2:54321      6000    (TID 441)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 9 ms. row count = 189\n",
      "10-20 14:41:41.757 172.17.0.2:54321      6000    (TID 443)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 215.0 (TID 443). 1624 bytes result sent to driver\n",
      "10-20 14:41:41.758 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 215.0 (TID 443) in 56 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:41.758 172.17.0.2:54321      6000    (TID 444)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:41.759 172.17.0.2:54321      6000    (TID 444)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 161\n",
      "10-20 14:41:41.767 172.17.0.2:54321      6000    (TID 442)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:41:41.768 172.17.0.2:54321      6000    (TID 442)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 173\n",
      "10-20 14:41:41.770 172.17.0.2:54321      6000    (TID 444)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 215.0 (TID 444). 1624 bytes result sent to driver\n",
      "10-20 14:41:41.770 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 215.0 (TID 444) in 68 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:41.775 172.17.0.2:54321      6000    (TID 441)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 215.0 (TID 441). 1624 bytes result sent to driver\n",
      "10-20 14:41:41.776 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 215.0 (TID 441) in 74 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:41.780 172.17.0.2:54321      6000    (TID 442)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 215.0 (TID 442). 1624 bytes result sent to driver\n",
      "10-20 14:41:41.781 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 215.0 (TID 442) in 79 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:41.781 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.781 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 215 (map at treeModels.scala:531) finished in 0.082 s\n",
      "10-20 14:41:41.781 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:41:41.781 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:41:41.781 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 216)\n",
      "10-20 14:41:41.781 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:41:41.782 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 216 (MapPartitionsRDD[561] at sortByKey at treeModels.scala:536), which has no missing parents\n",
      "10-20 14:41:41.783 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_353 stored as values in memory (estimated size 27.4 KiB, free 433.0 MiB)\n",
      "10-20 14:41:41.783 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_353_piece0 stored as bytes in memory (estimated size 10.5 KiB, free 433.0 MiB)\n",
      "10-20 14:41:41.784 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_353_piece0 in memory on 95675304fa2d:39707 (size: 10.5 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.784 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 353 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.784 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 216 (MapPartitionsRDD[561] at sortByKey at treeModels.scala:536) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:41.784 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 216.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:41.785 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 216.0 (TID 445) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.785 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 216.0 (TID 446) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.785 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 216.0 (TID 447) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.785 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 216.0 (TID 448) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.786 172.17.0.2:54321      6000    (TID 446)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 216.0 (TID 446)\n",
      "10-20 14:41:41.786 172.17.0.2:54321      6000    (TID 448)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 216.0 (TID 448)\n",
      "10-20 14:41:41.786 172.17.0.2:54321      6000    (TID 447)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 216.0 (TID 447)\n",
      "10-20 14:41:41.789 172.17.0.2:54321      6000    (TID 448)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (11.1 KiB) non-empty blocks including 4 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.789 172.17.0.2:54321      6000    (TID 448)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.789 172.17.0.2:54321      6000    (TID 447)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.0 KiB) non-empty blocks including 4 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.791 172.17.0.2:54321      6000    (TID 445)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 216.0 (TID 445)\n",
      "10-20 14:41:41.791 172.17.0.2:54321      6000    (TID 447)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:41:41.794 172.17.0.2:54321      6000    (TID 445)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.6 KiB) non-empty blocks including 4 (10.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.794 172.17.0.2:54321      6000    (TID 445)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.795 172.17.0.2:54321      6000    (TID 448)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 216.0 (TID 448). 2015 bytes result sent to driver\n",
      "10-20 14:41:41.795 172.17.0.2:54321      6000    (TID 447)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 216.0 (TID 447). 2015 bytes result sent to driver\n",
      "10-20 14:41:41.795 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 216.0 (TID 448) in 10 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:41.796 172.17.0.2:54321      6000    (TID 446)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (11.4 KiB) non-empty blocks including 4 (11.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.796 172.17.0.2:54321      6000    (TID 446)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.797 172.17.0.2:54321      6000    (TID 445)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 216.0 (TID 445). 2015 bytes result sent to driver\n",
      "10-20 14:41:41.798 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 216.0 (TID 447) in 12 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:41.798 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 216.0 (TID 445) in 13 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:41.801 172.17.0.2:54321      6000    (TID 446)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 216.0 (TID 446). 2015 bytes result sent to driver\n",
      "10-20 14:41:41.801 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 216.0 (TID 446) in 16 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:41.801 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 216.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.802 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 216 (sortByKey at treeModels.scala:536) finished in 0.020 s\n",
      "10-20 14:41:41.802 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 184 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.802 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 216: Stage finished\n",
      "10-20 14:41:41.802 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 184 finished: sortByKey at treeModels.scala:536, took 0.105029 s\n",
      "10-20 14:41:41.807 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: collect at treeModels.scala:536\n",
      "10-20 14:41:41.808 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Registering RDD 559 (map at treeModels.scala:533) as input to shuffle 27\n",
      "10-20 14:41:41.808 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 185 (collect at treeModels.scala:536) with 4 output partitions\n",
      "10-20 14:41:41.808 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 219 (collect at treeModels.scala:536)\n",
      "10-20 14:41:41.808 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 218)\n",
      "10-20 14:41:41.808 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 218)\n",
      "10-20 14:41:41.808 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 218 (MapPartitionsRDD[559] at map at treeModels.scala:533), which has no missing parents\n",
      "10-20 14:41:41.809 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_354 stored as values in memory (estimated size 26.5 KiB, free 433.0 MiB)\n",
      "10-20 14:41:41.810 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_354_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 433.0 MiB)\n",
      "10-20 14:41:41.810 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_354_piece0 in memory on 95675304fa2d:39707 (size: 10.3 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.810 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 354 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.811 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 218 (MapPartitionsRDD[559] at map at treeModels.scala:533) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:41.811 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 218.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:41.811 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 218.0 (TID 449) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.812 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 218.0 (TID 450) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.812 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 218.0 (TID 451) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.812 172.17.0.2:54321      6000   ent-loop-0  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 218.0 (TID 452) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.812 172.17.0.2:54321      6000    (TID 449)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 218.0 (TID 449)\n",
      "10-20 14:41:41.812 172.17.0.2:54321      6000    (TID 451)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 218.0 (TID 451)\n",
      "10-20 14:41:41.812 172.17.0.2:54321      6000    (TID 452)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 218.0 (TID 452)\n",
      "10-20 14:41:41.812 172.17.0.2:54321      6000    (TID 450)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 218.0 (TID 450)\n",
      "10-20 14:41:41.816 172.17.0.2:54321      6000    (TID 450)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (11.4 KiB) non-empty blocks including 4 (11.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.817 172.17.0.2:54321      6000    (TID 450)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "10-20 14:41:41.819 172.17.0.2:54321      6000    (TID 451)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.0 KiB) non-empty blocks including 4 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.819 172.17.0.2:54321      6000    (TID 451)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.822 172.17.0.2:54321      6000    (TID 449)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.6 KiB) non-empty blocks including 4 (10.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.822 172.17.0.2:54321      6000    (TID 449)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.824 172.17.0.2:54321      6000    (TID 451)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 218.0 (TID 451). 1968 bytes result sent to driver\n",
      "10-20 14:41:41.824 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 218.0 (TID 451) in 12 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:41.825 172.17.0.2:54321      6000    (TID 450)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 218.0 (TID 450). 1968 bytes result sent to driver\n",
      "10-20 14:41:41.825 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 218.0 (TID 450) in 14 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:41.828 172.17.0.2:54321      6000    (TID 452)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (11.1 KiB) non-empty blocks including 4 (11.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.828 172.17.0.2:54321      6000    (TID 452)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.830 172.17.0.2:54321      6000    (TID 449)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 218.0 (TID 449). 1968 bytes result sent to driver\n",
      "10-20 14:41:41.830 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 218.0 (TID 449) in 19 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:41.833 172.17.0.2:54321      6000    (TID 452)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 218.0 (TID 452). 1968 bytes result sent to driver\n",
      "10-20 14:41:41.834 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 218.0 (TID 452) in 22 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:41.834 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 218.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.834 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ShuffleMapStage 218 (map at treeModels.scala:533) finished in 0.025 s\n",
      "10-20 14:41:41.834 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: looking for newly runnable stages\n",
      "10-20 14:41:41.834 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: running: Set()\n",
      "10-20 14:41:41.834 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: waiting: Set(ResultStage 219)\n",
      "10-20 14:41:41.834 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: failed: Set()\n",
      "10-20 14:41:41.834 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 219 (MapPartitionsRDD[563] at values at treeModels.scala:536), which has no missing parents\n",
      "10-20 14:41:41.835 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_355 stored as values in memory (estimated size 4.7 KiB, free 433.0 MiB)\n",
      "10-20 14:41:41.846 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_355_piece0 stored as bytes in memory (estimated size 2.6 KiB, free 433.0 MiB)\n",
      "10-20 14:41:41.846 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_355_piece0 in memory on 95675304fa2d:39707 (size: 2.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.847 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 355 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:41.847 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 219 (MapPartitionsRDD[563] at values at treeModels.scala:536) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "10-20 14:41:41.847 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 219.0 with 4 tasks resource profile 0\n",
      "10-20 14:41:41.847 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_353_piece0 on 95675304fa2d:39707 in memory (size: 10.5 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.848 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 219.0 (TID 453) (95675304fa2d, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.848 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 1.0 in stage 219.0 (TID 454) (95675304fa2d, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.848 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 2.0 in stage 219.0 (TID 455) (95675304fa2d, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.848 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 3.0 in stage 219.0 (TID 456) (95675304fa2d, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:41.849 172.17.0.2:54321      6000    (TID 454)  INFO org.apache.spark.executor.Executor: Running task 1.0 in stage 219.0 (TID 454)\n",
      "10-20 14:41:41.849 172.17.0.2:54321      6000    (TID 456)  INFO org.apache.spark.executor.Executor: Running task 3.0 in stage 219.0 (TID 456)\n",
      "10-20 14:41:41.851 172.17.0.2:54321      6000    (TID 454)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (9.8 KiB) non-empty blocks including 4 (9.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.851 172.17.0.2:54321      6000    (TID 454)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.852 172.17.0.2:54321      6000    (TID 456)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.9 KiB) non-empty blocks including 4 (10.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.852 172.17.0.2:54321      6000    (TID 456)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "10-20 14:41:41.852 172.17.0.2:54321      6000    (TID 453)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 219.0 (TID 453)\n",
      "10-20 14:41:41.854 172.17.0.2:54321      6000    (TID 453)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.0 KiB) non-empty blocks including 4 (10.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.855 172.17.0.2:54321      6000    (TID 453)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "10-20 14:41:41.854 172.17.0.2:54321      6000    (TID 455)  INFO org.apache.spark.executor.Executor: Running task 2.0 in stage 219.0 (TID 455)\n",
      "10-20 14:41:41.856 172.17.0.2:54321      6000    (TID 454)  INFO org.apache.spark.executor.Executor: Finished task 1.0 in stage 219.0 (TID 454). 16238 bytes result sent to driver\n",
      "10-20 14:41:41.855 172.17.0.2:54321      6000    (TID 456)  INFO org.apache.spark.executor.Executor: Finished task 3.0 in stage 219.0 (TID 456). 18698 bytes result sent to driver\n",
      "10-20 14:41:41.860 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 1.0 in stage 219.0 (TID 454) in 12 ms on 95675304fa2d (executor driver) (1/4)\n",
      "10-20 14:41:41.861 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 3.0 in stage 219.0 (TID 456) in 13 ms on 95675304fa2d (executor driver) (2/4)\n",
      "10-20 14:41:41.859 172.17.0.2:54321      6000    (TID 453)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 219.0 (TID 453). 17283 bytes result sent to driver\n",
      "10-20 14:41:41.862 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_349_piece0 on 95675304fa2d:39707 in memory (size: 2.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.862 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 219.0 (TID 453) in 14 ms on 95675304fa2d (executor driver) (3/4)\n",
      "10-20 14:41:41.858 172.17.0.2:54321      6000    (TID 455)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Getting 4 (10.2 KiB) non-empty blocks including 4 (10.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\n",
      "10-20 14:41:41.863 172.17.0.2:54321      6000    (TID 455)  INFO org.apache.spark.storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "10-20 14:41:41.864 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_348_piece0 on 95675304fa2d:39707 in memory (size: 9.5 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.864 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_352_piece0 on 95675304fa2d:39707 in memory (size: 9.6 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.865 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_350_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.866 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_345_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.866 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_347_piece0 on 95675304fa2d:39707 in memory (size: 8.9 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:41.868 172.17.0.2:54321      6000    (TID 455)  INFO org.apache.spark.executor.Executor: Finished task 2.0 in stage 219.0 (TID 455). 17088 bytes result sent to driver\n",
      "10-20 14:41:41.869 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 2.0 in stage 219.0 (TID 455) in 20 ms on 95675304fa2d (executor driver) (4/4)\n",
      "10-20 14:41:41.869 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 219.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:41.869 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 219 (collect at treeModels.scala:536) finished in 0.034 s\n",
      "10-20 14:41:41.870 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 185 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:41.870 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 219: Stage finished\n",
      "10-20 14:41:41.870 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 185 finished: collect at treeModels.scala:536, took 0.062145 s\n",
      "10-20 14:41:41.877 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [c7808ac3] training finished\n",
      "10-20 14:41:41.878 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.ml.util.Instrumentation: [c65efe56] training finished\n",
      "10-20 14:41:42.306 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:42.306 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:42.306 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<fnlwgt: double, age: double, capital_gain: double, capital_loss: double, hours_per_week: double ... 3 more fields>\n",
      "10-20 14:41:42.312 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_356 stored as values in memory (estimated size 177.8 KiB, free 433.2 MiB)\n",
      "10-20 14:41:42.325 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_346_piece0 on 95675304fa2d:39707 in memory (size: 28.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:42.326 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_355_piece0 on 95675304fa2d:39707 in memory (size: 2.6 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:42.330 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_356_piece0 stored as bytes in memory (estimated size 28.7 KiB, free 433.4 MiB)\n",
      "10-20 14:41:42.330 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_356_piece0 in memory on 95675304fa2d:39707 (size: 28.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:42.331 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 356 from head at Imputer.scala:258\n",
      "10-20 14:41:42.332 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:42.332 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_351_piece0 on 95675304fa2d:39707 in memory (size: 29.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:42.333 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_216_piece0 on 95675304fa2d:39707 in memory (size: 27.2 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:42.334 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_354_piece0 on 95675304fa2d:39707 in memory (size: 10.3 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:42.338 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: head at Imputer.scala:258\n",
      "10-20 14:41:42.341 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 186 (head at Imputer.scala:258) with 1 output partitions\n",
      "10-20 14:41:42.341 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 220 (head at Imputer.scala:258)\n",
      "10-20 14:41:42.341 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:42.341 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:42.341 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 220 (MapPartitionsRDD[567] at head at Imputer.scala:258), which has no missing parents\n",
      "10-20 14:41:42.342 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_357 stored as values in memory (estimated size 14.0 KiB, free 433.8 MiB)\n",
      "10-20 14:41:42.343 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_357_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 433.8 MiB)\n",
      "10-20 14:41:42.344 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_357_piece0 in memory on 95675304fa2d:39707 (size: 5.7 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:42.344 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 357 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:42.345 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 220 (MapPartitionsRDD[567] at head at Imputer.scala:258) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:42.345 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 220.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:42.346 172.17.0.2:54321      6000   ent-loop-3  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 220.0 (TID 457) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:42.346 172.17.0.2:54321      6000    (TID 457)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 220.0 (TID 457)\n",
      "10-20 14:41:42.348 172.17.0.2:54321      6000    (TID 457)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark/stages/00_Imputer_f71f2b7be3c3/data/part-00000-a97a8010-555e-44ad-bd78-6ec0db1bb5ae-c000.snappy.parquet, range: 0-1479, partition values: [empty row]\n",
      "10-20 14:41:42.352 172.17.0.2:54321      6000    (TID 457)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 220.0 (TID 457). 1700 bytes result sent to driver\n",
      "10-20 14:41:42.353 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 220.0 (TID 457) in 8 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:42.353 172.17.0.2:54321      6000   t-getter-1  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 220.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:42.354 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 220 (head at Imputer.scala:258) finished in 0.013 s\n",
      "10-20 14:41:42.354 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 186 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:42.354 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 220: Stage finished\n",
      "10-20 14:41:42.355 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 186 finished: head at Imputer.scala:258, took 0.014073 s\n",
      "10-20 14:41:42.883 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:41:42.883 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:41:42.883 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<age: int, workclass: string, fnlwgt: double, education: string, marital_status: string ... 11 more fields>\n",
      "10-20 14:41:42.890 172.17.0.2:54321      6000     Thread-4  WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "10-20 14:41:42.913 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:41:42.924 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:41:42.925 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:41:42.949 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 10.48458 ms\n",
      "10-20 14:41:42.981 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 18.643048 ms\n",
      "10-20 14:41:42.982 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_358 stored as values in memory (estimated size 176.1 KiB, free 433.6 MiB)\n",
      "10-20 14:41:42.987 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_358_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.6 MiB)\n",
      "10-20 14:41:42.987 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_358_piece0 in memory on 95675304fa2d:39707 (size: 28.0 KiB, free: 434.3 MiB)\n",
      "10-20 14:41:42.988 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 358 from parquet at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:41:42.988 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:41:43.023 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:41:43.024 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 187 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 14:41:43.024 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 221 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "10-20 14:41:43.024 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:41:43.024 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:41:43.024 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 221 (MapPartitionsRDD[573] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:41:43.038 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_359 stored as values in memory (estimated size 412.5 KiB, free 433.2 MiB)\n",
      "10-20 14:41:43.040 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_359_piece0 stored as bytes in memory (estimated size 143.1 KiB, free 433.0 MiB)\n",
      "10-20 14:41:43.040 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_359_piece0 in memory on 95675304fa2d:39707 (size: 143.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:41:43.041 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 359 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:41:43.041 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 221 (MapPartitionsRDD[573] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:41:43.041 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 221.0 with 1 tasks resource profile 0\n",
      "10-20 14:41:43.042 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 221.0 (TID 458) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4865 bytes) taskResourceAssignments Map()\n",
      "10-20 14:41:43.042 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 221.0 (TID 458)\n",
      "10-20 14:41:43.092 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 6.696702 ms\n",
      "10-20 14:41:43.123 172.17.0.2:54321      6000   bin/python  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/data/census-test.csv, range: 0-2003153, partition values: [empty row]\n",
      "10-20 14:41:43.150 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 31.398768 ms\n",
      "10-20 14:41:43.153 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_357_piece0 on 95675304fa2d:39707 in memory (size: 5.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:43.157 172.17.0.2:54321      6000   bin/python  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 31.948292 ms\n",
      "10-20 14:41:43.166 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:41:43.167 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "10-20 14:41:43.169 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_356_piece0 on 95675304fa2d:39707 in memory (size: 28.7 KiB, free: 434.2 MiB)\n",
      "10-20 14:41:43.180 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:41:43.182 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY\n",
      "10-20 14:41:43.224 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728\n",
      "10-20 14:41:43.224 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576\n",
      "10-20 14:41:43.225 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\n",
      "10-20 14:41:43.225 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on\n",
      "10-20 14:41:43.225 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off\n",
      "10-20 14:41:43.225 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\n",
      "10-20 14:41:43.225 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "10-20 14:41:43.225 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Page size checking is: estimated\n",
      "10-20 14:41:43.225 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Min row count for page size check is: 100\n",
      "10-20 14:41:43.225 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\n",
      "10-20 14:41:43.247 172.17.0.2:54321      6000   bin/python  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 12.649929 ms\n",
      "10-20 14:41:43.258 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"rawPrediction\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"udt\",\n",
      "      \"class\" : \"org.apache.spark.ml.linalg.VectorUDT\",\n",
      "      \"pyClass\" : \"pyspark.ml.linalg.VectorUDT\",\n",
      "      \"sqlType\" : {\n",
      "        \"type\" : \"struct\",\n",
      "        \"fields\" : [ {\n",
      "          \"name\" : \"type\",\n",
      "          \"type\" : \"byte\",\n",
      "          \"nullable\" : false,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"size\",\n",
      "          \"type\" : \"integer\",\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"indices\",\n",
      "          \"type\" : {\n",
      "            \"type\" : \"array\",\n",
      "            \"elementType\" : \"integer\",\n",
      "            \"containsNull\" : false\n",
      "          },\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"values\",\n",
      "          \"type\" : {\n",
      "            \"type\" : \"array\",\n",
      "            \"elementType\" : \"double\",\n",
      "            \"containsNull\" : false\n",
      "          },\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        } ]\n",
      "      }\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"ml_attr\" : {\n",
      "        \"num_attrs\" : 2\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"probability\",\n",
      "    \"type\" : {\n",
      "      \"type\" : \"udt\",\n",
      "      \"class\" : \"org.apache.spark.ml.linalg.VectorUDT\",\n",
      "      \"pyClass\" : \"pyspark.ml.linalg.VectorUDT\",\n",
      "      \"sqlType\" : {\n",
      "        \"type\" : \"struct\",\n",
      "        \"fields\" : [ {\n",
      "          \"name\" : \"type\",\n",
      "          \"type\" : \"byte\",\n",
      "          \"nullable\" : false,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"size\",\n",
      "          \"type\" : \"integer\",\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"indices\",\n",
      "          \"type\" : {\n",
      "            \"type\" : \"array\",\n",
      "            \"elementType\" : \"integer\",\n",
      "            \"containsNull\" : false\n",
      "          },\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        }, {\n",
      "          \"name\" : \"values\",\n",
      "          \"type\" : {\n",
      "            \"type\" : \"array\",\n",
      "            \"elementType\" : \"double\",\n",
      "            \"containsNull\" : false\n",
      "          },\n",
      "          \"nullable\" : true,\n",
      "          \"metadata\" : { }\n",
      "        } ]\n",
      "      }\n",
      "    },\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"ml_attr\" : {\n",
      "        \"num_attrs\" : 2\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"prediction\",\n",
      "    \"type\" : \"double\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : {\n",
      "      \"ml_attr\" : {\n",
      "        \"type\" : \"nominal\",\n",
      "        \"num_vals\" : 2\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"prob\",\n",
      "    \"type\" : \"float\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional group rawPrediction {\n",
      "    required int32 type (INT_8);\n",
      "    optional int32 size;\n",
      "    optional group indices (LIST) {\n",
      "      repeated group list {\n",
      "        required int32 element;\n",
      "      }\n",
      "    }\n",
      "    optional group values (LIST) {\n",
      "      repeated group list {\n",
      "        required double element;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  optional group probability {\n",
      "    required int32 type (INT_8);\n",
      "    optional int32 size;\n",
      "    optional group indices (LIST) {\n",
      "      repeated group list {\n",
      "        required int32 element;\n",
      "      }\n",
      "    }\n",
      "    optional group values (LIST) {\n",
      "      repeated group list {\n",
      "        required double element;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  required double prediction;\n",
      "  optional float prob;\n",
      "}\n",
      "\n",
      "       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 221:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:41:44.372 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.spark.sql.execution.python.PythonUDFRunner: Times: total = 995, boot = 6, init = 256, finish = 733\n",
      "10-20 14:41:44.378 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 644784\n",
      "10-20 14:41:44.427 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.spark.mapred.SparkHadoopMapRedUtil: attempt_202310201441434029071695467480550_0221_m_000000_458: Committed\n",
      "10-20 14:41:44.430 172.17.0.2:54321      6000    (TID 458)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 221.0 (TID 458). 3254 bytes result sent to driver\n",
      "10-20 14:41:44.431 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 221.0 (TID 458) in 1390 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:41:44.432 172.17.0.2:54321      6000   t-getter-3  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool \n",
      "10-20 14:41:44.432 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 221 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.408 s\n",
      "10-20 14:41:44.432 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 187 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:41:44.432 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 221: Stage finished\n",
      "10-20 14:41:44.434 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 187 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.410170 s\n",
      "10-20 14:41:44.443 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Write Job 9ab8bcdc-0a08-4688-8d01-96c787e012c1 committed.\n",
      "10-20 14:41:44.446 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileFormatWriter: Finished processing stats for write job 9ab8bcdc-0a08-4688-8d01-96c787e012c1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml import (\n",
    "    PipelineModel\n",
    ")\n",
    "\n",
    " \n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"workclass\", StringType(), True),\n",
    "    StructField(\"fnlwgt\", DoubleType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"education_num\", IntegerType(), True),\n",
    "    StructField(\"marital_status\", StringType(), True),\n",
    "    StructField(\"occupation\", StringType(), True),\n",
    "    StructField(\"relationship\", StringType(), True),\n",
    "    StructField(\"race\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"capital_gain\", DoubleType(), True),\n",
    "    StructField(\"capital_loss\", DoubleType(), True),\n",
    "    StructField(\"hours_per_week\", DoubleType(), True),\n",
    "    StructField(\"native_country\", StringType(), True),\n",
    "    StructField(\"income_level\", StringType(), True),\n",
    "])\n",
    "\n",
    "test_df = (\n",
    "    spark.read\n",
    "    .format('csv')\n",
    "    .option('header', 'false')\n",
    "    .option('delimiter', ',')\n",
    "    .schema(schema)\n",
    "    .load(test_path)\n",
    "    .withColumn('label', when(col('income_level').contains('>50K'), lit(1)).otherwise(lit(0)))\n",
    "    .drop('education_num', 'income_level', 'label')\n",
    "    .withColumn('workclass', when(col('workclass') == ' ?', lit('NA')).otherwise(col('workclass')))\n",
    "    .withColumn('occupation', when(col('occupation') == ' ?', lit('NA')).otherwise(col('occupation')))\n",
    "    .withColumn('native_country', when(col('native_country') == ' ?', lit('NA')).otherwise(col('native_country')))\n",
    ")\n",
    "\n",
    "pipeline_model = PipelineModel.load(model_path)\n",
    "udf_pos_prob = udf(lambda v: float(v[1]), FloatType())\n",
    "test_df_pred = pipeline_model.transform(test_df)\n",
    "test_df_pred = test_df_pred.withColumn('prob', udf_pos_prob(col('probability')))\n",
    "cols = ['rawPrediction', 'probability', 'prediction', 'prob']\n",
    "test_df_pred.select(*cols).write.parquet(pred_path, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fd2d3b4-57be-4264-83d1-fe62a9faeff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:42:25.309 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.\n",
      "10-20 14:42:25.352 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0\n",
      "10-20 14:42:25.353 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 188 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "10-20 14:42:25.353 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 222 (load at NativeMethodAccessorImpl.java:0)\n",
      "10-20 14:42:25.353 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:42:25.353 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:42:25.354 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 222 (MapPartitionsRDD[577] at load at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "10-20 14:42:25.365 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_360 stored as values in memory (estimated size 84.5 KiB, free 433.2 MiB)\n",
      "10-20 14:42:25.378 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_360_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 433.1 MiB)\n",
      "10-20 14:42:25.378 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_360_piece0 in memory on 95675304fa2d:39707 (size: 30.1 KiB, free: 434.1 MiB)\n",
      "10-20 14:42:25.379 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 360 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:42:25.380 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 222 (MapPartitionsRDD[577] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:42:25.380 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 222.0 with 1 tasks resource profile 0\n",
      "10-20 14:42:25.381 172.17.0.2:54321      6000   ent-loop-2  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 222.0 (TID 459) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4700 bytes) taskResourceAssignments Map()\n",
      "10-20 14:42:25.382 172.17.0.2:54321      6000    (TID 459)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 222.0 (TID 459)\n",
      "10-20 14:42:25.394 172.17.0.2:54321      6000    (TID 459)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 222.0 (TID 459). 2794 bytes result sent to driver\n",
      "10-20 14:42:25.395 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 222.0 (TID 459) in 14 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:42:25.395 172.17.0.2:54321      6000   t-getter-2  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 222.0, whose tasks have all completed, from pool \n",
      "10-20 14:42:25.396 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 222 (load at NativeMethodAccessorImpl.java:0) finished in 0.042 s\n",
      "10-20 14:42:25.396 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 188 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:42:25.396 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 222: Stage finished\n",
      "10-20 14:42:25.397 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 188 finished: load at NativeMethodAccessorImpl.java:0, took 0.044314 s\n",
      "10-20 14:42:25.422 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Pushed Filters: \n",
      "10-20 14:42:25.423 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Post-Scan Filters: \n",
      "10-20 14:42:25.423 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy: Output Data Schema: struct<rawPrediction: vector, probability: vector, prediction: double, prob: float ... 2 more fields>\n",
      "10-20 14:42:25.429 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_361 stored as values in memory (estimated size 179.8 KiB, free 433.0 MiB)\n",
      "10-20 14:42:25.440 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_361_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 432.9 MiB)\n",
      "10-20 14:42:25.442 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_361_piece0 in memory on 95675304fa2d:39707 (size: 29.2 KiB, free: 434.1 MiB)\n",
      "10-20 14:42:25.443 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Created broadcast 361 from toPandas at /tmp/ipykernel_5962/2714203179.py:1\n",
      "10-20 14:42:25.445 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.sql.execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "10-20 14:42:25.453 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.SparkContext: Starting job: toPandas at /tmp/ipykernel_5962/2714203179.py:1\n",
      "10-20 14:42:25.453 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Got job 189 (toPandas at /tmp/ipykernel_5962/2714203179.py:1) with 1 output partitions\n",
      "10-20 14:42:25.453 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Final stage: ResultStage 223 (toPandas at /tmp/ipykernel_5962/2714203179.py:1)\n",
      "10-20 14:42:25.453 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Parents of final stage: List()\n",
      "10-20 14:42:25.453 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Missing parents: List()\n",
      "10-20 14:42:25.454 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting ResultStage 223 (MapPartitionsRDD[580] at toPandas at /tmp/ipykernel_5962/2714203179.py:1), which has no missing parents\n",
      "10-20 14:42:25.463 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_362 stored as values in memory (estimated size 10.1 KiB, free 432.9 MiB)\n",
      "10-20 14:42:25.464 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.storage.memory.MemoryStore: Block broadcast_362_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 432.9 MiB)\n",
      "10-20 14:42:25.464 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Added broadcast_362_piece0 in memory on 95675304fa2d:39707 (size: 5.3 KiB, free: 434.1 MiB)\n",
      "10-20 14:42:25.465 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.SparkContext: Created broadcast 362 from broadcast at DAGScheduler.scala:1388\n",
      "10-20 14:42:25.466 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 223 (MapPartitionsRDD[580] at toPandas at /tmp/ipykernel_5962/2714203179.py:1) (first 15 tasks are for partitions Vector(0))\n",
      "10-20 14:42:25.466 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Adding task set 223.0 with 1 tasks resource profile 0\n",
      "10-20 14:42:25.467 172.17.0.2:54321      6000   ent-loop-1  INFO org.apache.spark.scheduler.TaskSetManager: Starting task 0.0 in stage 223.0 (TID 460) (95675304fa2d, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()\n",
      "10-20 14:42:25.467 172.17.0.2:54321      6000    (TID 460)  INFO org.apache.spark.executor.Executor: Running task 0.0 in stage 223.0 (TID 460)\n",
      "10-20 14:42:25.485 172.17.0.2:54321      6000    (TID 460)  INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator: Code generated in 11.377194 ms\n",
      "10-20 14:42:25.487 172.17.0.2:54321      6000    (TID 460)  INFO org.apache.spark.sql.execution.datasources.FileScanRDD: Reading File path: file:///home/jovyan/notebooks/outputs/income_rf_spark_pred/part-00000-dc0e79c5-633e-4f04-85de-5c522a931a95-c000.snappy.parquet, range: 0-243443, partition values: [empty row]\n",
      "10-20 14:42:25.495 172.17.0.2:54321      6000    (TID 460)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 16282 records.\n",
      "10-20 14:42:25.498 172.17.0.2:54321      6000    (TID 460)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block\n",
      "10-20 14:42:25.500 172.17.0.2:54321      6000    (TID 460)  INFO org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 16282\n",
      "10-20 14:42:25.507 172.17.0.2:54321      6000    (TID 460)  INFO org.apache.spark.executor.Executor: Finished task 0.0 in stage 223.0 (TID 460). 2122 bytes result sent to driver\n",
      "10-20 14:42:25.508 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSetManager: Finished task 0.0 in stage 223.0 (TID 460) in 41 ms on 95675304fa2d (executor driver) (1/1)\n",
      "10-20 14:42:25.508 172.17.0.2:54321      6000   t-getter-0  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool \n",
      "10-20 14:42:25.508 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: ResultStage 223 (toPandas at /tmp/ipykernel_5962/2714203179.py:1) finished in 0.054 s\n",
      "10-20 14:42:25.509 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.DAGScheduler: Job 189 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "10-20 14:42:25.509 172.17.0.2:54321      6000   event-loop  INFO org.apache.spark.scheduler.TaskSchedulerImpl: Killing all running tasks in stage 223: Stage finished\n",
      "10-20 14:42:25.509 172.17.0.2:54321      6000     Thread-4  INFO org.apache.spark.scheduler.DAGScheduler: Job 189 finished: toPandas at /tmp/ipykernel_5962/2714203179.py:1, took 0.056119 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[16.37736275283466, 3.622637247165343]</td>\n",
       "      <td>[0.8188681376417328, 0.18113186235826712]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[19.010115101836554, 0.9898848981634504]</td>\n",
       "      <td>[0.9505057550918276, 0.04949424490817251]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[13.375161764175118, 6.624838235824885]</td>\n",
       "      <td>[0.6687580882087558, 0.33124191179124424]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[13.326906456552484, 6.673093543447515]</td>\n",
       "      <td>[0.6663453228276242, 0.33365467717237574]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[8.207082112497687, 11.792917887502313]</td>\n",
       "      <td>[0.4103541056248844, 0.5896458943751156]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.589646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[19.021352795491893, 0.9786472045081104]</td>\n",
       "      <td>[0.9510676397745945, 0.04893236022540551]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[18.497068651104033, 1.5029313488959692]</td>\n",
       "      <td>[0.9248534325552015, 0.07514656744479845]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[18.23298354762287, 1.7670164523771308]</td>\n",
       "      <td>[0.9116491773811435, 0.08835082261885654]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[10.331123697187872, 9.668876302812127]</td>\n",
       "      <td>[0.5165561848593936, 0.4834438151406063]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[18.87149111861569, 1.1285088813843114]</td>\n",
       "      <td>[0.9435745559307845, 0.05642544406921557]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              rawPrediction  \\\n",
       "0    [16.37736275283466, 3.622637247165343]   \n",
       "1  [19.010115101836554, 0.9898848981634504]   \n",
       "2   [13.375161764175118, 6.624838235824885]   \n",
       "3   [13.326906456552484, 6.673093543447515]   \n",
       "4   [8.207082112497687, 11.792917887502313]   \n",
       "5  [19.021352795491893, 0.9786472045081104]   \n",
       "6  [18.497068651104033, 1.5029313488959692]   \n",
       "7   [18.23298354762287, 1.7670164523771308]   \n",
       "8   [10.331123697187872, 9.668876302812127]   \n",
       "9   [18.87149111861569, 1.1285088813843114]   \n",
       "\n",
       "                                 probability  prediction      prob  \n",
       "0  [0.8188681376417328, 0.18113186235826712]         0.0  0.181132  \n",
       "1  [0.9505057550918276, 0.04949424490817251]         0.0  0.049494  \n",
       "2  [0.6687580882087558, 0.33124191179124424]         0.0  0.331242  \n",
       "3  [0.6663453228276242, 0.33365467717237574]         0.0  0.333655  \n",
       "4   [0.4103541056248844, 0.5896458943751156]         1.0  0.589646  \n",
       "5  [0.9510676397745945, 0.04893236022540551]         0.0  0.048932  \n",
       "6  [0.9248534325552015, 0.07514656744479845]         0.0  0.075147  \n",
       "7  [0.9116491773811435, 0.08835082261885654]         0.0  0.088351  \n",
       "8   [0.5165561848593936, 0.4834438151406063]         0.0  0.483444  \n",
       "9  [0.9435745559307845, 0.05642544406921557]         0.0  0.056425  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 14:42:25.673 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_358_piece0 on 95675304fa2d:39707 in memory (size: 28.0 KiB, free: 434.1 MiB)\n",
      "10-20 14:42:25.677 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_359_piece0 on 95675304fa2d:39707 in memory (size: 143.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:44:58.935 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_360_piece0 on 95675304fa2d:39707 in memory (size: 30.1 KiB, free: 434.3 MiB)\n",
      "10-20 14:44:58.970 172.17.0.2:54321      6000   agerMaster  INFO org.apache.spark.storage.BlockManagerInfo: Removed broadcast_362_piece0 on 95675304fa2d:39707 in memory (size: 5.3 KiB, free: 434.3 MiB)\n"
     ]
    }
   ],
   "source": [
    "spark.read.load('outputs/income_rf_spark_pred').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0eac30-5a4b-4d9f-b9f9-639949917577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
